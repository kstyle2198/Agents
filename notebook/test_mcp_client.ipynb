{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e377e059",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51723748",
   "metadata": {},
   "source": [
    "# Basic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a72b2536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['web_search', 'wiki_search', 'arxiv_search']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='web_search', description='Do Search\\n\\n### Responses:\\n\\n**200**: Successful Response (Success Response)\\nContent-Type: application/json\\n\\n**Output Schema:**\\n```json\\n{}\\n```\\n**422**: Validation Error\\nContent-Type: application/json\\n\\n**Example Response:**\\n```json\\n{\\n  \"detail\": [\\n    {\\n      \"loc\": [],\\n      \"msg\": \"Message\",\\n      \"type\": \"Error Type\"\\n    }\\n  ]\\n}\\n```\\n\\n**Output Schema:**\\n```json\\n{\\n  \"properties\": {\\n    \"detail\": {\\n      \"items\": {\\n        \"properties\": {\\n          \"loc\": {\\n            \"items\": {},\\n            \"type\": \"array\",\\n            \"title\": \"Location\"\\n          },\\n          \"msg\": {\\n            \"type\": \"string\",\\n            \"title\": \"Message\"\\n          },\\n          \"type\": {\\n            \"type\": \"string\",\\n            \"title\": \"Error Type\"\\n          }\\n        },\\n        \"type\": \"object\",\\n        \"required\": [\\n          \"loc\",\\n          \"msg\",\\n          \"type\"\\n        ],\\n        \"title\": \"ValidationError\"\\n      },\\n      \"type\": \"array\",\\n      \"title\": \"Detail\"\\n    }\\n  },\\n  \"type\": \"object\",\\n  \"title\": \"HTTPValidationError\"\\n}\\n```', args_schema={'type': 'object', 'properties': {'query': {'type': 'string', 'title': 'query'}}, 'title': 'web_searchArguments', 'required': ['query']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x0000026A4169A7A0>),\n",
       " StructuredTool(name='wiki_search', description='Do Search\\n\\n### Responses:\\n\\n**200**: Successful Response (Success Response)\\nContent-Type: application/json\\n\\n**Output Schema:**\\n```json\\n{}\\n```\\n**422**: Validation Error\\nContent-Type: application/json\\n\\n**Example Response:**\\n```json\\n{\\n  \"detail\": [\\n    {\\n      \"loc\": [],\\n      \"msg\": \"Message\",\\n      \"type\": \"Error Type\"\\n    }\\n  ]\\n}\\n```\\n\\n**Output Schema:**\\n```json\\n{\\n  \"properties\": {\\n    \"detail\": {\\n      \"items\": {\\n        \"properties\": {\\n          \"loc\": {\\n            \"items\": {},\\n            \"type\": \"array\",\\n            \"title\": \"Location\"\\n          },\\n          \"msg\": {\\n            \"type\": \"string\",\\n            \"title\": \"Message\"\\n          },\\n          \"type\": {\\n            \"type\": \"string\",\\n            \"title\": \"Error Type\"\\n          }\\n        },\\n        \"type\": \"object\",\\n        \"required\": [\\n          \"loc\",\\n          \"msg\",\\n          \"type\"\\n        ],\\n        \"title\": \"ValidationError\"\\n      },\\n      \"type\": \"array\",\\n      \"title\": \"Detail\"\\n    }\\n  },\\n  \"type\": \"object\",\\n  \"title\": \"HTTPValidationError\"\\n}\\n```', args_schema={'type': 'object', 'properties': {'query': {'type': 'string', 'title': 'query'}}, 'title': 'wiki_searchArguments', 'required': ['query']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x0000026A4FC23D80>),\n",
       " StructuredTool(name='arxiv_search', description='Do Search\\n\\n### Responses:\\n\\n**200**: Successful Response (Success Response)\\nContent-Type: application/json\\n\\n**Output Schema:**\\n```json\\n{}\\n```\\n**422**: Validation Error\\nContent-Type: application/json\\n\\n**Example Response:**\\n```json\\n{\\n  \"detail\": [\\n    {\\n      \"loc\": [],\\n      \"msg\": \"Message\",\\n      \"type\": \"Error Type\"\\n    }\\n  ]\\n}\\n```\\n\\n**Output Schema:**\\n```json\\n{\\n  \"properties\": {\\n    \"detail\": {\\n      \"items\": {\\n        \"properties\": {\\n          \"loc\": {\\n            \"items\": {},\\n            \"type\": \"array\",\\n            \"title\": \"Location\"\\n          },\\n          \"msg\": {\\n            \"type\": \"string\",\\n            \"title\": \"Message\"\\n          },\\n          \"type\": {\\n            \"type\": \"string\",\\n            \"title\": \"Error Type\"\\n          }\\n        },\\n        \"type\": \"object\",\\n        \"required\": [\\n          \"loc\",\\n          \"msg\",\\n          \"type\"\\n        ],\\n        \"title\": \"ValidationError\"\\n      },\\n      \"type\": \"array\",\\n      \"title\": \"Detail\"\\n    }\\n  },\\n  \"type\": \"object\",\\n  \"title\": \"HTTPValidationError\"\\n}\\n```', args_schema={'type': 'object', 'properties': {'query': {'type': 'string', 'title': 'query'}}, 'title': 'arxiv_searchArguments', 'required': ['query']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x0000026A4FC23EC0>)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def get_tools():\n",
    "    # 서버 설정 정의\n",
    "    server_config = {\n",
    "        \"search\": {\n",
    "            \"url\": \"http://localhost:8000/mcp\",\n",
    "            \"transport\": \"sse\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    # 1. 'async with'를 제거하고 클라이언트를 직접 생성합니다.\n",
    "    client = MultiServerMCPClient(server_config)\n",
    "    \n",
    "    # 2. 'await'를 사용하여 비동기적으로 도구를 가져옵니다.\n",
    "    tools = await client.get_tools()\n",
    "    return tools\n",
    "\n",
    "tools = await get_tools()\n",
    "tool_names = [tool.name for tool in tools]\n",
    "print(tool_names)\n",
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "957e4957",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "# Add other necessary imports like ChatGroq, create_react_agent etc.\n",
    "\n",
    "async def main(tools:list, query:str):\n",
    "\n",
    "    # 서버 설정 정의\n",
    "    server_config = {\n",
    "        \"search\": {\n",
    "            \"url\": \"http://localhost:8000/mcp\",\n",
    "            \"transport\": \"sse\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    # 1. 'async with'를 제거하고 클라이언트를 직접 생성합니다.\n",
    "    client = MultiServerMCPClient(server_config)\n",
    "    \n",
    "    # 2. 'await'를 사용하여 비동기적으로 도구를 가져옵니다.\n",
    "    tools = await client.get_tools()\n",
    "    \n",
    "    model = ChatGroq(\n",
    "            model= \"qwen/qwen3-32b\", \n",
    "            temperature=0.5,\n",
    "            max_tokens=1000,\n",
    "            )\n",
    "        \n",
    "    prompt = \"\"\"\n",
    "        You are the Smart AI Assistant in a company.\n",
    "        Based on the result of tool calling, Generate a consice and logical answer.\n",
    "        and if there is no relevant infomation in the tool calling result, Just say 'I don't know'\n",
    "        \"\"\"\n",
    "    \n",
    "    agent = create_react_agent(model=model, tools=tools, prompt=prompt)\n",
    "    \n",
    "    inputs = {\"messages\": [(\"user\", query)]}\n",
    "    return await agent.ainvoke(inputs, stream_mode=\"values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d435efd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StructuredTool(name='web_search', description='Do Search\\n\\n### Responses:\\n\\n**200**: Successful Response (Success Response)\\nContent-Type: application/json\\n\\n**Output Schema:**\\n```json\\n{}\\n```\\n**422**: Validation Error\\nContent-Type: application/json\\n\\n**Example Response:**\\n```json\\n{\\n  \"detail\": [\\n    {\\n      \"loc\": [],\\n      \"msg\": \"Message\",\\n      \"type\": \"Error Type\"\\n    }\\n  ]\\n}\\n```\\n\\n**Output Schema:**\\n```json\\n{\\n  \"properties\": {\\n    \"detail\": {\\n      \"items\": {\\n        \"properties\": {\\n          \"loc\": {\\n            \"items\": {},\\n            \"type\": \"array\",\\n            \"title\": \"Location\"\\n          },\\n          \"msg\": {\\n            \"type\": \"string\",\\n            \"title\": \"Message\"\\n          },\\n          \"type\": {\\n            \"type\": \"string\",\\n            \"title\": \"Error Type\"\\n          }\\n        },\\n        \"type\": \"object\",\\n        \"required\": [\\n          \"loc\",\\n          \"msg\",\\n          \"type\"\\n        ],\\n        \"title\": \"ValidationError\"\\n      },\\n      \"type\": \"array\",\\n      \"title\": \"Detail\"\\n    }\\n  },\\n  \"type\": \"object\",\\n  \"title\": \"HTTPValidationError\"\\n}\\n```', args_schema={'type': 'object', 'properties': {'query': {'type': 'string', 'title': 'query'}}, 'title': 'web_searchArguments', 'required': ['query']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x0000026A4169A7A0>),\n",
       " StructuredTool(name='wiki_search', description='Do Search\\n\\n### Responses:\\n\\n**200**: Successful Response (Success Response)\\nContent-Type: application/json\\n\\n**Output Schema:**\\n```json\\n{}\\n```\\n**422**: Validation Error\\nContent-Type: application/json\\n\\n**Example Response:**\\n```json\\n{\\n  \"detail\": [\\n    {\\n      \"loc\": [],\\n      \"msg\": \"Message\",\\n      \"type\": \"Error Type\"\\n    }\\n  ]\\n}\\n```\\n\\n**Output Schema:**\\n```json\\n{\\n  \"properties\": {\\n    \"detail\": {\\n      \"items\": {\\n        \"properties\": {\\n          \"loc\": {\\n            \"items\": {},\\n            \"type\": \"array\",\\n            \"title\": \"Location\"\\n          },\\n          \"msg\": {\\n            \"type\": \"string\",\\n            \"title\": \"Message\"\\n          },\\n          \"type\": {\\n            \"type\": \"string\",\\n            \"title\": \"Error Type\"\\n          }\\n        },\\n        \"type\": \"object\",\\n        \"required\": [\\n          \"loc\",\\n          \"msg\",\\n          \"type\"\\n        ],\\n        \"title\": \"ValidationError\"\\n      },\\n      \"type\": \"array\",\\n      \"title\": \"Detail\"\\n    }\\n  },\\n  \"type\": \"object\",\\n  \"title\": \"HTTPValidationError\"\\n}\\n```', args_schema={'type': 'object', 'properties': {'query': {'type': 'string', 'title': 'query'}}, 'title': 'wiki_searchArguments', 'required': ['query']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x0000026A4FC23D80>),\n",
       " StructuredTool(name='arxiv_search', description='Do Search\\n\\n### Responses:\\n\\n**200**: Successful Response (Success Response)\\nContent-Type: application/json\\n\\n**Output Schema:**\\n```json\\n{}\\n```\\n**422**: Validation Error\\nContent-Type: application/json\\n\\n**Example Response:**\\n```json\\n{\\n  \"detail\": [\\n    {\\n      \"loc\": [],\\n      \"msg\": \"Message\",\\n      \"type\": \"Error Type\"\\n    }\\n  ]\\n}\\n```\\n\\n**Output Schema:**\\n```json\\n{\\n  \"properties\": {\\n    \"detail\": {\\n      \"items\": {\\n        \"properties\": {\\n          \"loc\": {\\n            \"items\": {},\\n            \"type\": \"array\",\\n            \"title\": \"Location\"\\n          },\\n          \"msg\": {\\n            \"type\": \"string\",\\n            \"title\": \"Message\"\\n          },\\n          \"type\": {\\n            \"type\": \"string\",\\n            \"title\": \"Error Type\"\\n          }\\n        },\\n        \"type\": \"object\",\\n        \"required\": [\\n          \"loc\",\\n          \"msg\",\\n          \"type\"\\n        ],\\n        \"title\": \"ValidationError\"\\n      },\\n      \"type\": \"array\",\\n      \"title\": \"Detail\"\\n    }\\n  },\\n  \"type\": \"object\",\\n  \"title\": \"HTTPValidationError\"\\n}\\n```', args_schema={'type': 'object', 'properties': {'query': {'type': 'string', 'title': 'query'}}, 'title': 'arxiv_searchArguments', 'required': ['query']}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x0000026A4FC23EC0>)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel_tools = tools[:]\n",
    "sel_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7dac4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='knowledge distillation regarding large language models?', additional_kwargs={}, response_metadata={}, id='afaa2338-936c-4d58-9b6e-6931a3d5c42e'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking about knowledge distillation in the context of large language models. Let me start by recalling what knowledge distillation is. From what I remember, it\\'s a technique where a smaller model, called the student model, is trained to mimic the behavior of a larger, more complex model known as the teacher model. The idea is to transfer the knowledge from the teacher to the student so that the student can achieve similar performance but with lower computational costs.\\n\\nNow, applying this to large language models (LLMs), the teacher model would typically be a massive LLM like GPT-3 or BERT, and the student model would be a more compact version, such as DistilBERT. The user might be interested in how exactly this process works for LLMs, the methods used, the challenges involved, or the benefits and limitations.\\n\\nI need to check if there are existing functions I can use to get more detailed information. The available functions are web_search, wiki_search, and arxiv_search. Since the user is asking for technical details about knowledge distillation in LLMs, arxiv_search might be the best choice because it can retrieve academic papers on the topic. Web_search could provide general information, and wiki_search might have an overview, but for in-depth technical discussions, arxiv would be more appropriate.\\n\\nLet me structure the query for arxiv_search. The user\\'s question is \"knowledge distillation regarding large language models?\" so the search query should be something like \"knowledge distillation in large language models\". That should fetch relevant research papers. If the results from arxiv_search are sufficient, I can summarize the key points from those papers. If not, I might need to use web_search to get more general information.\\n\\nWait, I should also consider that the user might want to know about recent advancements, so using arxiv_search with the right keywords is crucial. The response should include how knowledge distillation is applied, techniques like using soft labels, temperature scaling, attention transfer, etc. Also, challenges like preserving accuracy while reducing model size, computational efficiency during training, and the trade-offs involved.\\n\\nI should make sure that after retrieving the information, the answer is concise and covers the main aspects: definition, methods, applications, benefits, and challenges. If the tool calls don\\'t return enough data, I\\'ll have to inform the user that I can\\'t provide the details. But given that arxiv likely has several papers on this, I\\'m hopeful for a good response.\\n', 'tool_calls': [{'id': '3yyk2wmwc', 'function': {'arguments': '{\"query\":\"knowledge distillation in large language models\"}', 'name': 'arxiv_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 536, 'prompt_tokens': 1280, 'total_tokens': 1816, 'completion_time': 1.279720287, 'prompt_time': 0.070499554, 'queue_time': 0.206680771, 'total_time': 1.350219841}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--086e5ce5-c815-404f-8c17-54f43e328b9c-0', tool_calls=[{'name': 'arxiv_search', 'args': {'query': 'knowledge distillation in large language models'}, 'id': '3yyk2wmwc', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1280, 'output_tokens': 536, 'total_tokens': 1816}),\n",
       "  ToolMessage(content='{\\n  \"results\": [\\n    {\\n      \"Published\": \"2023-03-10\",\\n      \"Title\": \"Robust Knowledge Distillation from RNN-T Models With Noisy Training Labels Using Full-Sum Loss\",\\n      \"Authors\": \"Mohammad Zeineldeen, Kartik Audhkhasi, Murali Karthick Baskar, Bhuvana Ramabhadran\",\\n      \"Summary\": \"This work studies knowledge distillation (KD) and addresses its constraints for recurrent neural network transducer (RNN-T) models. In hard distillation, a teacher model transcribes large amounts of unlabelled speech to train a student model. Soft distillation is another popular KD method that distills the output logits of the teacher model. Due to the nature of RNN-T alignments, applying soft distillation between RNN-T architectures having different posterior distributions is challenging. In addition, bad teachers having high word-error-rate (WER) reduce the efficacy of KD. We investigate how to effectively distill knowledge from variable quality ASR teachers, which has not been studied before to the best of our knowledge. We show that a sequence-level KD, full-sum distillation, outperforms other distillation methods for RNN-T models, especially for bad teachers. We also propose a variant of full-sum distillation that distills the sequence discriminative knowledge of the teacher leading to further improvement in WER. We conduct experiments on public datasets namely SpeechStew and LibriSpeech, and on in-house production data.\"\\n    },\\n    {\\n      \"Published\": \"2023-06-11\",\\n      \"Title\": \"GKD: A General Knowledge Distillation Framework for Large-scale Pre-trained Language Model\",\\n      \"Authors\": \"Shicheng Tan, Weng Lam Tam, Yuanchun Wang, Wenwen Gong, Yang Yang, Hongyin Tang, Keqing He, Jiahao Liu, Jingang Wang, Shu Zhao, Peng Zhang, Jie Tang\",\\n      \"Summary\": \"Currently, the reduction in the parameter scale of large-scale pre-trained language models (PLMs) through knowledge distillation has greatly facilitated their widespread deployment on various devices. However, the deployment of knowledge distillation systems faces great challenges in real-world industrial-strength applications, which require the use of complex distillation methods on even larger-scale PLMs (over 10B), limited by memory on GPUs and the switching of methods. To overcome these challenges, we propose GKD, a general knowledge distillation framework that supports distillation on larger-scale PLMs using various distillation methods. With GKD, developers can build larger distillation models on memory-limited GPUs and easily switch and combine different distillation methods within a single framework. Experimental results show that GKD can support the distillation of at least 100B-scale PLMs and 25 mainstream methods on 8 NVIDIA A100 (40GB) GPUs.\"\\n    },\\n    {\\n      \"Published\": \"2025-02-17\",\\n      \"Title\": \"Warmup-Distill: Bridge the Distribution Mismatch between Teacher and Student before Knowledge Distillation\",\\n      \"Authors\": \"Zengkui Sun, Yijin Liu, Fandong Meng, Yufeng Chen, Jinan Xu, Jie Zhou\",\\n      \"Summary\": \"The widespread deployment of Large Language Models (LLMs) is hindered by the high computational demands, making knowledge distillation (KD) crucial for developing compact smaller ones. However, the conventional KD methods endure the distribution mismatch issue between the teacher and student models, leading to the poor performance of distillation. For instance, the widely-used KL-based methods suffer the mode-averaging and mode-collapsing problems, since the mismatched probabitliy distribution between both models. Previous studies mainly optimize this issue via different distance calculations towards the distribution of both models. Unfortunately, the distribution mismatch issue still exists in the early stage of the distillation. Hence, to reduce the impact of distribution mismatch, we propose a simple yet efficient method, named Warmup-Distill, which aligns the distillation of the student to that of the teacher in advance of distillation. Specifically, we first detect the distribution of the student model in practical scenarios with its internal knowledge, and then modify the knowledge with low probability via the teacher as the c\"\\n    }\\n  ]\\n}', name='arxiv_search', id='eba32a14-6edb-41ad-b1e1-05b6db3448ea', tool_call_id='3yyk2wmwc'),\n",
       "  AIMessage(content='Knowledge distillation (KD) in large language models (LLMs) focuses on transferring knowledge from large, complex models (teachers) to smaller, more efficient student models. Recent research highlights two key approaches:\\n\\n1. **GKD Framework (2023)**:  \\n   A general KD framework for large-scale pre-trained language models. It enables distillation of models with over 100B parameters using memory-efficient techniques, supporting 25+ distillation methods on limited GPU resources. This addresses real-world deployment challenges for industrial-scale LLMs.\\n\\n2. **Warmup-Distill (2025)**:  \\n   Addresses distribution mismatch between teacher and student models, a critical issue in KD. Traditional KL-divergence methods suffer from \"mode-averaging\" and \"mode-collapsing.\" Warmup-Distill introduces a pre-distillation phase to align student and teacher distributions, improving distillation effectiveness by mitigating early-stage mismatches.\\n\\nThese advancements aim to reduce computational costs while maintaining performance, making LLMs deployable on resource-constrained devices. For speech models (e.g., RNN-T), similar principles apply but face unique challenges like alignment mismatches and noisy labels.', additional_kwargs={'reasoning_content': \"Okay, the user is asking about knowledge distillation regarding large language models. Let me look at the tool responses from the arXiv search.\\n\\nFirst, there's a 2023 paper on robust knowledge distillation for RNN-T models with noisy labels. It talks about both hard and soft distillation methods. The key point here is addressing the challenges with different posterior distributions in RNN-T models and using full-sum loss to handle bad teachers. That's useful but specific to speech models, not LLMs.\\n\\nNext, a 2023 paper introduces GKD, a general framework for distilling large pre-trained language models. It mentions handling up to 100B parameters on limited GPU memory and supporting various distillation methods. This seems directly relevant to LLMs and their deployment challenges.\\n\\nThe third paper from 2025 discusses Warmup-Distill, which addresses distribution mismatch between teacher and student models. It points out issues with KL-based methods and proposes a warm-up phase to align distributions before distillation. This is important for LLMs as distribution mismatch is a common problem.\\n\\nPutting this together, the user wants to know about KD in LLMs. The GKD framework and Warmup-Distill are the most relevant. I should explain these methods, their purposes, and how they solve specific problems in distilling LLMs. Also, mention the challenges like computational demands and distribution mismatch. Make sure to highlight the recent advancements from these papers.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 555, 'prompt_tokens': 2225, 'total_tokens': 2780, 'completion_time': 1.284478541, 'prompt_time': 0.100823978, 'queue_time': 0.213427747, 'total_time': 1.3853025190000001, 'prompt_tokens_details': {'cached_tokens': 512}}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--7ab39fd8-1938-4081-8f7a-313e843808b1-0', usage_metadata={'input_tokens': 2225, 'output_tokens': 555, 'total_tokens': 2780})]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Example of how to run it (assuming the rest of the code is defined)\n",
    "async def run_example():\n",
    "    try:\n",
    "        query = \"knowledge distillation regarding large language models?\"\n",
    "        result = await main(tools=sel_tools, query=query)\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "result = asyncio.run(run_example())\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51b886e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, the user asked about \"knowledge distillation.\" I need to figure out which tool to use here. The available tools are web_search, wiki_search, and arxiv_search. \n",
      "\n",
      "First, I should consider what knowledge distillation is. It's a machine learning technique where a smaller model, called the student model, is trained to mimic the behavior of a larger, more complex model, known as the teacher model. The goal is to transfer the knowledge from the teacher to the student so that the student can perform well while being more efficient.\n",
      "\n",
      "Now, the user might be looking for a general explanation, or they might want recent research papers on the topic. Since the tools include arxiv_search, which is good for academic papers, and wiki_search for encyclopedic info, and web_search for general information.\n",
      "\n",
      "If I use arxiv_search, I can find recent studies or detailed papers on knowledge distillation. The user might benefit from knowing the latest advancements. Alternatively, wiki_search could provide a concise overview. But if the user wants a comprehensive answer, combining both might be best. However, since the user just asked for an answer based on the tool results, I should choose the most appropriate tool.\n",
      "\n",
      "Given that knowledge distillation is a technical topic, arxiv_search might give the most relevant and up-to-date information. Let me call arxiv_search with the query \"knowledge distillation\" to retrieve recent papers.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result[\"messages\"][1].additional_kwargs[\"reasoning_content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a1ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"messages\"][1].additional_kwargs[\"tool_calls\"][0][\"function\"][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a54049",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"messages\"][2].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1300a315",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f5b6db",
   "metadata": {},
   "source": [
    "# Langraph Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "574564f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAANgAAAD5CAIAAADKsmwpAAAQAElEQVR4nOydB2AURdvHZ/dKkkvvCSkkISSBUCIGEEU6iNIVpQsigvBRFFBUQKoKAoooRVQEVECkgygvIkUCoQqGFloaIb0nl+Tudvd77jY5juQucAm7t3s3v5f33Jud3ezt/ndmnmdmnpEyDIMwGEsjRRiMAMBCxAgCLESMIMBCxAgCLESMIMBCxAgCLMSa5KSpLscVluRq1GpaVUFRKkRIEENpd0mkSEMxhHaTQAwipYjW6NLtEFWp3SAliNbl1B5CM4gh9HkIEmkdZTpfmT6R0aUjuupPa/NUb0tkDKUmHlwWm02fmag6FYudgpRICQcnqV+YfWx3NyRCCOxHZEm/WfH3juySAjWloUkJoXCW2iskcHM0lbReXhIZodHoNIiQTogErdFuS+WkRqUViD4FzkDDjaUfpBAkoZWmDlJK0poqxZEkovVClBAMVZVHYkdQlQ8eTdXhEoQo9nsNIUo0KkatoiuVtFrDyO3JRiH2fd/yR+IBCxFlpWr2f3evUqlx9ZLHPO/eoqMzEjUUOroz905CaWU55RtsP3hqABIDti7EnasyMlOVwVGO/cb5IesiP1P7gilLqK6DfaPaOSFhY9NC/G72XYWjdMRHwch6uXa69MTu7MAIRV9hv2m2K8Qf5iYFNHHsPcYH2QDfz0lu28u9dSdXJFRsVIjffnAnPMal+1BvZDN8PyfJK9B+4NsCtWBIZHtsmJccFOFoUyoExi0OzU2rOLk7DwkSmxPi3nUZ8PnSWGszTR6HcQtCwUWKBFkF2pgQKXTvVtnYBSHINpGiwCYOG+YlIeFhW0Lc/FmqV6ADsmEGTGxUoaRvXixFAsO2hFicrxoyTRwOXu7wD7X/Z08OEhg2JMQD32VAxx3Pv/iDDz7Yu3cvMp+ePXump6cjDhg4IQB6ApHAsCEhZiRVBEcpEL9cu3YNmU9GRkZBQQHiBkKKZHLyyFZhFYo2JERVJR3bzRNxQ1xc3IQJEzp27Dhw4MB58+bl5uZCYmxs7P379xctWtSlSxf4Wlpaum7dutGjR7PZvvzyy4qKCvbw7t27b9269a233oJDjh8/3q9fP0gcMGDAjBkzEAe4+cjuJymRkLAVId75T0mSyM1Xgjjgxo0b06ZNa9u27Y4dO95///2bN2/Onz8f6dQJn3Pnzj127BhsbNu2bePGjaNGjVq5ciXkP3z48Pr169kzyGSy3bt3R0ZGrl69+rnnnoMMkAh1+ooVKxAH+DZWVAisdraV8YiZSeVSGYG44dKlS/b29mPHjiVJ0s/Pr3nz5rdv366dbeTIkVDyhYaGsl8vX7586tSpqVOnwjZBEK6urjNnzkS84Bskv3oaC9ESlJfShIQrIcbExEAl+84777Rv375Tp05BQUFQw9bOBsXe6dOnoeKGIlOj0Y6M9fDw0O8F+SK+8PCW07SwhGgrVTPN0Nz1KERFRa1atcrb2/vrr78eNGjQpEmToLSrnQ32Ql0MGfbs2XP+/Pk33njDcK9cLke8IYWXUliP3laEaO8opSkO+7aeffZZaAvu378fWodFRUVQOrJlnh6GYXbu3DlkyBAQIlTfkFJSUoIsRGF2BeKqeqgntiJE3wA7ijMhXrhwAVp7sAGFYt++fcHUBZGBC8Ywj1qtLi8v9/GpGnWmUqlOnDiBLER2WqVEKiwl2ooQI9s5adS0qpwTLUJFDMbyrl27wPl35coVsI5Bkf7+/nZ2dqC8+Ph4qIjBjgkJCdm3b9+9e/cKCwsXLlwILcvi4uKysrLaJ4Sc8AlmNZwNcUBGUrncDlfNFkJmR8YfykccAOYwVLjLly+H7pDx48c7OjpCW1Aq1RqCYEqfO3cOykgoDj/99FMwrgcPHgxOxHbt2k2ePBm+9ujRA3yNNU4YGBgIrkRwOkKzEnFAfmalX5Cw+txtaGDstmVpZSWaNxeGIpvn63dvj1sY5uAsoGLIhkrEXqN8lSUaZPP8sTHTzoEUlAqRTU2w9/CTy+0lu1enD/o/4wNwKIoCh7PRXWBbgBcQ3M61d4WFhW3YsAFxw0YdRnc5OTlBn6HRXdHR0dBDg0yQfK3sqa7uSGDY1pyV9FuVu9emTf4i3FSG2s01Fnjk8OCN7oK2oN4WfuKU6DC6C1zo0MQ0ugveGbCWjO46/Ev23YSSCUuaIIFhc5Onti5NAz/OSKueQloHa2befnlisF8THp3nj4fNzVkZNiuotFhz5g9OzGeB8+P85ICmCgGqENnmLL63l4SdP5JflGNbVcGWpfekcmLAhEZIkNjuBPvVM+70GurftC3fQ2UtwsZFqV6N5H3fFO7cRZsOObLm/bsBIQ4DJokpalY92DAv2U4hGTErCAkYWw/CtHFBSrlS0+FF75guLsjq2LU6IytJ2eQp514jhB5ZBYelQ3F78xJOFcFGUITDi6/7kzIkdu5cVp47nJeXqXJykY7+qLEonMVYiFUc35GbeKFYVUFLZISDo8TJXaZwlJFSSq0ycn8kMpJS1xxYqvV2Ew+icRqmE5IHkTkNEqvixhoc/iBiLAtJapMpw3PqDmQe7iGSyghKQ5SXaJQlVHmZhqaRq6es8yvegU1FM4kbC7Emcfvy02+XKUtpjYqhaYbSGBMiCeKomch2u9S+nTqFMQxd1StD0zT00GgVRiDDUdJGhWgY8FgPScKFPdTHI5UjiYSEjjtXT3nTGKfItkKPhlgbLES+mTJlyvDhwzt06IAwBuBg7nyj0WjYEWIYQ/Ad4RssRKPgO8I3WIhGwXeEb9RqtUwmfhfRkwYLkW9wiWgUfEf4BgvRKPiO8A0WolHwHeEbECJuI9YGC5FvcIloFHxH+AYL0Sj4jvANFqJR8B3hGyxEo+A7wjfg0MZCrA2+I7zCMAxN0xIJJxGURQ0WIq/getkU+KbwChaiKfBN4RU84sEUWIi8gktEU+CbwitYiKbAN4VXsBBNgW8Kr2AhmgLfFF7BxoopsBB5BZeIpsA3hW9MxXK1cbAQeQU69zIzMxGmFliIvAL1co2l0TAsWIi8goVoCixEXsFCNAUWIq9gIZoCC5FXsBBNgYXIK1iIpsBC5BUsRFNgIfIKFqIpsBB5BYRIURTC1MIWV56yLNC5grVYGyxEvsG1s1GwEPkGC9EouI3IN1iIRsFC5BssRKNgIfINFqJRsBD5BgvRKHjlKZ6IiYkhySrTEO45bMNn3759Fy5ciDDYauaNVq1aIe0yelrAlUgQhL+//8iRIxFGBxYiT7z++uuOjo6GKa1bt46IiEAYHViIPNGjRw9D2Xl6eg4bNgxhqsFC5I8xY8a4uLiw21FRUS1btkSYarAQ+eP555+PjIyEDVdX1xEjRiCMAdZsNeekqBLii8rLKLp6lW+ZnNCvSE/KEK2uyqk1ZwmCpqp3SQiaZtjlumEXQZJU9frzNXJqF/aG/zCEfsFwOJbRxoVF+gyE1kyuus+FhYUJV684OSratGljuEY4SWoXAqcfXv2+xt96kC7VrThea+VyUkowFDL6QKUyiUZtfKSFTC5x95a3f8kdWRSrFeKmRanKEo3cjtSoaP1C8RIZovTikzK0pmodeEJbMTxYZJ6QIEYrRO3XGuvSa3Mytb8y2tXnq1O0X5nqFebZ/xpkoBlaJzvCcF36Gqc1SDTygODyQIW1n5suHbITqBaGP7YGMnsStE5rmLCWTr1G+SALYZ1C/OHjJBdP+95j/BHm8SjJpvZvSGvV0aVDHw9kCaxQiD/OT/X2V3Qe6oUwZvLr8uTINi7PD7KAFq3NWEk8X1FZQWEV1o+IGNfEc0XIElidEC8WOCiwK6CePNXVXaW2TA1pbc+svJTG4/DrjwSBf6C81AJ30NpG32gogEaYhmCJNxkPA8MIAixEjCCwNiFqO0IIhGkQpAUsB2szVmhjXQ4YM2CQRe4grpoxD0NgIT4JJCTbcYwRGdYmRHDdMNh700BIC7Syrc5YwaZKw6Fx1dxgaGyqNBxLvMtW10aUWMT5YF1Y4l22ujYihWjcRmwgligRcelRHwa+3GPzT9/Dxs5d23r0ao945+ixw127xxYWFtSdTX+dZoKNlQYDVbNEgu2VhoH9iA0HqmaKwvZKA2CwsWIhKIr6bccvmzavh+3mzVqOGT2hZcsY2E5KurNv/46L/57LzLwf0jjspZcGDug/GNULqCLhtPfupe7ctdXNzb3DM89P/r+Zny6ZGxd3PCio8cjhY3v16sPmhBS4kpTUJFdXt/DwyGlTZvn6+rG71n371f8O/65wUHTv3jswsLH+5BqN5ocNa+LPnMzOzmzRImbQgNeeeaYjqjeEZYwVa2sjQr1sbtW8/ruv9+79beGC5XM++sTb23fWh1NSU5MhffWaFefOnZ42ddaSz1aBCr9atTT+TByqFzKZbNuvm4KDQw79cWrcm//3x5/73p0+vnu33ocPxXft0nPZikUlpSWQ7fyFMx/Pfw9EuX3bwXlzl2RlZaxctYQ9w959O/bu+w0uZs2azf7+AZt/+k5/8lVff75j55ZBA4ds+WV/507d5y14//iJI6ghWMKhbW1ChHrZrKq5uKR4+28/Dx06um3sM88913nmjDmxTz+Tl58Lu+bO/WzZsjVtnmr7VEwslIWREc3OnjuF6kvT8Kj+/V6Ry+VdOveEr9HRrUCCUqm0a5deUKSlpiRB4oYf13Z6vtvgV4ZDcQgZJk2cHh9/8kbiNdi1a/e2zp16gM5cnF16v9AProo9bWVl5aH/HRg+bAyc3NXF9aUXB4C+DWVaH7BDu+HAy2xWXzOrgKioaPYrKGPhgmVV+xhm165tZ87GpaWlsAlQFKH6AsUhu8GGYgoJacJ+dXBQwGdJSTF83r17C6SmPyQyojl83rhxFd6B9PS0F3v31++KiGjGbty8eV2lUrWN7aDfFdP6aShxi4qLQJdIPFibEBkz+5rLlGXwaW9nXyOdpukPPpqmVqveGjc5JibW2cl5yrQ3UQMgHu57JGu53UtLS6F4szO4EoVCq1GlsgyAhiwrWRZ7e4fqo7R1eu1rK8jPw0K0JIyZzRuFQ9XDrpF+89YNKIqWL1vzdJt2bAo8cm8vDgMh2NtrJVhRUa5PYV8STw8vKEQlEkllZYV+V3m5kt3w9PKGzxnTZwcEBBmezcfHD9UTBlvNTwCpFEmkZtzIsLCmUB1f/u9is2YtkC6W64ez3+nauaebu3aSuV55ycl34V9odX3KBXAZUAVfvfqfPoXdDmvSFEpTX19/7ddXq3aBjcxuBAYE29nZwQY0ZNmUgoJ8+BVsaVovCIuMcbc2Y0WjQZTGjLY2FDY9e7wEVjO0q/69dP7rb5ZduHAGRAn+GlDGr9t/AmsGjGhIB2smMysDcQlYvifjju3cuRX+KFzMmrVfgFHSNFwbQAwsmxP//A0dKrC9dduma9cS2ENAcOAYAuskIeESNBbBXp75/qSVXy1BDQEbKw2nHoMewCcCT27FF59AOyy8ScTC+ctYw2L2R4vBpTdgxYwrnQAAEABJREFUYDeo9WZ/uAhM6bkfzxz9xuBNP+5A3ACOm5zc7F9/++mbNSvAfQj2O7RQ2V0jR7wJHXrwPixc9CG4OcGg/uTTOWy4mKFDXm/SJGLLto0XL551dHSKbt5qxow5SGxYW+ybX5alKouooe+FIky92Djv9riFoQ4uEsQv1lYi6po3uK+5ARB4GNiTwCLlO7TPPpr9jqm9P/+0BxzUSETgqQINxyKFITTa1q/fYmqvyFSIsLHyJCDB1UFY4D76+zVCmAZgdVUzsirbi3+0xiuBq+YGQzM40kOD0HZF4oGxDQeP0BYpeIQ2phbYam44UvMHxmJqgq3mhqMxc2AsphZ49M2TgCBqjvzDmAmBe1aeACSJIz2IEmysYASBtQnR3kFCVWAh1h/tsGI530NvkPUNjPXwlqsrEaZ+5N1XkSTh4ID4x9qE2HWId6VKo5tRhDGbc4dynd1lyBJYYcM+orXLvtVJCGMmty5V5N2vGPFBELIE1rlM7u3/lEe2ZPoEOwZFOECnX0OsFwb8QQ8fXiM4TO0MegiD/IxBosnLMRF3pmbyw6eo2TlcnZtkVwh4cBChHxFieAJSisry6JTrpcoS1fjPwpCFsNqFwxMvKM8ezFWWUWoVZeonEkTVaBMjz1r/dAnGcI6q7pCHlMTmNDpU4IEQiar1vPUpRv9W1al0+RjTUoNmnOFa94Z7ddtV1117yXP9jG/wcBkupi6VSrz87F+easnlra1WiI/Pl19+CZ/vvvsu4oVp06YNGTLk2WefRRywfft2+DkymczR0dHb2zskJCQmJqaZDiRsbFqICQkJLVu2vHr1anR0NOKLRYsW9e/fv3Xr1ogbQOW3bt0iSZLWFXpQMLq6ujo7O+/duxcJGBvthYDXb9KkSZmZmUgbD4k/FSJtbKe53KkQ6NOnDxs0gtQBQiwuLk5LS0PCxhZLxLy8PHg8t2/fbteuHeIdUL+7uzsbnoELysvLR40alZycrE9RKBQnTpxAwsa2SsTKysoJEybAo/Lw8LCICoFZs2bBO4A4w8HBoWfPnvqRH1BBL168GAke2xLi77//Pn78+MDAQGQ5fH19GxCY5rF4+eWX/fy0QZhAhRcvXtyzZ8/atWuRsLEJIRYVFc2cORPpntDTTz+NLMrnn38eGsptIAqwl7t06QIbjRpp5xZ+8cUXcrl8ypQpSMDYhBAXLlz45psNim74BElPT9doNIhjZsyYAS3RAwcOsF/h5w8fPrxbt2737t1DgsSajRUwC44dOzZ06FAkJMB3s27dOras4hkwn19//fWJEye+8MILSGBYbYmoVCrHjRvXqVMnJDCg9eZgkfEtCLm4uEB7ESxo1ocvKKywRMzIyCgpKQkICGCjVWNqs2XLlr///vv77+uxKBVXWFuJeP36ddYuFqwKU1NTaUsvFwjtRbBdOnTocPPmTSQMrEeI9+/fRzpP4f79+7n2jzSEkSNHVlRUIEsDvTtQR8+fPx8qayQArESIIL558+bBBvTxI2EDZgo4U5AAkMlkUEdfuXLlk08+QZZG9G3EwsJCNze3Xbt2gY8QYerF7t27d+zYsXnzZonEArNVWMQtxO+++w7u3dixY5F4SElJady4MRIYiYmJo0eP/vbbbzkdkFEHYq2aoS2Yl5cHrX5xqRBahyNGjEDCIzIyMj4+ftWqVVu3bkWWQJRCXL9+PdieUCNPmDABiQqof8LCLDYc/5H88MMPYPPNmWOBRQnEJ8SDBw/CZ9OmTS3YoKk34MqGphgSMNA32LFjR2hwgy8W8YiY2ojwCKGHqqioyNVVTKvMGUJRFPjbLTv853GACgeajEuWLGnfvj3iBdGUiLNmzWIHHotXhUBOTs7bb7+NBE9wcPDRo0fhzd+wYQPiBREIMS5Ou1z39OnTX3vtNSRyCIIQoMlsitWrV4NRCJU14h5BC1Gj0fTv358dVe/r64vED/wKeLpIPEycOBEeQe/evbOzsxGXCLeNmJmZCT0Q4O+wyIgpjlCpVLm5uaL7RXDN0DpfunRpy5YtETcItESErqeEhAQPDw9rUiHSzWyCrkjRdSJ4eXmBswK8jFlZWYgbBCpEKA7BOkZWB1haa9asgZ5xiw/AqQeXLl3iroGEIz1YhrS0NJIkAwICkEi4devWxx9/zF2/i0BLREoHsl6CgoImTZpUVlaGRAIIEToREGcIVIhQf/3yyy/Iqtm7d29iYmJpaSkSA3fu3AkPD0ecIVAhchcIQVC0adMmPT391KlTSPBAicipEAUaQ3v8+PHINoiMjJw6dWqrVq2cnJyQgLl9+7YtlohW30Y0BNwixcXFgp1xjHQRCqCLxcfHB3GGQIUIvZzr1q1DNgO4SwsKCiw1FvCRcF0cIiG3EW1tASnotLh//z54vJHw4EGI2I8oLJRK5Y0bN8CIQUJi8eLFLVq0GDhwIOIM3EYUFgqFwt7e/tNPP0VCAkpETp2ISLBC3L1797Jly5BN0rx586ioKCQkbLeNKJfLbXmRUXZq7L59+5AAgN5Ib29vrj27AhVi//79Z82ahWwbMF/YsI6WhevOPRaBCpGmaR6CCAqc0NDQMWPGIEvDQ72MBCvEw4cPsyFEbBywVVH1SjCWwqaFKJPJSLwAeDVQLlpwyhU/VTP2I4qDkpISZ2dnaK5IpdrhAb1794Z3df/+/YhjoGevW7du7Pw1TsFtRHEAKkS62e9lZWV9+/bNzc2FLsFDhw4hjuHBg8giUCHGx8fzM4tRXHz11Vcvvvgiu2AWdAYeOXIEcQzXo7/0CLeNaMt+RFMMGTIE+gDZbbg/iYmJrCi5gx9LBQlWiG3btl25ciXCGDB8+PA7d+4YpmRlZR0/fhxxCT+WChKsEMGEUqvVCGMAtJsDAwMNQ0+pVCrwcyEu4XqGgB6BjtBOSEiAEpG3wCuiYNu2bRcvXjx37tyZM2dKS0szMjJ8HdswxR6Hd970b+Snz6ZdO1y3uDlhsN65fs16/dr1+pXSiVoLmetTwVQP8eqcdg2loWLTWeuCJAmfQDuvgEeHahaW+2bcuHFwi+GS4BOsQh8fHygGoFX0119/IYwBPy64qyymCBJRWtdCleCqlrInWAnSDCK1cmT36jRUvaQ9ocsMt5l4cJR2S5u9SmwGmjOULKohRd0hD77VyiCVwZ8hZHKi1XPu7V9yQ6YRVonYvHnzn3/+We/KZkfPQ487whiw/sO73kEOgyf5I0HEhH80V08VJcTl+4fYBTc3udKRsNqII0eOrB070FLr2QqT9R/dbRbr2WOEaFQIRD/rOuS90N83ZZz/n8noHcISItTFffr0MUzx9PQUZtBpi/DHpmypTBLTQ5QRIpu3d7t0PM/UXsFZzcOGDTMsFGNiYiIiIhBGR1ZqhZe/PRInbbp7qNWMykQ8AcEJ0cXFpV+/fmyPqoeHx6hRoxCmGnWlRmov4rEgNI1ys4zPDhPir9IXii10IEw1GhWjUYnYvcpQDE0Z7zBrkNWsKkdxB3JyUlUlRWoa/gaN4LNGHnAxMLThV4Khdf4BvdfAADCX2XBtXUI+owIpqUS69v27pISocVr9sfqzgb+KphlTfxeKVxIcwVLGwUUaEuXY/kV3hLEE2idkwl1YTyH+uSkrNVGprqBICSmVSQm5RG4nASkwtTyeNQT3QEOEERemXoiGR+nVZnCSqmP12UiCoGuczcATJpVKaERQFZqCLE1eRsH5I/ng2Yp+xvW5/p5IVBBar6CIu+AJhExdvtlC/OPHrLtXSyUSwtnbOSDaA4kQWo1SE7IS4oovnSh4upv7My+JRo7MQ/5jUWLq8s0T4rcfJkF917ilv5OPiKN1kTIU0kYb+TT7TtGFI/lXTpeMWxSCxIKYBzIzpi//cY2VtBsV30y/7eztGNUlWNQqNMSniWt0j1BoPq6ZeQeJAULUFXNV1Wz8FzyWEAtz1HvXpzfvFtqomcgaVY9DWPtGflHeq0WhRe1TFLEU6zBWHi3Eu5eVWz5Pa9EzhBTf0nePi0eAY2jbYOFrkTFmDooLxoTiHi3EPzZlhLcT+tpxDUfhQnqHuK+bdRdhuIQwsZrCI4T47UdJzj6OcifrLQwNgCajRC6B4h9huKEO901dQjy+I5fWMMGtbWgUVtNnA/MzKzOTVUiQgEtV1FN5mKr/G6EuIV45XegVYnOdEI7uDvu/T0fChBF3G7E+JWLc3jw4yDvUBQmSSwl/zZzbvrSsAD1pQmP9KpVUUa4QozMyDOJfhwNf7rH5p+/Rk6A+JeKNCyUKd7GOOGogEhl5aHMGEh7V007MYMHCDw7+sRcJg/r4EctLNX7hVug1fBxcfJzzMiuR8GAnnZh1SGLiNSQYzB70cONMGbSLHVxliBuSU//739Hv0+5dc3J0bxbZsVfXcfb2jpAeF//b4eMbJo5du3nbh1nZd/19wzs9O6xtm77sUQf+/Pr85YN2csVTrV7w8QpGnOEX7pp/T5BLUprZs9K1eyx8Llu+aO26L/fvPYa0q7Af37R5fUpqkqurW3h45LQps3x9q2YA1rGLBRqoO3dtPXToQNq9lMbBobGxz4x9Y6Lh9NbHuHwzS8Tk62USKVcum9y8tG83TlGrKyeP/3708KUZWbfWbphI6aajSaSy8vKSPb8vf23gR8sWxrdq0W37nsUFhdpgBqfO7jx1dsfLfd6bNuFHT/dGh4/+gDgDnDgkSSSeF9ziZLrBN2YMIf3zoDZ40nsz57IqPH/hzMfz3+vVq8/2bQfnzV2SlZWxctUSNmcdu/Ts2rXt5182DH5l+LYtB/r1e+X3g3u2/boZmUMdlpbxX1Wcr+KuH+Xi5T+lEtmYYUt9vUP8fMJeHTA7PSPxyvXj7F6KUvfsOq5xUEvwU8TG9IG3MD3jJqSfPL29VXR3kKZC4QJlZHhYLOISUkpkpwqudma01H993Q0/ru30fDdQEpR50dGtJk2cHh9/8oau7q5jl57L/12MjGz+wgt93dzc+/YZtPqbje3bPYfMgTA9Ndq4EDUamjDnzTMLqJeDAps7OlbNcvVw9/f0CExKuaTPEBwQzW4oHLQ2e3lFCdz+3Pw0X59QfZ7ARtyGOycYpCwX3FjoBnY13717KyoqWv81MqI5fN64cbXuXXpatGh94cKZz5ct/PPQ/qLiooBGgeHh5k0nqsNqNt5GJAiGu3WtyytK09KvgfPFMLG4JM/gr9e82RWVZTRN2dkp9ClyuQPiEoYkJMLrXG+I+6a0tLSystLO7oEnRKHQ3k+lsqyOXYZngPJSoXCMO3V86ecLpFJply49J7w11cvLjP4ObXlImDNVQCaXkoir8ITOzp6hjWNe6PbQso+OjnVNkbS3cyRJiVpdoU+pVCkRp9CMvYPgJvQ0ZBiYvb1WZxUVD+Yulel05unhVccuwzOQJAk1MvxLTr578eLZjZvXl5WVfrrYvLDKBDLHanbzlOVmcNXN1ci36YXLB8NCntJHdMjMvuvtWZcVDGWku5t/cuI1YLIAAAVXSURBVGpC5+o2yfVEbmOY0jTjF8ptoVsfCO2sCFQvoAyLjGh29ep/+hR2O6xJ0zp2GZ4B7OWIiGahoU1CQsLgX0lpye8HdyNzqKM0N/7SN2ntRKm5qpzBI0PT9L4/vlSpKrJzUg4c+mbFN8Mzsm7XfVTrFj0Srh2FDhXY/vufzSn3riDOUJVSUCKGt1YggQENphrTd+rGzs7O29vn/Pn4fy+d12g0gwYOORl3bOfOrcUlxZCyZu0XbZ5q2zQ8EnLWsUvPkb//BMv61KkT0EAEU+afk3+3iG6NzMWsNmJoSwW8fCU5Fc7eT75zBczemZO3HP3np5XrRmfnJAcHRr86cPYjjY8end8oKyvYc3DFz9tnQ83e/8V3tvz2MUcRpLKTCuT2Qh1wZOaghxHDx/64cd3Zc6e2bjkA3pmc3Oxff/vpmzUrwEcY+/Qzb42bzGarY5eeGdPnfLN6+ey505F2yrkn1NGvDh6JzKGOvmaT0cA2LkihGEmT9v7I9kg8lurb2H7gJMH99rXv3wkId+g6pBESJxvn3x70dkBgpJE2j8n2eExnt4pSIXZz8YBaTQ18W4hvILjZxT1pxTQmZ/HFdHE9fTA340aBf5TxkWCFRVnLvxludJeDnVN5pfFuCT/vsMnjv0NPjjmfdDe1C3prJBIjPzAkuNW4USZtvTtnM1085MIMpasNIiDmmQKE6ZZFXdNJ2/byPPNnnikhOjt5Tp/0k9FdYIXI5cYblyT5hCMymroG7WWoK+UyIxMOpZK6IrqVF5W/sYSPYL31RdwDYxmzjBWW2B5uCXFFSeczQmON1FNQ2Hi4W76x8mSv4ebJtOAIR1LQoQfFPXnKFI+ogd6Y17i8uLIwg2PvsTC4918OeDb7C7J1yEKKfWKzaR7dFJr0eZP0q9nI2sm8ll+apxR4yAexzyZt2AR7Ar29tEnC4aT89DJkpaQl5BXllL79eRgSOoztTrBH2mGCaMoX4fevZ989J8QB9A0k8WSasqB0wpJQJHgIcU/iq+900hpMXhGOaM31oylZifnIKkj5N+fK4SQ3N+mEz4RfFmqpw+oUBWYPAzPF2PkhZw4VXD5WmJde7OBs7xPu4egunuD21RSkl+YmFVVWqBwU0kETggIiRRNTijA9ekUUPMn4iO1fcId/5/8qvBJXlHzxvnY4iJQk4H+kdpmZh4PDar/qh+QaBnXVBtiE7epqhtGtUVMddZPRN2p13Y9scvWaNrpVanRJBDII7MnC/kFSgmiqKpgnezApgTa+hFKDh5uiKQau1tld2nNYQEgL4Y2vqRPdcETrnGBfT/cyuBjhH2zc/ld550pJUY5aVUlrVLShECUyRKkfhBAGTzatqboKEBDFaFXFfiUk2ujKVTkJmg3Uo81Paauih+LDsvlJbf7qcz74E4SEYSht+ENaDZ80rSbYDFKZdvEjiUzq7qto3t61UROxhtXTvaDW6UdsaD9H+FMK+IcwvGCRCfb8INBFITFGkcklUpmIA2JJpQQyMQEDC1FMyOyJSiV3s4k4B5pjgWHGrVsRrx5jg4Q0E2gIisfh1L5cOwcJMlGgYyGKic6veMAD+3uLKHtcU64Ud3vVx9ReYa3XjHkcNi9OBb9Dmy5ejaNFECWrtJC5+FdOyo2S0XNCHF1NNnCxEEXJbyvT8zNVlIamqCf8+B63M/vx8pEScNoiBydprxG+jcLrem2wEMWMCpWXG4vjSFSvVf8gRfd/hkE1gn7ouwuYWsc+tPoXqzzDVcQInUez1rpiNeLbSCQOTuhxwELECALsvsEIAixEjCDAQsQIAixEjCDAQsQIAixEjCD4fwAAAP//R4r4vwAAAAZJREFUAwDDAB7QgAjHjQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x0000026A4FC402F0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "from langgraph.graph import StateGraph, MessagesState, START\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "# model = init_chat_model(\"openai:gpt-4.1\")\n",
    "model = ChatGroq(\n",
    "            model= \"qwen/qwen3-32b\", \n",
    "            temperature=0.5,\n",
    "            max_tokens=1000,\n",
    "            )\n",
    "\n",
    "server_config = {\n",
    "        \"search\": {\n",
    "            \"url\": \"http://localhost:8000/mcp\",\n",
    "            \"transport\": \"sse\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "client = MultiServerMCPClient(server_config)\n",
    "tools = await client.get_tools()\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    \n",
    "    response = model.bind_tools(tools).invoke(state[\"messages\"])\n",
    "    return {\"messages\": response}\n",
    "\n",
    "builder = StateGraph(MessagesState)\n",
    "builder.add_node(call_model)\n",
    "builder.add_node(ToolNode(tools))\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_conditional_edges(\n",
    "    \"call_model\",\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\", \"call_model\")\n",
    "graph = builder.compile()\n",
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad179fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='knowledge distillation regarding large language models?', additional_kwargs={}, response_metadata={}, id='da742d3d-fbf9-4c03-b3f5-54e5fb13b0e9'),\n",
       "  AIMessage(content='', additional_kwargs={'reasoning_content': 'Okay, the user is asking about knowledge distillation in the context of large language models. Let me start by recalling what knowledge distillation is. From what I remember, it\\'s a technique where a smaller model, called the student model, is trained to mimic the behavior of a larger, more complex model known as the teacher model. The idea is to transfer the knowledge from the teacher to the student so that the student can achieve similar performance but with lower computational costs.\\n\\nNow, applying this to large language models (LLMs), the teacher model would typically be a massive model like GPT-3 or BERT, and the student model would be a more compact version. The user might be interested in how this process works specifically for LLMs, maybe looking for methods or recent advancements. \\n\\nI should check if there are any recent papers or articles on this topic. Since the user provided tools for web_search, wiki_search, and arxiv_search, I should use one of these to find relevant information. Given that the user is asking for technical details, arxiv_search might be the best option because it can retrieve academic papers. \\n\\nI need to structure the search query. The key terms here are \"knowledge distillation\" and \"large language models\". Maybe adding \"techniques\" or \"methods\" could help. Let me use the arxiv_search function with the query \"knowledge distillation in large language models techniques\". That should fetch relevant research papers. \\n\\nWait, but I should also consider that the user might want a general overview first. However, since the user is asking for specific information related to LLMs, going straight to academic sources would be more efficient. Let me proceed with the arxiv_search.\\n', 'tool_calls': [{'id': 'c4gbj46g7', 'function': {'arguments': '{\"query\":\"knowledge distillation in large language models techniques\"}', 'name': 'arxiv_search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 379, 'prompt_tokens': 1227, 'total_tokens': 1606, 'completion_time': 0.819955914, 'prompt_time': 0.116133852, 'queue_time': 0.212222517, 'total_time': 0.936089766}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--59f44bd6-4896-4a64-ae27-ea229a1fca02-0', tool_calls=[{'name': 'arxiv_search', 'args': {'query': 'knowledge distillation in large language models techniques'}, 'id': 'c4gbj46g7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1227, 'output_tokens': 379, 'total_tokens': 1606}),\n",
       "  ToolMessage(content='{\\n  \"results\": [\\n    {\\n      \"Published\": \"2025-04-18\",\\n      \"Title\": \"Feature Alignment and Representation Transfer in Knowledge Distillation for Large Language Models\",\\n      \"Authors\": \"Junjie Yang, Junhao Song, Xudong Han, Ziqian Bi, Tianyang Wang, Chia Xin Liang, Xinyuan Song, Yichao Zhang, Qian Niu, Benji Peng, Keyu Chen, Ming Liu\",\\n      \"Summary\": \"Knowledge distillation (KD) is a technique for transferring knowledge from complex teacher models to simpler student models, significantly enhancing model efficiency and accuracy. It has demonstrated substantial advancements in various applications including image classification, object detection, language modeling, text classification, and sentiment analysis. Recent innovations in KD methods, such as attention-based approaches, block-wise logit distillation, and decoupling distillation, have notably improved student model performance. These techniques focus on stimulus complexity, attention mechanisms, and global information capture to optimize knowledge transfer. In addition, KD has proven effective in compressing large language models while preserving accuracy, reducing computational overhead, and improving inference speed. This survey synthesizes the latest literature, highlighting key findings, contributions, and future directions in knowledge distillation to provide insights for researchers and practitioners on its evolving role in artificial intelligence and machine learning.\"\\n    },\\n    {\\n      \"Published\": \"2025-07-29\",\\n      \"Title\": \"Basic Reading Distillation\",\\n      \"Authors\": \"Zhi Zhou, Sirui Miao, Xiangyu Duan, Hao Yang, Min Zhang\",\\n      \"Summary\": \"Large language models (LLMs) have demonstrated remarkable abilities in various natural language processing areas, but they demand high computation resources which limits their deployment in real-world. Distillation is one technique to solve this problem through either knowledge distillation or task distillation. Both distillation approaches train small models to imitate specific features of LLMs, but they all neglect basic reading education for small models on generic texts that are \\\\\\\\emph{unrelated} to downstream tasks. In this paper, we propose basic reading distillation (BRD) which educates a small model to imitate LLMs basic reading behaviors, such as named entity recognition, question raising and answering, on each sentence. After such basic education, we apply the small model on various tasks including language inference benchmarks and BIG-bench tasks. It shows that the small model can outperform or perform comparable to over 20x bigger LLMs. Analysis reveals that BRD effectively influences the probability distribution of the small model, and has orthogonality to either knowledge distillation or task distillation.\"\\n    },\\n    {\\n      \"Published\": \"2024-01-21\",\\n      \"Title\": \"Confidence Preservation Property in Knowledge Distillation Abstractions\",\\n      \"Authors\": \"Dmitry Vengertsev, Elena Sherman\",\\n      \"Summary\": \"Social media platforms prevent malicious activities by detecting harmful content of posts and comments. To that end, they employ large-scale deep neural network language models for sentiment analysis and content understanding. Some models, like BERT, are complex, and have numerous parameters, which makes them expensive to operate and maintain. To overcome these deficiencies, industry experts employ a knowledge distillation compression technique, where a distilled model is trained to reproduce the classification behavior of the original model. The distillation processes terminates when the distillation loss function reaches the stopping criteria. This function is mainly designed to ensure that the original and the distilled models exhibit alike classification behaviors. However, besides classification accuracy, there are additional properties of the original model that the distilled model should preserve to be considered as an appropriate abstraction. In this work, we explore whether distilled TinyBERT models preserve confidence values of the original BERT models, and investigate how this confidence preservation property could guide tuning hyperparameters of the dist\"\\n    }\\n  ]\\n}', name='arxiv_search', id='054d193a-4db6-4d30-a398-44536852c010', tool_call_id='c4gbj46g7'),\n",
       "  AIMessage(content='Knowledge distillation (KD) is a critical technique for compressing large language models (LLMs) while retaining their performance. Recent advancements highlight diverse approaches and insights:\\n\\n### Key Techniques in KD for LLMs\\n1. **Feature Alignment & Representation Transfer**  \\n   - **Methods**: Attention-based distillation, block-wise logit distillation, and decoupling distillation.  \\n   - **Focus**: Aligning attention mechanisms, capturing global context, and optimizing stimulus complexity.  \\n   - **Outcome**: Improved student model accuracy and efficiency, as seen in works by *Junjie Yang et al. (2025)*.\\n\\n2. **Basic Reading Distillation (BRD)**  \\n   - **Approach**: Trains small models on foundational tasks (e.g., named entity recognition, question-answering) using generic texts, unrelated to downstream tasks.  \\n   - **Impact**: Small models trained with BRD (*Zhi Zhou et al., 2025*) outperform or match much larger LLMs (e.g., 20x bigger models) on benchmarks like BIG-bench.  \\n   - **Advantage**: Enhances generalization by \"educating\" models on basic reading behaviors.\\n\\n3. **Confidence Preservation**  \\n   - **Challenge**: Ensuring distilled models retain the teacher model’s confidence scores (critical for reliability in applications like sentiment analysis).  \\n   - **Study**: *Dmitry Vengertsev et al. (2024)* found that TinyBERT models may not fully preserve BERT’s confidence values, suggesting hyperparameter tuning could mitigate this.\\n\\n### Benefits of KD\\n- **Efficiency**: Reduces computational overhead and inference costs.  \\n- **Accuracy**: Maintains high performance despite smaller model size.  \\n- **Flexibility**: Applicable to tasks like text classification, language modeling, and safety-critical content moderation.\\n\\n### Future Directions\\n- **Orthogonality of Methods**: BRD complements traditional KD/task distillation, suggesting hybrid approaches could further enhance performance.  \\n- **Confidence Calibration**: Addressing confidence preservation remains key for deploying distilled models in high-stakes scenarios.  \\n\\nFor researchers, these findings underscore the importance of exploring both architectural innovations (e.g., attention alignment) and pedagogical strategies (e.g., BRD) to advance LLM compression.', additional_kwargs={'reasoning_content': \"Okay, the user asked about knowledge distillation regarding large language models. Let me start by recalling what knowledge distillation (KD) is. From what I know, KD is a model compression technique where a smaller model (student) learns from a larger, more complex model (teacher). The idea is to transfer the knowledge from the teacher to the student so that the student can achieve similar performance but with lower computational costs.\\n\\nLooking at the search results provided, there are three recent papers. The first one from 2025 by Junjie Yang et al. discusses feature alignment and representation transfer in KD for LLMs. They mention techniques like attention-based methods, block-wise logit distillation, and decoupling distillation. These methods focus on improving how knowledge is transferred by aligning features and capturing global information. The summary also notes that KD helps in compressing LLMs while maintaining accuracy and speed.\\n\\nThe second paper from 2025 by Zhi Zhou et al. introduces Basic Reading Distillation (BRD). This approach educates small models on basic reading tasks unrelated to downstream tasks, like named entity recognition and question answering. Their results show that BRD can make small models perform as well as much larger ones. This is interesting because it suggests that foundational training on generic texts can enhance the model's general capabilities, which might be overlooked in traditional distillation methods.\\n\\nThe third paper from 2024 by Dmitry Vengertsev and Elena Sherman examines the confidence preservation in distilled models. They look at whether TinyBERT models retain the confidence values of the original BERT models. Confidence preservation is crucial because it affects how reliable the model's predictions are, especially in applications like sentiment analysis where confidence scores might influence decision-making.\\n\\nNow, synthesizing this information. The user probably wants an overview of current KD techniques in LLMs. The first paper covers various KD methods and their effectiveness. The second introduces BRD as a novel approach, emphasizing basic education for small models. The third highlights the importance of preserving not just accuracy but also confidence metrics in distilled models.\\n\\nI should structure the answer to first explain KD in general, then discuss the techniques mentioned (attention-based, block-wise logit, decoupling), mention BRD as a new method, and touch on confidence preservation. Also, note the benefits like efficiency and accuracy, and future directions as indicated in the survey. Make sure to mention the authors and key findings from each paper to give proper credit and depth.\\n\"}, response_metadata={'token_usage': {'completion_tokens': 991, 'prompt_tokens': 2075, 'total_tokens': 3066, 'completion_time': 2.529300989, 'prompt_time': 0.075018792, 'queue_time': 0.219490885, 'total_time': 2.604319781, 'prompt_tokens_details': {'cached_tokens': 1024}}, 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--621ab09c-2aa1-4f15-8044-d7892b171f1e-0', usage_metadata={'input_tokens': 2075, 'output_tokens': 991, 'total_tokens': 3066})]}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await graph.ainvoke({\"messages\": \"knowledge distillation regarding large language models?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f209a005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='' additional_kwargs={} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'Okay'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' user'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' is'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' asking'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' about'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' knowledge'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' dist'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'illation'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' in'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' context'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' of'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' large'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' language'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' models'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' Let'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' me'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' start'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' by'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' recalling'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' what'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' knowledge'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' dist'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'illation'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' is'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' From'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' what'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' I'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' remember'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' it'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': \"'s\"} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' a'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' technique'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' where'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' a'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' smaller'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' called'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' student'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' is'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' trained'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' mimic'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' behavior'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' of'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' a'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' larger'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' more'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' complex'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' known'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' as'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' teacher'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' The'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' idea'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' is'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' transfer'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' knowledge'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' from'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' teacher'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' student'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' so'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' that'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' student'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' can'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' achieve'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' similar'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' performance'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' but'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' with'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' lower'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' computational'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' costs'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.\\n\\n'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'Now'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' applying'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' this'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' large'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' language'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' models'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' ('} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'LL'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'Ms'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '),'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' teacher'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' would'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' typically'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' be'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' a'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' large'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' pre'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '-trained'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' like'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' G'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'PT'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '-'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '3'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' or'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' B'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'ERT'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' The'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' student'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' is'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' a'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' smaller'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' version'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' such'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' as'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' B'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'ERT'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '-base'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' instead'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' of'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' B'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'ERT'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '-large'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' The'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' process'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' involves'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' using'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' outputs'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' of'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' teacher'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' ('} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'like'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' soft'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' labels'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ')'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' train'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' student'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' along'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' with'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' possibly'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' original'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' training'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' data'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' This'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' helps'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' student'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' learn'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' not'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' just'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' correct'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' answers'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' but'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' also'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' nuanced'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' probabilities'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' that'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' teacher'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' has'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' learned'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.\\n\\n'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'I'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' should'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' check'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' if'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' there'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' are'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' specific'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' challenges'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' when'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' applying'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' dist'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'illation'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' L'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'LM'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 's'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' For'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' example'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' L'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'LM'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 's'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' have'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' a'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' vast'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' number'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' of'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' parameters'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' so'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' dist'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'illing'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' them'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' might'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' require'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' careful'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' handling'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' of'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' architecture'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' and'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' training'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' procedures'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' Techniques'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' like'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' using'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' attention'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' mechanisms'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' dist'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'illing'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' knowledge'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' from'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' intermediate'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' layers'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' or'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' employing'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' specific'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' loss'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' functions'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' ('} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'like'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' KL'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' divergence'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ')'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' compare'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' teacher'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': \"'s\"} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' and'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' student'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': \"'s\"} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' outputs'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' might'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' be'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' involved'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.\\n\\n'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'I'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' should'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' also'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' consider'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' recent'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' advancements'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' or'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' papers'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' on'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' this'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' topic'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' Maybe'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' there'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' are'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' studies'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' comparing'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' different'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' dist'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'illation'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' methods'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' for'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' L'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'LM'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 's'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' or'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' frameworks'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' that'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' facilitate'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' this'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' process'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' The'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' user'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' might'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' be'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' interested'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' in'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' practical'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' applications'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' such'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' as'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' deploying'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' smaller'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' models'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' on'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' devices'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' with'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' limited'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' resources'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' or'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' in'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' scenarios'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' where'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' inference'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' speed'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' is'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' critical'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.\\n\\n'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'Wait'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' user'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' might'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' want'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' know'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' steps'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' involved'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' in'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' dist'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'illation'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' process'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' for'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' L'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'LM'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 's'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' Let'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' me'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' outline'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' that'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ':'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' first'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' train'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' teacher'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' on'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' a'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' large'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' dataset'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' Then'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' generate'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' soft'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' labels'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' using'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' teacher'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' on'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' a'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' training'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' set'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' Next'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' train'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' student'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' using'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' both'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' soft'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' labels'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' and'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' original'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' labels'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' optimizing'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' for'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' similarity'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' in'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' predictions'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' Additionally'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' techniques'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' like'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' multi'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '-task'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' learning'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' or'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' using'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' auxiliary'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' tasks'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' during'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' dist'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'illation'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' could'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' enhance'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' student'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': \"'s\"} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' performance'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.\\n\\n'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'I'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' should'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' also'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' mention'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' evaluation'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' metrics'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' How'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' do'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' you'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' measure'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' if'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' student'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' effectively'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' captures'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' teacher'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': \"'s\"} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' knowledge'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '?'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' Metrics'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' like'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' accuracy'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' perplex'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'ity'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' or'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' task'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '-specific'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' benchmarks'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' would'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' be'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' relevant'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' There'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' might'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' also'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' be'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' trade'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '-offs'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' between'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' size'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' inference'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' speed'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' and'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' accuracy'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' that'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' need'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' be'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' discussed'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.\\n\\n'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'Are'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' there'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' any'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' notable'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' examples'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' of'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' distilled'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' L'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'LM'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 's'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '?'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' For'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' instance'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' models'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' like'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' Dist'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'il'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'BERT'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' which'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' is'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' a'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' smaller'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' version'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' of'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' B'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'ERT'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' or'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' Tiny'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'BERT'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' These'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' models'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' are'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' often'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' used'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' in'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' production'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' environments'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' where'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' efficiency'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' is'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' key'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' The'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' user'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' might'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' be'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' looking'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' for'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' recommendations'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' on'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' which'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' distilled'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' models'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' use'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' for'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' specific'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' tasks'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' or'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' how'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' implement'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' dist'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'illation'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' themselves'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.\\n\\n'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'Potential'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' issues'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' consider'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' include'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' loss'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' of'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' some'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' capabilities'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' in'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' student'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' compared'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' teacher'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' especially'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' in'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' complex'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' tasks'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' There'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': \"'s\"} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' also'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' aspect'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' of'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' data'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' requirements'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '—'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'dist'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'illation'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' might'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' need'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' a'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' large'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' amount'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' of'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' data'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' be'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' effective'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' which'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' could'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' be'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' a'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' limitation'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' Additionally'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' choice'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' of'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' architecture'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' for'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' student'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' model'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' is'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' crucial'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ';'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' it'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' needs'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' be'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' simple'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' enough'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' for'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' efficiency'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' but'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' still'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' capable'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' of'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' learning'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' necessary'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' patterns'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.\\n\\n'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'In'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' summary'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' my'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' response'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' should'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' cover'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' the'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' definition'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' of'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' knowledge'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' dist'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'illation'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' its'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' application'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' to'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' L'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 'LM'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': 's'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' key'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' techniques'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' and'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' challenges'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' examples'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' of'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' distilled'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' models'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' and'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' considerations'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' for'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' implementation'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' I'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' should'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' structure'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' this'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' information'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' clearly'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' perhaps'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' starting'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' with'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' an'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' overview'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' then'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' diving'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' into'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' specifics'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ','} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' and'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' concluding'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' with'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' practical'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' insights'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' or'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': ' recommendations'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'reasoning_content': '.\\n'} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b'\n",
      "content='' additional_kwargs={'tool_calls': [{'index': 0, 'id': 'y1xbsjyej', 'function': {'arguments': '{\"query\":\"knowledge distillation large language models techniques\"}', 'name': 'web_search'}, 'type': 'function'}]} response_metadata={} id='run--3218f831-2b43-48dc-af06-8b9f2156970b' tool_calls=[{'name': 'web_search', 'args': {'query': 'knowledge distillation large language models techniques'}, 'id': 'y1xbsjyej', 'type': 'tool_call'}] tool_call_chunks=[{'name': 'web_search', 'args': '{\"query\":\"knowledge distillation large language models techniques\"}', 'id': 'y1xbsjyej', 'index': 0, 'type': 'tool_call_chunk'}]\n",
      "content='' additional_kwargs={} response_metadata={'finish_reason': 'tool_calls', 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand'} id='run--3218f831-2b43-48dc-af06-8b9f2156970b' usage_metadata={'input_tokens': 1227, 'output_tokens': 735, 'total_tokens': 1962}\n",
      "content='{\\n  \"results\": {\\n    \"query\": \"knowledge distillation large language models techniques\",\\n    \"follow_up_questions\": null,\\n    \"answer\": \"Knowledge distillation transfers knowledge from large language models to smaller models, improving efficiency. Techniques include training the student model on outputs from the teacher model. This method reduces computational demands.\",\\n    \"images\": [\\n      \"https://assets.zilliz.com/Knowledge_Distillation_of_Large_Language_Models_20241122_101853_562807feda.png\",\\n      \"https://i.ytimg.com/vi/fbledYWt_PE/maxresdefault.jpg\",\\n      \"https://aicorr.com/wp-content/uploads/2024/08/Knowledge-Distillation-in-Large-Language-Models.jpg\",\\n      \"https://i1.rgstatic.net/publication/371605388_Knowledge_Distillation_of_Large_Language_Models/links/648bd18295bbbe0c6ecb5330/largepreview.png\",\\n      \"https://pbs.twimg.com/media/FytbKl2XoAEO-ow.jpg:large\"\\n    ],\\n    \"results\": [\\n      {\\n        \"url\": \"https://zilliz.com/learn/knowledge-distillation-from-large-language-models-deep-dive\",\\n        \"title\": \"Knowledge Distillation for Large Language Models: A Deep Dive\",\\n        \"content\": \"Knowledge distillation is a machine learning technique in which the knowledge of a large, complex model (teacher) is transferred to a smaller, simpler model (student). Knowledge distillation from a large teacher model to a student model Figure: Knowledge distillation from a large teacher model to a student model | Source In this method, the student model is trained on the labeled data generated by the teacher LLM. For example, in text generation tasks, the teacher LLM could rank different possible outputs, and the student model would be trained to predict this ranking, learning the teacher\\'s subjective preferences. Using the distilled knowledge from large language models (LLMs), student models can more effectively navigate\",\\n        \"score\": 0.93161833,\\n        \"raw_content\": \"* [Learn](/learn)\\\\n* Large Language Models (LLMs) 101\\\\n\\\\n# Knowledge Distillation: Transferring Knowledge from Large, Computationally Expensive LLMs to Smaller Ones Without Sacrificing Validity\\\\n\\\\nNov 11, 2024\\\\n13 min read\\\\n\\\\nKnowledge distillation is a machine learning technique in which the knowledge of a large, complex model (teacher) is transferred to a smaller, simpler model (student).\\\\n\\\\nBy\\xa0 [Haziqa Sajid](/authors/_Haziqa_Sajid)\\\\n\\\\nRead the entire series\\\\n\\\\n* [OpenAI\\'s ChatGPT](/learn/ChatGPT-Vector-Database-Prompt-as-code)\\\\n* [Unlocking the Secrets of GPT-4.0 and Large Language Models](/learn/what-are-llms-unlock-secrets-of-gpt-4-and-llms)\\\\n* [Top LLMs of 2024: Only the Worthy](/learn/top-llms-2024)\\\\n* [Large Language Models and Search](/learn/large-language-models-and-search)\\\\n* [Introduction to the Falcon 180B Large Language Model (LLM)](/learn/Falcon-180B-advancing-language-models-in-AI-frontier)\\\\n* [OpenAI Whisper: Transforming Speech-to-Text with Advanced AI](/learn/open-ai-whisper-transforming-speech-to-text-with-advanced-ai)\\\\n* [Exploring OpenAI CLIP: The Future of Multi-Modal AI Learning](/learn/exploring-openai-clip-the-future-of-multimodal-ai-learning)\\\\n* [What are Private LLMs? Running Large Language Models Privately - privateGPT and Beyond](/learn/what-are-private-llms)\\\\n* [LLM-Eval: A Streamlined Approach to Evaluating LLM Conversations](/learn/streamlined-approach-to-evaluating-llm-conversations)\\\\n* [Mastering Cohere\\'s Reranker for Enhanced AI Performance](/learn/mastering-coheres-reranker-enhanced-ai-performance)\\\\n* [Efficient Memory Management for Large Language Model Serving with PagedAttention](/learn/efficient-memory-management-for-llm-serving-pagedattention)\\\\n* [LoRA Explained: Low-Rank Adaptation for Fine-Tuning LLMs](/learn/lora-explained-low-rank-adaptation-for-fine-tuning-llms)\\\\n* [Knowledge Distillation: Transferring Knowledge from Large, Computationally Expensive LLMs to Smaller Ones Without Sacrificing Validity](/learn/knowledge-distillation-from-large-language-models-deep-dive)\\\\n* [RouteLLM: An Open-Source Framework for Navigating Cost-Quality Trade-Offs in LLM Deployment](/learn/routellm-open-source-framework-for-navigate-cost-quality-trade-offs-in-llm-deployment)\\\\n* [Prover-Verifier Games Improve Legibility of LLM Outputs](/learn/prover-verifier-games-improve-legibility-of-llm-outputs)\\\\n* [Be like a Goldfish, Don\\'t Memorize! Mitigating Memorization in Generative LLMs](/learn/mitigate-memorization-in-generative-LLMs)\\\\n* [Unlocking the Power of Many-Shot In-Context Learning in LLMs](/learn/unlock-power-of-many-shot-in-context-learning-in-llms)\\\\n* [Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text](/learn/spotting-llms-with-binoculars-zero-shot-detection-of-machine-generated-text)\\\\n* [Teaching LLMs to Rank Better: The Power of Fine-Grained Relevance Scoring](/learn/teaching-llms-to-rank-better-the-power-of-fine-grained-relevance-scoring)\\\\n* [Everything You Need to Know About LLM Guardrails](/learn/everything-you-need-to-know-about-llm-guardrails)\\\\n* [Chain-of-Retrieval Augmented Generation](/learn/chain-of-retrieval-augmented-generation)\\\\n* [Chain of Agents (COA): Large Language Models Collaborating on Long-Context Tasks](/learn/chain-of-agents-large-language-models-collaborating-on-long-context-tasks)\\\\n\\\\n[Large language models](https://zilliz.com/glossary/large-language-models-(llms)) (LLMs) like [GPT-4](https://zilliz.com/learn/what-are-llms-unlock-secrets-of-gpt-4-and-llms), [Gemini](https://zilliz.com/learn/build-multimodal-rag-gemini-bge-m3-milvus-langchain), and Claude have stood out as groundbreaking technologies in the rapidly evolving field of AI. They can generate human-like text and solve complex problems, showcasing emergent abilities beyond their original training objectives.\\\\n\\\\nDespite their impressive abilities, proprietary LLMs like GPT-4 have limitations, including restricted accessibility, high costs, and data privacy and security concerns. Open-source models like [LLaMA](https://zilliz.com/glossary/llama2) and [Mistral](https://zilliz.com/blog/optimize-multi-agent-system-with-mistral-large-mistral-nemo-and-llama-agents) give advantages over proprietary LLMs in accessibility and adaptability but can suffer from smaller model scales and lower performance.\\\\n\\\\n[**Knowledge Distillation**](https://zilliz.com/learn/distilbert-distilled-version-of-bert) **(KD)** is an important technique for bridging this gap. Through distillation techniques, the gap between proprietary LLMs and open-source models is greatly reduced and even filled. Knowledge distillation is important for improving the capabilities of LLMs, model compression, and self-improvement. Additionally, it helps models act as their own teachers for self-improvement.\\\\n\\\\nIn this article, we will discuss the significance of knowledge distillation within the context of large language models (LLMs), the need for knowledge distillation, evolving knowledge distillation techniques, their detailed descriptions, and their applications.\\\\n\\\\nSelf-improvement via Knowledge Distillation\\\\n\\\\nFigure: Self-improvement via Knowledge Distillation | [Source](https://arxiv.org/pdf/2402.13116)\\\\n\\\\nIf you want to explore this topic further, here is the paper: [A Survey on Knowledge Distillation of LLMs.](https://arxiv.org/abs/2402.13116)\\\\n\\\\n## What is Knowledge Distillation (KD)?\\\\n\\\\n**Knowledge distillation** is a technique where a smaller, simpler \\\\\"student\\\\\" model is trained to mimic the behavior of a larger, more complex \\\\\"teacher\\\\\" model. Teacher models are trained on a large amount of data and possess a deeper understanding of the task. The goal is to transfer this expertise to the student model, which is optimized to run faster and more efficiently on resource-constrained devices.\\\\n\\\\nKnowledge distillation from a large teacher model to a student model\\\\n\\\\nFigure: Knowledge distillation from a large teacher model to a student model | [Source](https://arxiv.org/pdf/2402.13116)\\\\n\\\\n## Data Augmentation (DA) in Knowledge Distillation\\\\n\\\\n**Data Augmentation (DA)** is essential in improving the effectiveness of Knowledge Distillation. It uses the teacher LLM’s ability to generate new data, expanding the training dataset for the student model. This is important when dealing with specialized domains or skills with limited labeled data. Here’s how data augmentation works in knowledge distillation:\\\\n\\\\n* **Seed Knowledge:** The teacher LLM is provided with a small set of initial data, such as instructions, demonstrations, or specific domain knowledge.\\\\n* **Prompt Engineering:** Carefully designed [prompts](https://zilliz.com/glossary/prompt-as-code-(prompt-engineering)) guide the teacher LLM in generating new data relevant to the target skill or domain.\\\\n* **Data Generation:** The teacher LLM generates new data samples, such as question-answer pairs, explanations, or code, based on the seed knowledge and prompts.\\\\n* **Data Filtering and Evaluation:** The generated data is then reviewed and filtered to ensure it is high-quality and relevant before training the student model.\\\\n\\\\nKD enables smaller models to acquire advanced capabilities that would otherwise require significantly more training data and computational resources by generating large-scale, high-quality [datasets](https://zilliz.com/learn/popular-datasets-for-natural-language-processing).\\\\n\\\\n## Methodologies Driving Knowledge Distillation for LLMs\\\\n\\\\nKnowledge Distillation (KD) for Large Language Models (LLMs) is multifaceted, emphasizing the interplay between algorithms, skill enhancement, and domain specialization. Let\\'s break down each aspect and methodologies involved:\\\\n\\\\n* KD Algorithms\\\\n* Skill Distillation\\\\n* Verticalization Distillation\\\\n\\\\nA multifaceted overview of knowledge distillation of LLMs\\\\n\\\\nFigure: A multifaceted overview of knowledge distillation of LLMs | [Source](https://arxiv.org/pdf/2402.13116)\\\\n\\\\n### KD Algorithms: The Foundation for Knowledge Transfer\\\\n\\\\n**Knowledge distillation algorithms** provide the technical mechanisms for transferring knowledge. The objective is to improve the student\\'s capabilities without requiring the same extensive training data and computational resources as the teacher. This process is categorized into two primary steps:\\\\n\\\\n* Knowledge Elicitation\\\\n* Distillation Algorithms\\\\n\\\\nTaxonomy of KD algorithms.png\\\\n\\\\nFigure: Taxonomy of KD algorithms | [Source](https://arxiv.org/pdf/2402.13116)\\\\n\\\\n#### Knowledge elicitation\\\\n\\\\n**Knowledge elicitation** in the context of LLMs is extracting valuable knowledge from the teacher, often a proprietary LLM like the GPT-4 model. Unlike traditional knowledge distillation, in which model architectures compress to reduce the size and computational load, this process focuses on the selective transfer of rich and diverse knowledge.\\\\n\\\\nKnowledge elicitation can be done in various ways, including **Labeling, Expansion, Data Curation, Feature, Feedback, and Self-knowledge.**\\\\n\\\\n**Labeling**\\\\n\\\\nThe teacher LLM generates labels or outputs y for a given input x. This labeled data serves as the training data for the student model. For example, the teacher LLM could be prompted to categorize text for a natural language understanding task or generate summaries for a text summarization task. The labeling process can be defined as follows:\\\\n\\\\nequation - labeling\\\\n\\\\nHere,\\\\n\\\\n* x Is the input data point\\\\n* y represents output or label\\\\n* pT\\u200b(y∣I⊕c⊕x) represents the probability distribution of the teacher model\\\\n\\\\n**Expansion**\\\\n\\\\nThe Expansion technique uses LLMs\\' in-context learning abilities to generate new input-output pairs (x, y) similar to a provided set of demonstrations (c) or instructions. The expansion process can be described as:\\\\n\\\\nequation - expansion\\\\n\\\\n**Data Curation**\\\\n\\\\nData curation addresses the quality and quantity constraints of Labeling and Expansion by using extensive meta-information as seed knowledge to curate high-quality and large-scale data. For example, in [developing](https://arxiv.org/pdf/2402.13116) the \\\\\"phi-1\\\\\" model, random topics or function names were used as meta-information to assist the teacher LLM in creating a dataset of Python textbooks and exercises. The process of data curation can be represented as:\\\\n\\\\nequation - data curation.png\\\\n\\\\n**Feature**\\\\n\\\\nFeature knowledge elicitation uses the internal representations of teacher LLMs, such as output distributions, intermediate features, or activations. This gives the student model an understanding of the teacher\\'s decision-making process. The technique for eliciting feature knowledge can be outlined as follows:\\\\n\\\\nequation - feature\\\\n\\\\n**Feedback**\\\\n\\\\nThe teacher LLM gives feedback on the student model\\'s outputs, guiding its learning process. This feedback can take various forms, such as corrections, preferences, or assessments. A generalized formulation for eliciting feedback knowledge is as follows:\\\\n\\\\nequation - feedback\\\\n\\\\n**Self-Knowledge**\\\\n\\\\nSelf-knowledge elicitation is a method where the student model takes on both the roles of teacher and student. It generates outputs and then evaluates them, filtering for high-quality responses. The model learns and improves over time by distilling and refining its own previously generated outputs. The process of eliciting self-knowledge can be defined as:\\\\n\\\\nequation - self-knowledge\\\\n\\\\nDifferent knowledge elicitation methods from teacher LLMs.png\\\\n\\\\nFigure: Different knowledge elicitation methods from teacher LLMs | [Source](https://arxiv.org/pdf/2402.13116)\\\\n\\\\n#### Distillation Algorithms\\\\n\\\\nOnce knowledge is extracted from the teacher\\'s LLM, various distillation algorithms are used to transfer this knowledge to the student\\'s LLM. The choice of algorithm depends on factors such as the type of knowledge being distilled, the architecture of the student model, and the available resources.\\\\n\\\\n**Supervised Fine-Tuning (SFT)**\\\\n\\\\nSupervised Fine-Tuning (SFT) is the simplest and most widely used distillation method. In this method, the student model is trained on the labeled data generated by the teacher LLM. The objective is to replicate the output behavior directly. This method is usually used with the \\\\\"Labeling\\\\\" or \\\\\"Expansion\\\\\" knowledge elicitation methods. The process of SFT can be mathematically formulated as follows:\\\\n\\\\nEquation - Supervised Fine-Tuning (SFT)\\\\n\\\\nHere,\\\\n\\\\n* −LogpS\\u200b(y∣x) Is the negative log-likelihood of the student model (S) generating the output (y) given the input (x)\\\\n\\\\n**Divergence and Similarity**\\\\n\\\\nDivergence and Similarity methods aim to minimize the difference (divergence) between the probability distributions of the teacher and student model outputs or maximize the similarity of their internal representations (hidden states). Divergence-based methods, such as minimizing the Kullback-Leibler divergence, encourage the student model to cover all the modes of the teacher\\'s distribution.\\\\n\\\\nVarious divergence types\\\\n\\\\nFigure: Various divergence types | [Source](https://arxiv.org/pdf/2402.13116)\\\\n\\\\n[Similarity](https://zilliz.com/learn/vector-similarity-search)-based algorithms align the internal representations or hidden states of the teacher and student models. This approach trains the student model to mirror the teacher model\\'s internal structures, ensuring a closer resemblance in how both models process information.\\\\n\\\\nSimilarity functions in knowledge distillation\\\\n\\\\nFigure: Similarity functions in knowledge distillation | [Source](https://arxiv.org/pdf/2402.13116)\\\\n\\\\n**Reinforcement Learning (RL)**\\\\n\\\\nReinforcement Learning (RL) algorithm works based on feedback from the teacher LLM to train the student model through a reward-based system.\\\\n\\\\n* A reward model is first trained using the feedback provided by the teacher LLM. This reward model learns to assess the quality of the student\\'s outputs based on the teacher\\'s preferences. The loss function for the reward model is defined as:\\\\n\\\\nequation - Reinforcement Learning (RL)\\\\n\\\\n* The student model is then trained using [reinforcement learning](https://zilliz.com/glossary/deep-reinforcement-learning) algorithms to maximize the reward it receives from the reward model. The student model learns to generate outputs that the teacher LLM will likely find favorable. The RL objective is given by:\\\\n\\\\nequation - Reinforcement Learning (RL) 2\\\\n\\\\n**Rank Optimization**\\\\n\\\\nThe student model learns to rank outputs in the same order the teacher LLM would rank them. For example, in text generation tasks, the teacher LLM could rank different possible outputs, and the student model would be trained to predict this ranking, learning the teacher\\'s subjective preferences. The ranking process is defined as follows:\\\\n\\\\nequation - Rank Optimization\\\\n\\\\n### Skill Distillation: Targeting Specific Capabilities\\\\n\\\\nKnowledge Distillation is not limited to simply replicating the teacher LLM\\'s overall behavior. It goes beyond examining how these algorithms can be applied to enhance specific skills or competencies in student LLMs. **Skill Distillation** (SD)has numerous examples across different skill categories.\\\\n\\\\nSkill distillation\\\\n\\\\nFigure: Skill distillation | [Source](https://arxiv.org/pdf/2402.13116)\\\\n\\\\n#### Context Following\\\\n\\\\nThis process trains student LLMs to understand and respond to a variety of contexts, including:\\\\n\\\\n* **Instructions:** This focuses on training the model to follow specific commands or guidelines provided in the input and perform tasks in a more controlled manner.\\\\n* **Multi-turn Dialogue:** This extends the context to ongoing conversations, helping the student model to maintain coherence and relevance across multiple turns in a dialogue.\\\\n* **Retrieval-Augmented Generation (**[**RAG**](https://zilliz.com/learn/Retrieval-Augmented-Generation)**):** This integrates external information sources and model access and incorporates relevant data from databases or documents to improve its responses.\\\\n\\\\n#### Alignment\\\\n\\\\nAlignment refines the student LLM\\'s outputs better to match human preferences, values, and intentions. Its element, thinking patterns, emphasizes training students to adopt the teacher\\'s reasoning processes, such as generating step-by-step explanations or evaluating multiple perspectives before concluding.\\\\n\\\\nAnother important element is Persona and Preference Modeling. The student learns to mirror the teacher\\'s persona or style differences to ensure consistent responses that meet a specific personality or brand voice.\\\\n\\\\n#### Agent\\\\n\\\\nSD helps develop LLM agents capable of interacting with the external world and completing more complex tasks. LLM agents can use external tools like calculators, calendars, or databases to enhance their functionality and problem-solving capabilities.\\\\n\\\\n#### NLP Task Specialization\\\\n\\\\nStudent models can be adapted to excel in specific [natural language processing](https://zilliz.com/learn/A-Beginner-Guide-to-Natural-Language-Processing) tasks, including:\\\\n\\\\n* **Natural Language Understanding (NLU):** KD can improve the student model\\'s ability to accurately understand and interpret human language, which can be used in tasks such as text classification, sentiment analysis, and information extraction.\\\\n* **Natural Language Generation (NLG):** NLG includes text summarization, machine translation, and dialogue generation tasks. KD can help student models generate more fluent, coherent, and informative text.\\\\n* **Recommendation Systems:** KD can help student models learn to make more accurate and relevant recommendations.\\\\n* **Code Generation:** This involves generating computer code from natural language descriptions. KD trains student models to generate correct, efficient, and readable code.\\\\n\\\\nUsing the distilled knowledge from large language models (LLMs), student models can more effectively navigate diverse NLP challenges, enhancing their performance and addressing data limitations.\\\\n\\\\n#### Multi-Modality\\\\n\\\\nExtending KD techniques to multi-modal LLMs that handle not just text but also process and generate content in [multiple modalities](https://zilliz.com/blog/combine-image-and-text-how-multimodal-retrieval-transforms-search), such as images. KD transfers image-text knowledge from teacher LLMs to student models in the [vision-language domain](https://zilliz.com/learn/CLIP-object-detection-merge-AI-vision-with-language-understanding). These student models can understand and generate both text and translate images into textual descriptions.\\\\n\\\\n### Verticalization: Domain-Specific Distillation\\\\n\\\\nTaxonomy of verticalization distillation.png\\\\n\\\\nFigure: Taxonomy of verticalization distillation | [Source](https://arxiv.org/pdf/2402.13116)\\\\n\\\\nKnowledge Distillation (KD) is crucial in customizing the LLMs for particular domains to perform specialized tasks with greater accuracy and efficiency. Key domains include.\\\\n\\\\n#### Law\\\\n\\\\nKD is used to develop LLMs who can understand legal documents, reason about legal issues, and provide legal assistance. These models were trained on extensive legal corpora and were fine-tuned for specific legal tasks, such as contract analysis or legal research. Here are some examples of LLMs used in the law domain:\\\\n\\\\n* [**LawyerLLaMA**](https://arxiv.org/abs/2305.15062)**:** This Chinese legal language model was built upon the LLaMA framework. It was first pre-trained on a large legal corpus and then fine-tuned using objective questions from the Chinese National Judicial Examination dataset and responses to legal consultations generated by ChatGPT.\\\\n* [**LawGPT**](https://arxiv.org/abs/2406.04614)**:** This model, based on OpenLLaMA, was trained using a dataset composed of real-world legal text, regulations, judicial interpretations, and legal consultation data. ChatGPT was used to generate additional data for training.\\\\n\\\\n#### Medical & Healthcare\\\\n\\\\nKD is applied to create LLMs that can process medical records, answer health-related questions, and generate personalized treatment plans. Some LLMs examples included:\\\\n\\\\n* [**HuatuoGPT**](https://arxiv.org/abs/2305.15075)**:** This model, designed for medical consultations, uses data distilled from ChatGPT and real-world data from doctors during the supervised fine-tuning stage.\\\\n* [**DoctorGLM**](https://arxiv.org/abs/2304.01097)**:** This Chinese medical dialogue model was trained on a dataset constructed with assistance from ChatGPT and uses a variety of techniques for diagnoses, drug recommendations, and medical advice.\\\\n\\\\n#### Finance\\\\n\\\\nLLMs are trained with KD using financial news, market data, and company filings to analyze financial information, assess risks, and make informed financial decisions. These models assist with tasks like investment analysis and risk management. Here are examples of knowledge distillation (KD) in building large language models (LLMs):\\\\n\\\\n* [**XuanYuan**](https://arxiv.org/abs/2305.12002)**:** This finance-focused LLM uses self-instruct techniques applied to seed data and self-QA methods on structured and unstructured data to generate instruction data for training.\\\\n\\\\n#### Science\\\\n\\\\nKD plays a transformative role in scientific research, enabling the creation of LLMs that can:\\\\n\\\\n* Read and understand vast amounts of scientific literature, identifying key findings and trends.\\\\n* Generate new hypotheses based on existing scientific knowledge.\\\\n* Assist with writing, generating initial drafts, and suggesting improvements to scientific papers.\\\\n\\\\nScience domain LLMs included:\\\\n\\\\n* [**SciGLM**](https://arxiv.org/abs/2401.07950)**:** This scientific LLM prompts a teacher LLM to generate detailed answers for unlabeled scientific questions and employs a self-reflective critic-and-revise process to improve data quality.\\\\n* [**AstroLLaMA-Chat**](https://arxiv.org/abs/2401.01916)**:** Built upon the 7B-parameter LLaMA-2 model and focuses on astronomy. It uses continual pre-training on a curated astronomy corpus to improve its performance in question-answering tasks related to astronomy.\\\\n\\\\n**Knowledge distillation (KD)** extends beyond traditional domains into education, aiding teaching, learning, and assessment. It\\'s also used in creating language models that automate IT tasks and support IT professionals. KD methods enhance the transfer of complex skills and knowledge, leading to more versatile AI solutions. However, challenges like data selection, catastrophic forgetting, and ensuring the reliability of distilled knowledge still need to be addressed.\\\\n\\\\n## Impact and Implications of Knowledge Distillation for LLMs\\\\n\\\\nTransferring knowledge from large models to smaller models is vital for bridging the gap and making state-of-the-art AI capabilities more accessible. This process not only improves accessibility but also enhances efficiency and sustainability in AI development.\\\\n\\\\n* **Sustainability:** KD contributes to AI\\'s environmental sustainability by enabling smaller, more efficient models that require less computational power.\\\\n* **Model Compression and Efficiency:** KD enables the development of smaller, efficient LLMs with minimal performance loss, essential for AI deployment in resource-limited environments like mobile devices.\\\\n* **Data Efficiency and Quality:** New data selection and augmentation methods like Superfiltering and self-instruct improve distillation, reducing data needs while improving model performance.\\\\n* **Broader Task Coverage:** KD enhances generalizability across tasks by using diverse instruction data. Models like WaveCoder and MFTCoder show how KD improves multi-task learning, excelling in specialized areas like code generation.\\\\n* **Advancements in Multi-Modality:** Innovative LLMs like LLaVA and MIMIC-IT showcase knowledge distillation\\'s role in linking language, vision, and audio, enhancing applications like image-based instruction tuning and multimodal conversational agents.\\\\n\\\\n## Conclusions and Future Work\\\\n\\\\nKnowledge distillation is a technique that helps smaller language models adopt the strengths of larger ones. AI solutions become more accessible, efficient, and reliable by using methods like data augmentation, knowledge elicitation, and efficient distillation algorithms. As AI technology advances, there will be a growing need for more advanced KD methods. Future research could explore several areas, including:\\\\n\\\\n* **Advancing Data Selection and Filtering Techniques:** As the volume of LLM training data grows, efficient data selection for knowledge distillation (KD) is essential. Research should focus on automatically identifying valuable data for distillation into smaller models.\\\\n* **Mitigating Catastrophic Forgetting:** Continued fine-tuning of LLMs on specific tasks or domains can lead to catastrophic forgetting of previously learned knowledge. Future research needs to explore methods to overcome this challenge.\\\\n* **Exploiting Richer Knowledge from Teacher LLMs:** Existing KD methods use teacher LLM outputs as labels for training smaller models. Future research should explore ways to use richer knowledge from teachers.\\\\n* **Advancing Weak-to-Strong Distillation:** Explore techniques to enable the distillation of knowledge from weaker or less accurate teacher models to stronger student models.\\\\n\\\\n## Further Resources\\\\n\\\\n* Paper: <https://arxiv.org/pdf/2402.13116>\\\\n* [DistilBERT: A Distilled Version of BERT](https://zilliz.com/learn/distilbert-distilled-version-of-bert)\\\\n* [Retrieval Augmented Generation (RAG)](https://zilliz.com/learn/Retrieval-Augmented-Generation)\\\\n* [CLIP Object Detection: Merging AI Vision with Language Understanding](https://zilliz.com/learn/CLIP-object-detection-merge-AI-vision-with-language-understanding)\\\\n* [What are Vector Databases and How Do They Work?](https://zilliz.com/learn/what-is-vector-database)\\\\n* [[2306.08543] MiniLLM: Knowledge Distillation of Large Language Models](https://arxiv.org/abs/2306.08543)\\\\n\\\\nUpdated on Nov 23, 2024\\\\n\\\\n* [Haziqa Sajid](/authors/_Haziqa_Sajid)\\\\n\\\\n  Digital Storytelling for Data, AI, B2B & SaaS\\\\n\\\\n[Next: RouteLLM: An Open-Source Framework for Navigating Cost-Quality Trade-Offs in LLM Deployment](/learn/routellm-open-source-framework-for-navigate-cost-quality-trade-offs-in-llm-deployment)\\\\n\\\\n### Content\\\\n\\\\n* [What is Knowledge Distillation (KD)?](/learn/knowledge-distillation-from-large-language-models-deep-dive#What-is-Knowledge-Distillation-KD)\\\\n* [Data Augmentation (DA) in Knowledge Distillation](/learn/knowledge-distillation-from-large-language-models-deep-dive#Data-Augmentation-DA-in-Knowledge-Distillation)\\\\n* [Methodologies Driving Knowledge Distillation for LLMs](/learn/knowledge-distillation-from-large-language-models-deep-dive#Methodologies-Driving-Knowledge-Distillation-for-LLMs)\\\\n* [Impact and Implications of Knowledge Distillation for LLMs](/learn/knowledge-distillation-from-large-language-models-deep-dive#Impact-and-Implications-of-Knowledge-Distillation-for-LLMs)\\\\n* [Conclusions and Future Work](/learn/knowledge-distillation-from-large-language-models-deep-dive#Conclusions-and-Future-Work)\\\\n* [Further Resources](/learn/knowledge-distillation-from-large-language-models-deep-dive#Further-Resources)\\\\n\\\\n#### Start Free, Scale Easily\\\\n\\\\nTry the fully-managed vector database built for your GenAI applications.\\\\n\\\\n[Try Zilliz Cloud for Free](https://cloud.zilliz.com/signup?utm_page=knowledge-distillation-from-large-language-models-deep-dive&utm_button=right_CTA)\\\\n\\\\n## Keep Reading\\\\n\\\\n[### What are Private LLMs? Running Large Language Models Privately - privateGPT and Beyond\\\\n\\\\nPrivate LLMs enhance data control through customization to meet organizational policies and privacy needs, ensuring legal compliance and minimizing risks like data breaches. Operating in a secure environment, they reduce third-party access, protecting sensitive data from unauthorized exposure\\u200b. Private LLMs can be designed to integrate seamlessly with an organization\\'s existing systems, networks, and databases. Organizations can implement tailored security measures in private LLMs to protect sensitive information.](/learn/what-are-private-llms)\\\\n[### LLM-Eval: A Streamlined Approach to Evaluating LLM Conversations\\\\n\\\\nIn this piece, we\\'ll talk about a method called LLM-Eval, which is used to evaluate the response quality of an LLM.](/learn/streamlined-approach-to-evaluating-llm-conversations)\\\\n[### Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text\\\\n\\\\nThis blog will discuss the growing need to detect machine-generated text, past detection methods, and a new approach: Binoculars.](/learn/spotting-llms-with-binoculars-zero-shot-detection-of-machine-generated-text)\\\\n\\\\n### AI Assistant\"\\n      },\\n      {\\n        \"url\": \"https://openreview.net/forum?id=5h0qf7IBZZ\",\\n        \"title\": \"MiniLLM: Knowledge Distillation of Large Language Models\",\\n        \"content\": \"Knowledge Distillation (KD) is a promising technique for reducing the high computational demand of large language models (LLMs).\",\\n        \"score\": 0.9255605,\\n        \"raw_content\": \"## MiniLLM: Knowledge Distillation of Large Language Models\\\\n\\\\n### [Yuxian Gu](/profile?id=~Yuxian_Gu1), [Li Dong](/profile?id=~Li_Dong1), [Furu Wei](/profile?id=~Furu_Wei1), [Minlie Huang](/profile?id=~Minlie_Huang1)\\\\n\\\\nPublished: 16 Jan 2024, Last Modified: 15 Mar 2024\\\\nICLR 2024 poster\\\\nEveryone\\\\n\\\\n[Revisions](/revisions?id=5h0qf7IBZZ)\\\\n\\\\n[BibTeX](#)\\\\n\\\\n**Code Of Ethics:** I acknowledge that I and all co-authors of this work have read and commit to adhering to the ICLR Code of Ethics.\\\\n\\\\n**Keywords:** Large Lanauge Models, Knowledge Distillation\\\\n\\\\n**Submission Guidelines:** I certify that this submission complies with the submission instructions as described on <https://iclr.cc/Conferences/2024/AuthorGuide>.\\\\n\\\\n**TL;DR:** We propose a knowledge distillation method for Large Language Models with minimizing the reverse KL divergence as the objective.\\\\n\\\\n**Abstract:**\\\\n\\\\nKnowledge Distillation (KD) is a promising technique for reducing the high computational demand of large language models (LLMs). However, previous KD methods are primarily applied to white-box classification models or training small models to imitate black-box model APIs like ChatGPT. How to effectively distill the knowledge of white-box LLMs into small models is still under-explored, which becomes more important with the prosperity of open-source LLMs. In this work, we propose a KD approach that distills LLMs into smaller language models. We first replace the forward Kullback-Leibler divergence (KLD) objective in the standard KD approaches with reverse KLD, which is more suitable for KD on generative language models, to prevent the student model from overestimating the low-probability regions of the teacher distribution. Then, we derive an effective optimization approach to learn this objective. The student models are named MiniLLM. Extensive experiments in the instruction-following setting show that MiniLLM generates more precise responses with higher overall quality, lower exposure bias, better calibration, and higher long-text generation performance than the baselines. Our method is scalable for different model families\\\\nwith 120M to 13B parameters. Our code, data, and model checkpoints can be found in <https://github.com/microsoft/LMOps/tree/main/minillm>.\\\\n\\\\n**Anonymous Url:** I certify that there is no URL (e.g., github page) that could be used to find authors\\' identity.\\\\n\\\\n**Supplementary Material:**  [zip](/attachment?id=5h0qf7IBZZ&name=supplementary_material \\\\\"Download Supplementary Material\\\\\")\\\\n\\\\n**No Acknowledgement Section:** I certify that there is no acknowledgement section in this submission for double blind review.\\\\n\\\\n**Primary Area:** generative models\\\\n\\\\n**Submission Number:** 2166\\\\n\\\\nAdd:\\\\n\\\\n#### **Paper Decision**\\\\n\\\\nDecision\\\\nby Program Chairs\\\\n16 Jan 2024, 06:52 (modified: 16 Feb 2024, 15:38)\\\\nEveryone\\\\n\\\\n[Revisions](/revisions?id=dcBGjfVsIi)\\\\n\\\\n**Decision:** Accept (poster)\\\\n\\\\nAdd:\\\\n\\\\n#### Meta Review of Submission2166 by Area Chair Ao5S\\\\n\\\\nMeta Review\\\\nby Area Chair Ao5S\\\\n05 Dec 2023, 16:14 (modified: 16 Feb 2024, 15:27)\\\\nEveryone\\\\n\\\\n[Revisions](/revisions?id=zROjSOOvrB)\\\\n\\\\n**Metareview:**\\\\n\\\\nThis paper proposes a distillation method for large language models based on optimizing the reverse KL and not the forward KL.\\\\n\\\\n**Justification For Why Not Higher Score:**\\\\n\\\\nThe method requires several tricks to stabilize training.\\\\n\\\\n**Justification For Why Not Lower Score:**\\\\n\\\\nThere was a consensus among reviewers that this paper should be accepted. In particular, as it seems to provide good empirical benefits compared to baselines in extensive experiments.\\\\n\\\\nAdd:\\\\n\\\\n#### **General response to all reviewers**\\\\n\\\\nOfficial Comment\\\\nby Authors\\\\n21 Nov 2023, 09:53\\\\nEveryone\\\\n\\\\n**Comment:**\\\\n\\\\nThanks again for reviewing our paper. We hope that we were able to address your concerns in our response. As the deadline is approaching, please let us know if you have any further questions before the reviewer-author discussion period ends. We are glad to address your further concerns.\\\\n\\\\nAdd:\\\\n\\\\n#### **General response to all reviewers**\\\\n\\\\nOfficial Comment\\\\nby Authors\\\\n18 Nov 2023, 00:03\\\\nEveryone\\\\n\\\\n**Comment:**\\\\n\\\\nWe sincerely thank all the reviewers for their detailed comments and constructive suggestions, which surely help us strengthen our paper! It is encouraging that all reviewers appreciate our comprehensive experiments and strong empirical results on various evaluation sets. In addition, Reviewer HmVQ believed our proposed approach is promising in practical use, allowing more people to run LLMs, and reviewer BHa2 affirmed the usefulness of our method for future scaling endeavors. In the following, we will respond to each reviewer\\'s comments and questions respectively. We have also updated our manuscript to incorporate the reviewers\\' suggestions. The major updates are highlighted in blue in our revised submission.\\\\n\\\\nAdd:\\\\n\\\\n#### Official Review of Submission2166 by Reviewer v2PG\\\\n\\\\nOfficial Review\\\\nby Reviewer v2PG\\\\n01 Nov 2023, 09:00 (modified: 10 Nov 2023, 12:09)\\\\nEveryone\\\\n\\\\n[Revisions](/revisions?id=U9xCYMADYu)\\\\n\\\\n**Summary:**\\\\n\\\\nThe paper proposes a method called MiniLLM for knowledge distillation of large language models (LLMs). The method focuses on distilling smaller language models from generative larger language models. It replaces the forward Kullback-Leibler divergence (KLD) objective in standard knowledge distillation approaches with reverse KLD, which is more suitable for generative language models.\\\\n\\\\n**Soundness:** 3 good\\\\n\\\\n**Presentation:** 3 good\\\\n\\\\n**Contribution:** 3 good\\\\n\\\\n**Strengths:**\\\\n\\\\n* The paper introduces an application for knowledge distillation of generative language models.\\\\n* The proposed method is supported by well-structured experiments and evaluation on various datasets, demonstrating its effectiveness in generating more precise responses with higher overall quality, lower exposure bias, better calibration, and higher long-text generation performance.\\\\n\\\\n**Weaknesses:**\\\\n\\\\n(major) The novelty of this paper is limited. It is just a simple application of reverse KL Divergence to knowledge distillation. However, distill models with reverse KLD have been researched before. The claim in the abstract \\\\\"how to effectively distill the knowledge … is still under-explored\\\\\" is not convincing. For example [1]. More importantly, this paper is not cited by the authors.\\\\n\\\\n(minor) In Table 1, the student model even outperforms the teacher model which lacks intuition. Although the authors attributed such results to the exposure bias issue of teacher-forcing, I doubt there is an overfitting problem with the experiments. Could the authors provide the hyper-parameters and the variance of each experiment?\\\\n\\\\n[1] Self-Knowledge Distillation via Dropout\\\\n\\\\n**Questions:**\\\\n\\\\nSee Weaknessed.\\\\n\\\\n**Flag For Ethics Review:** No ethics review needed.\\\\n\\\\n**Rating:** 6: marginally above the acceptance threshold\\\\n\\\\n**Confidence:** 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\\\\n\\\\n**Code Of Conduct:** Yes\\\\n\\\\nAdd:\\\\n\\\\n#### **Response to Reviewer v2PG**\\\\n\\\\nOfficial Comment\\\\nby Authors\\\\n17 Nov 2023, 23:11 (modified: 17 Nov 2023, 23:13)\\\\nEveryone\\\\n\\\\n[Revisions](/revisions?id=fbU6XFe6p1)\\\\n\\\\n**Comment:**\\\\n\\\\nWe thank the reviewer for the thoughtful comments.\\\\n\\\\n**Regarding Weakness #1 (Novelty):**\\\\n\\\\nOur paper focuses on the KD of **LLMs on language generation tasks**, which is essentially different from the KD in [1] and under-explored in previous literature. In [1], reverse KLD-based KD is applied to image classification tasks, where the output space is a finite set of labels. However, the output space of LLMs on text generation tasks is much more complex, consisting of discrete token sequences with unlimited length, making it difficult and non-trivial to apply reverse KLD to the KD of LLMs.\\\\n\\\\nSpecifically, in [1], the gradient of reverse KLD can be directly computed using the student model’s output distribution. In contrast, as stated in Section 2.2, computing the reverse KLD between the student and teacher language models requires sampling sentences from  in an auto-regressive manner, and thus Policy Gradient (and the strategies we proposed) is needed to calculate the gradient of the objective. Therefore, we argue that it is novel to apply reverse KLD to KD of LLMs and design algorithms to stabilize the training process. Moreover, since [1] is related to our method, we have added it to the reference in the revision.\\\\n\\\\n**Regarding Weakness #2 (The student model outperforming the teacher model):**\\\\n\\\\nThe hyper-parameters of each experiment are provided in Appendix C.1. We train 1.5B and 760M GPT-2 models under seeds [10, 20, 30, 40, 50] and report the average Rouge-L scores together with the standard deviations:\\\\n\\\\n| Model | Dolly | SelfInst | Vicuna | S-NI | UnNI |\\\\n| --- | --- | --- | --- | --- | --- |\\\\n| Teacher (1.5B) | 27.2 (0.3) | 14.9 (0.6) | 16.5 (0.1) | 27.8 (0.7) | 33.1 (1.0) |\\\\n| MiniLLM (760M) | 26.3 (0.2) | 16.0 (0.6) | 18.1 (0.1) | 28.3 (0.6) | 36.4 (0.8) |\\\\n\\\\nNote that we train the models on one training set (Dolly) but observe that the student model outperforms the teacher model on the other 4 test sets. Therefore, we argue that the student models generalize well.\\\\n\\\\nAs reported in previous works[2], replacing teacher-forcing with policy optimization can improve the quality of the generated texts by migrating exposure bias, which is orthogonal to the benefit of KD. Since the teacher model is trained in a teacher-forcing manner, the student model can outperform the teacher model by migrating this defect.\\\\n\\\\n[1] Self-Knowledge Distillation via Dropout.\\\\n\\\\n[2] Text generation by learning from demonstrations. 2021. In ICLR.\\\\n\\\\nAdd:\\\\n\\\\n#### Official Review of Submission2166 by Reviewer HmVQ\\\\n\\\\nOfficial Review\\\\nby Reviewer HmVQ\\\\n30 Oct 2023, 16:22 (modified: 10 Nov 2023, 12:09)\\\\nEveryone\\\\n\\\\n[Revisions](/revisions?id=4dpPpr1zQI)\\\\n\\\\n**Summary:**\\\\n\\\\nThis work primarily concerns distillation of large language models (LLMs) into smaller, more portable versions. Compared to standard distillation approaches, the authors advocate the substitution of reverse KL instead of the more typical forward KL divergence objective. This incentivizes the model to pursue mode-seeking behavior, rather than coverage-seeking behavior, leading to more precise answers, with a lower probability of generating data outside of the teacher distribution. A policy gradient objective function is modified with single-step decomposition, teacher-mixed sampling, and length normalization to further improve optimization. Experiments with three families of LLMs (GPT-2, OPT, LLaMA) on a variety of benchmarks show that the proposed method (MiniLLM) indeed outperforms the baseline distillation approaches, across a range of student sizes.\\\\n\\\\n**Soundness:** 3 good\\\\n\\\\n**Presentation:** 4 excellent\\\\n\\\\n**Contribution:** 2 fair\\\\n\\\\n**Strengths:**\\\\n\\\\n## S1. Relevant topic\\\\n\\\\nGiven the recent advances and widespread usage of LLMs, ways of compressing models for faster and cheaper deployment can have significant real-world impacts in promoting wider spread usage of such models. The proposed approach shows promise being able to reduce model size without suffering as much performance decay as the baseline approach (Fig 1). This can have the effect of allowing more people to run LLMs, with the hardware they have available.\\\\n\\\\n## S2. Experiments\\\\n\\\\n1. Models: The experiments are on 3 model families (GPT-2, OPT, LLaMA), across a range of student model sizes (3 each for GPT-2 and OPT). This is a pretty good spread and helps give a sense of how well the proposed method generalizes, and the relation between student model size and performance.\\\\n2. Evaluation: Models are evaluated on DollyEval, SelfInst, VicunaEval, S-NI, and UnNI. Rouge-L, GPT4, and human evaluation are used as metrics. Results are reported on 5 generations from separate random seeds, which gives a better sense of the evaluation’s reliability.\\\\n3. Results: The main results suggest that MiniLLM indeed outperform the baselines, and occasionally even the teacher in certain cases. Taken at face value, this is pretty impressive, as some of the student models are considerably smaller (>10x for GPT=2, 10x for OPT). However, I have some concerns about the metrics and whether they’re capturing the full picture here (see W1.1).\\\\n\\\\n## S3. Writing\\\\n\\\\nI’ve listed a few miscellaneous corrections below, but overall, the writing is fairly clear and well-written.\\\\n\\\\n**Weaknesses:**\\\\n\\\\n## W1. Reverse KL vs Forward KL\\\\n\\\\nOne of the primary contributions of the paper is the substitution of reverse KL Divergence for forward KL divergence. This leads the student model to pursue “mode-seeking behavior”, as opposed to “coverage-seeking behavior”. While this does cut down on unrealistic generation samples, the trade-off is that such an approach will cause much of the long tail to be lost as well. This leads to a couple concerns:\\\\n\\\\n1. The loss of sample diversity is not captured by the paper’s metrics, which primarily focus on realism/precision, so the baseline forward KL divergence is at a distinct disadvantage. Specifically, the metrics specifically measure where forward KL is weakest (correctness of samples), while ignoring where it is strongest (sample coverage). As such, the evaluation is somewhat unfair. Some sort of metric that captures sample diversity may yield a different story.\\\\n2. The long-tail knowledge of LLMs is arguably one of their most impressive and valuable properties, so sacrificing this in the name of realism is somewhat disappointing. In particular, this also raises potential ethical or fairness issues, as loss of diversity could lead to loss of minority representation or amplification of stereotypes.\\\\n3. Why do we have to make this tradeoff in the first place? Why not use both forward and reverse KL (see Q1), as in [a]?\\\\n\\\\n## W2. Novelty/Contributions\\\\n\\\\nFrom the abstract and introduction, it would seem that that the primary contributions are a) the focus on white-box KD for generative LLMs and b) the substitution of reverse KL instead of the more typical forward KL. Additionally, an amalgam of modifications (single-step decomposition, teacher-mixed sampling, length normalization) improves the policy gradient objective function to the final form (Equation 7) used in this paper. Some concerns/questions:\\\\n\\\\n1. This is not a reason for rejection in and of itself, but individually, neither of these are particularly new concepts. White-box KL has been explored in the past, and the merits of forward vs reverse KL (as well as other divergences) for generative modeling has also been well explored.\\\\n2. It’s not clear how related whitebox KD for generative LLMs and a reverse KL optimization are. In fact, they seem almost entirely orthogonal from each other.\\\\n3. It’s not clear from the Methods section how whitebox KL was used in the method. Where does having the teacher model’s parameters play a role?\\\\n4. The methods in Section 2.2 seems to be a series of cobbled together heuristics, and it appears that they aren’t necessarily novel either, as there are clear connections with (cited) prior work. I’m not necessarily saying that that’s a bad thing to have as part of the method, but it doesn’t appear to be something that should be counted as a contribution of this work.\\\\n\\\\n## Miscellaneous:\\\\n\\\\n* The name “MiniLLM” doesn’t fully capture the method. Yes, the model is a smaller LLM, but the same can be said of a distilled LLM learned by forward KL divergence as well, so the name fails to distinguish one of the primary points of the paper.\\\\n* pg 2: “finite-number classes” => “a finite number of classes”\\\\n* Appendix entries out of order\\\\n* pg 5: “Ouyang et al. (2022)” citation at top of the page should be parenthetical?\\\\n* pg 9: Sec 4 – Knowledge Distillation: [b] may be a relevant related work\\\\n* pg 9: Fig 8: The y-axis says “Forward KLD”, while the caption says “reverse KLD”. Also, doesn’t this graph imply that w/o teacher-mixed sampling is better, if trained long enough?\\\\n\\\\n[a] Chen, Liqun, et al. \\\\\"Symmetric variational autoencoder and connections to adversarial learning.\\\\\" AISTATS, 2018.  \\\\n[b] Liang, K., et al. \\\\\"Mixkd: Towards efficient distillation of large-scale language models.\\\\\" ICLR 2021.\\\\n\\\\n**Questions:**\\\\n\\\\nQ1. Given that forward and reverse KL each clearly have their own advantages and disadvantages, why not use both, e.g. as in [a]? See also [c] for a more general treatment of f-divergences for generative modeling.\\\\n\\\\nQ2. The student models outperforming the teacher model in Table 1 is somewhat surprising. Why do you think this is the case? Does it have to do with the specific choice of metrics? I’m somewhat doubtful for example that a 120M parameter GPT-2 model is truly outperforming the 1.5 B parameter teacher model.\\\\n\\\\n[a] Chen, Liqun, et al. \\\\\"Symmetric variational autoencoder and connections to adversarial learning.\\\\\" AISTATS, 2018.  \\\\n[c] Nowozin, Sebastian, Botond Cseke, and Ryota Tomioka. \\\\\"f-gan: Training generative neural samplers using variational divergence minimization.\\\\\" NeurIPS 2016.\\\\n\\\\n**Flag For Ethics Review:** No ethics review needed.\\\\n\\\\n**Rating:** 5: marginally below the acceptance threshold\\\\n\\\\n**Confidence:** 3: You are fairly confident in your assessment. It is possible that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work. Math/other details were not carefully checked.\\\\n\\\\n**Code Of Conduct:** Yes\\\\n\\\\nAdd:\\\\n\\\\n#### **Response to Reviewer HmVQ (part 1)**\\\\n\\\\nOfficial Comment\\\\nby Authors\\\\n17 Nov 2023, 23:26 (modified: 17 Nov 2023, 23:31)\\\\nEveryone\\\\n\\\\n[Revisions](/revisions?id=8KScVBLDkJ)\\\\n\\\\n**Comment:**\\\\n\\\\nWe thank the reviewer for the detailed and thoughtful comments. We will follow the suggestions about the paper writing and consider a better name for our method.\\\\n\\\\n**Regarding W1 and Q1 (Forward KLD v.s. Reverse KLD):**\\\\n\\\\n**1. Diversity measurement**\\\\n\\\\nIn Table 3, we report the fraction of responses’ distinct 4-grams and the test loss, which measures the diversity and mode coverage of the model generation. More discussion can be found in the “Generation Diversity” paragraph in Section 3.3. In summary, the diversity does not decrease much (Dist-4: 99.5 v.s. 99.0), and the student model still covers most of the modes of the teacher model (test loss: 3.89 v.s. 3.95).\\\\n\\\\n**2. The long tail part of the distribution**\\\\n\\\\nWe argue that our method will not sacrifice the long-tail knowledge of LLMs but only cause the sampled sentences to be less diverse (for example, the model will output similar responses with different random seeds). This is because:\\\\n\\\\n* The long-tail knowledge of LLMs is reflected by the long-tail part of the joint distribution of the input  and the output : , but our method computes reverse KLD between the conditional distribution . For example, even if  is a long-tail part,  will still be high if  is a suitable continuation of  and be covered by the student model using reverse KLD as the KD objective. In addition, reverse KLD encourages the model to ignore the low-probability regions of , and these regions have been proven harmful to language generation in previous literature[1,2].\\\\n* During MiniLLM training, we add a language modeling loss on the models’ pre-training corpus (equivalent to minimizing the forward KLD between the student output distribution and the human distribution) as a regularization to preserve the knowledge learned during pre-training.\\\\n  For potential fairness and ethical issues, we compute the HONEST score[3] on the provided dataset in [3] to measure the hurtful stereotypes of the llama-7B models’ completion. We find that the HONEST score is not affected much by the KD approaches (higher scores indicate more hurtful completions):\\\\n\\\\n  | Model | HONEST Score |\\\\n  | --- | --- |\\\\n  | SFT w/o KD | 14.86 |\\\\n  | KD | 15.22 |\\\\n  | SeqKD | 16.04 |\\\\n  | MiniLLM | 15.06 |\\\\n\\\\n**3. Why reverse KLD**\\\\n\\\\nThere is a trade-off between the mode-seeking and the coverage-seeking behavior because the small model has low capacity and cannot cover all the modes of the large model, as stated in Section 2. There are three reasons that we only use reverse KLD for KD on the instruction-following datasets in our experiments:\\\\n\\\\n* Inspired by [4], we add a language modeling loss  on the plain-text corpus, which is already a regularization to avoid the student model losing much of the long tail.\\\\n* We find that the linguistical diversity and the coverage of the real data distribution are not affected much by mainly considering reverse KLD (see the paragraph “Generation Diversity” in section 3.3).\\\\n  Besides the role of , we also suspect that the student model has the capacity to cover the main modes of , and most long-tail parts of  are noises, as shown in previous works[1,2].\\\\n* In our pilot experiments, we tried combining reverse and forward KLD by summing the losses with the ratio 1:1, based on GPT-2-base with GPT-2-xLarge as the teacher, and compared the Rouge-L scores on the test sets. The results are shown in the following table. We can see that the Rouge-L scores were not affected much, indicating that reverse KLD is enough for KD in our setting. As a result, to keep the simplicity of the method, we did not add the forward KLD in our setting.\\\\n\\\\n  | Model | Dolly | SelfInst | Vicuna | S-NI | UnNI |\\\\n  | --- | --- | --- | --- | --- | --- |\\\\n  | MiniLLM | 24.6 | 13.2 | 16.9 | 25.3 | 30.1 |\\\\n  | MiniLLM+forvward KLD | 23.4 | 13.8 | 16.9 | 24.7 | 29.3 |\\\\n\\\\n  We believe there are other ways to combine reverse and forward KLD, like in [a] and [c], and will explore them in future work.\\\\n\\\\n(continue in part 2)\\\\n\\\\nAdd:\\\\n\\\\n##### Replying to Response to Reviewer HmVQ (part 1)\\\\n\\\\n#### **Response to Reviewer HmVQ (part 2)**\\\\n\\\\nOfficial Comment\\\\nby Authors\\\\n17 Nov 2023, 23:30\\\\nEveryone\\\\n\\\\n**Comment:**\\\\n\\\\n**Regarding W2:**\\\\n\\\\n**Point 1 & 4 (Novelty)**\\\\n\\\\nWe study the **white-box KD of LLMs on text generation tasks**, but previous works on white-box KD focus on the image and text classification models, which differ largely from current LLMs. KD of LLMs has its own difficulty, and directly transferring previous white-box KD methods to LLMs does not work well (see the KD lines in our experiments). This is because LLMs generate answers auto-regressively, yielding a much larger label space than image and text classification tasks. Given the low capacity of the student model, there should be a trade-off between the mode-seeking and mode-average behavior. We point out this issue and provide a solution.\\\\n\\\\nFor the same reason, even if the properties of reverse v.s. forward KLD have been explored, applying reverse KLD to the KD of LLMs is still non-trivial, as stated in Section 2.2, and thus the three strategies are needed. Some of the strategies are inspired by prior work, but they are themselves novel:\\\\n\\\\n* Single-step Decomposition: Prior work only shows the importance of the first-step reward, but we propose to decompose it from the total gradient.\\\\n* Teacher-mixed Sampling: The idea of mixing the teacher distribution is novel and the cited works are about analyzing the reward-hacking phenomenon, and the derivation of importance sampling.\\\\n* Length Regularization: This strategy is inspired by our pilot experiments and unrelated to prior works.\\\\n\\\\nIn summary, the contributions of our work are\\\\n\\\\n* Discussion on the difficulty of knowledge distillation of LLMs, which is practical but far from solved.\\\\n* A novel KD objective for LLMs and a stable training approach.\\\\n* Extensive experiments on diverse datasets and model scaling property, which is essential for the practical use of the method on real-world LLMs.\\\\n\\\\n**Point 2 & 3 (Definition of white-box KD)**\\\\n\\\\nWe follow the definition in [5], where black-box KD refers to the scenario where only the API of the teacher model is available (only the generated sentences, not including the output distribution)[6,7], and other cases are white-box KD. MiniLLM belongs to the white-box KD because we need the model parameters to compute output distribution. In other words, we study KD when the teachers’ output distribution is available, which is related to using reverse KLD for optimization. We have clarified the description of “white-box KD” in the introduction of the revised paper.\\\\n**Regarding Question #2 (The student model outperforming the teacher model):**\\\\n\\\\nWe suspect the reason is related to exposure bias, i.e., the discrepancy between the MLE training and text generation phases. Since the teacher model is fine-tuned with MLE on the instruction following dataset, it suffers from exposure bias. However, MiniLLM is trained with policy optimization, which mitigates exposure bias in language generation, verified by both prior work[8] and our experiments in Figure 6. Therefore, a small model with less exposure bias (MiniLLM) is entirely possible to outperform a large model with more exposure bias. The metrics we use are the common metrics to evaluate instruction-following (Rouge-L, GPT-4 feedback, human evaluation)[9,10]. We leave the study of how the choice of metrics related to this phenomenon to future work.\\\\n\\\\n**Regarding “doesn’t this graph (Figure 8) imply that w/o teacher-mixed sampling is better, if trained long enough?”**\\\\n\\\\nMiniLLM w/o Teacher-Mixed Sampling shows the reward hacking phenomenon[11], where the model obtains high reward (low reverse KLD) but low scores on the final evaluation metrics (Rouge-L and GPT4 feedback in Table 4).\\\\n\\\\n[1] The Curious Case of Neural Text Degeneration. 2020. In ICLR.\\\\n\\\\n[2] Tailoring Language Generation Models under Total Variation Distance. 2021. In ICLR.\\\\n\\\\n[3] HONEST: Measuring Hurtful Sentence Completion in Language Models. 2022. In ACL.\\\\n\\\\n[4] Training language models to follow instructions with human feedback. 2022. In NeurIPS.\\\\n\\\\n[5] A Survey on Model Compression for Large Language Models.\\\\n\\\\n[6] Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%\\\\\\\\* ChatGPT Quality.\\\\n\\\\n[7] Instruction Tuning with GPT-4.\\\\n\\\\n[8] Text generation by learning from demonstrations. 2021. In ICLR.\\\\n\\\\n[9] Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ Tasks. 2022. In EMNLP.\\\\n\\\\n[10] LIMA: Less Is More for Alignment. 2023. In NeurIPS.\\\\n\\\\n[11] Defining and Characterizing Reward Hacking. 2022. In NeurIPS.\\\\n\\\\nAdd:\\\\n\\\\n#### Official Comment by Reviewer HmVQ\\\\n\\\\nOfficial Comment\\\\nby Reviewer HmVQ\\\\n19 Nov 2023, 19:15\\\\nEveryone\\\\n\\\\n**Comment:**\\\\n\\\\nI thank the authors for their thorough responses, which I’ve read along with the other reviews (and author responses).\\\\n\\\\n### Novelty\\\\n\\\\nWhile I acknowledge the authors effort in making reverse KL work for distilling LLMs in their paper, I still believe the novelty here is being overstated. In particular, Section 2.1 is still written as if this work is the first ever to consider reverse KL for generative modeling, without citing many of the prior work, which while perhaps pre-dating the recent trend of LLMs, is still relevant.\\\\n\\\\n### Diversity\\\\n\\\\nOn diversity, could the authors explain more what the metrics for diversity measure?\\\\n\\\\n* Dist-4: My understanding is that this is a measure of the number of unique 4-grams, but reported as some sort of proportion. What is the numerator and denominator in this proportion?\\\\n* Loss: It’s not clear to me how this is measure of diversity. Rather this would seem more to be a measure of how probable the generated text is from the training distribution.\\\\n\\\\nFrom the response, I’m also getting a mixed bag for interpreting the motivation and the results. It feels like the authors are simultaneously trying to argue for the value of reverse KL because it prioritizes coverage over covering modes (because low probability regions are harmful), and yet they are also arguing that coverage is in fact still intact?\\\\n\\\\n### Whitebox\\\\n\\\\nThank you for the clarification on the definition of white box here. There’s still potential for confusion here though, as the authors are using whitebox to refer to having the teacher model’s output probabilities; in many adversarial attack papers, having access to the model’s output is still considered an assumption of blackbox attacks.\\\\n\\\\nAdd:\\\\n\\\\n##### Replying to Official Comment by Reviewer HmVQ\\\\n\\\\n#### **Further Response to Reviewer oknc**\\\\n\\\\nOfficial Comment\\\\nby Authors\\\\n20 Nov 2023, 02:54\\\\nEveryone\\\\n\\\\n**Comment:**\\\\n\\\\nWe thank the reviewer for their comments. Further responses and clarifications are as follows:\\\\n\\\\n**Regarding Novelty**\\\\n\\\\nWe have clarified that \\\\\"we study the property of reverse KLD for KD of LLMs\\\\\" in section 2.1 and added relevant citations.\\\\n\\\\n**Regarding Diversity**\\\\n\\\\n* “Dist-4”[9] is a fraction: , where  is the number of the distinct 4-grams in the generated responses and  is the total number of 4-grams. It is a widely used metric to measure the generation diversity of a language model.\\\\n* Loss: The loss we reported in the original response and Table 3 is the language modeling loss: . Therefore, it measures \\\\\"how probable the instances in the training distribution are from the model distribution\\\\\", rather than \\\\\"how probable the generated text is from the training distribution\\\\\". We have clarified this in the latest revision of our paper.\\\\n\\\\n  In other words, loss measures the mode coverage of the real data distribution because it is essentially the forward KLD between the real data distribution and the model output distribution. This relates to diversity as in the ability to generate different generations given one context with different random seeds. Although this diversity is sacrificed to some extent (MiniLLM 3.95 v.s. SeqKD 3.91 in Table 3), we argue this is acceptable in practice because (1) the absolute value of the loss increase is small (2) many applications of test generation only require one but precise answer (like summarization, question answering, and coding).\\\\n\\\\nThe main point of the “Forward KLD v.s. Reverse KLD” part in our response is that using reverse KLD for MiniLLM  \\\\n(1) **will not** lose the long-tail knowledge of LLMs (because we consider , not  and add );\\\\n\\\\n(2) **will not** introduce fairness and ethical issues (verified by the HONEST metrics);\\\\n\\\\n(3) **will probably** lose the diversity of the generated sentences (because low-probability regions of  are not covered), but the diversity loss is not large (verified by the results in Table 3);\\\\n\\\\n(4) is sufficient for KD of LLMs and simply combining forward KLD does not yield better performance.\\\\n\\\\nIn summary, we do not argue that coverage is in fact still intact (the Dist-4 indeed decreases and the loss indeed increases). We argue that using reverse KLD allows the MiniLLM to ignore modes that are small or even noisy low-probability regions of  (not ) but still covering **major** (not all) parts of the teacher distribution, leading to a slight and acceptable drop in diversity and improvement in generation quality. This is sufficient for KD of LLMs in text generation.\\\\n\\\\n**White-box**\\\\n\\\\nIn the context of KD for LLMs, it is a common practice to include the scenario where the output distributions are available in white-box KD[1,2,3], mainly to distinguish from the methods that only use the APIs (output distributions are generally unavailable in model APIs).\\\\nIf the reviewer finds it necessary, we can clarify the difference between the “division of white and black box” in KD for LLMs and adversarial attacks in the footnote to prevent misunderstanding from readers familiar with the adversarial attacks.\\\\n\\\\n[1] A Survey on Model Compression for Large Language Models.\\\\n\\\\n[2] Lion: Adversarial Distillation of Closed-Source Large Language Model.\\\\n\\\\n[3] LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions.\\\\n\\\\nAdd:\\\\n\\\\n##### Replying to Further Response to Reviewer oknc\\\\n\\\\n#### Official Comment by Reviewer HmVQ\\\\n\\\\nOfficial Comment\\\\nby Reviewer HmVQ\\\\n21 Nov 2023, 19:32\\\\nEveryone\\\\n\\\\n**Comment:**\\\\n\\\\nThank you for adding the clarifications to Section 2.1.\\\\n\\\\nDist-4: Given the definition of this metric, I find it a little surprising that everything is 99+%. Can you also report  and  separately?\\\\n\\\\nI still find the statements in bullets 1-4 to be a little strong. The statements \\\\\"will not lose the long-tail knowledge of LLMs\\\\\" and \\\\\"using reverse KLD allows the MiniLLM to ignore modes that are small or even noisy low-probability regions\\\\\" are contradictory as the long-tail is by definition low-probability. While I admire the authors efforts to quantify these aspects, metrics only capture part of the story, and it\\'s still extremely difficult to tell what\\'s actually being lost here.\\\\n\\\\nI remain fairly on the fence, but I\\'m willing to raise my score to a 6.\\\\n\\\\nAdd:\\\\n\\\\n##### Replying to Official Comment by Reviewer HmVQ\\\\n\\\\n#### Official Comment\\\\n\\\\nOfficial Comment\\\\nby \\\\n21 Nov 2023, 22:41 (modified: 22 Nov 2023, 20:33)\\\\nEveryone\\\\n\\\\n[Revisions](/revisions?id=46a2AG6UpK)\\\\n\\\\n*[Deleted]*\\\\n\\\\n#### **About the Rating in the Official Review**\\\\n\\\\nOfficial Comment\\\\nby Authors\\\\n22 Nov 2023, 20:34 (modified: 23 Nov 2023, 06:24)\\\\nEveryone\\\\n\\\\n[Revisions](/revisions?id=LXQ7pJPsqt)\\\\n\\\\n**Comment:**\\\\n\\\\nWe thank the reviewer for **the willingness to raise the score to 6**. We have reported  and  in the latest version of our paper.\\\\n\\\\nHowever, we notice that the score in the rating of the official review is still 5. Could you please **also change this rating to 6**?\\\\n\\\\nAdd:\\\\n\\\\n#### Official Review of Submission2166 by Reviewer BHa2\\\\n\\\\nOfficial Review\\\\nby Reviewer BHa2\\\\n29 Oct 2023, 16:26 (modified: 10 Nov 2023, 12:09)\\\\nEveryone\\\\n\\\\n[Revisions](/revisions?id=GuIPtFb6kD)\\\\n\\\\n**Summary:**\\\\n\\\\nThis paper proposes to use Reverse KL Divergence for distilling large-language models. The paper starts from the Reverse KLD objective in section 2, describes the difference with forward KLD and its advantage that it is mode-seaking that is preferred when student has low capacity. Then in section 2.2 they review the challenges of optimizing for Reverse KLD and revisit ideas from prior work to improve it. To resolve challenges of reverse KLD, they propose 3 strategies to mitigate:\\\\n\\\\n1. Decompose gradient into the gradient for single-step prediction and long sentence prediction\\\\n2. Prevent reward hacking by mixing the teacher/student distributions for sampling next token\\\\n3. Normalize the reward to prefer longer sequences.\\\\n   They refer to Reverse KLD together with their strategies as MiniLLM.\\\\n   In section 3, they evaluate the effectiveness of MiniLLM on instruction-following generation tasks. They use various teacher/student architectures including GPT-2, OPT, and LLaMA. They compare to baselines with and without knowledge distillation. Section 3.2 provides positive improvements using MiniLLM and section 3.3 provides analysis that shows the method scales well, gives well-calibrated models, and generates diverse outputs. Section 3.4 provides ablations on the three elements of MiniLLM.\\\\n\\\\n**Soundness:** 4 excellent\\\\n\\\\n**Presentation:** 4 excellent\\\\n\\\\n**Contribution:** 4 excellent\\\\n\\\\n**Strengths:**\\\\n\\\\n* Significant gains and improvements compared with various baselines. The results show that improvements increase as the teacher gets bigger and all students at all parameter counts improve. So consistently large improvements.\\\\n* Figure 1: MiniLM is 5% better than SeqKD on GPT4 score.\\\\n* Table 1: MiniLM is up to 10% better than SFT w/o KD while KD is up to 5% better and SeqKD is up to 1% better than KD.\\\\n* Table 1: MiniLM is up to 8% better than the teacher while no other baseline surpasses the teacher.\\\\n* Comprehensive evaluations and ablations.\\\\n\\\\n**Weaknesses:**\\\\n\\\\n* The results seem to point that Reverse KLD might be harder to tune and requires all the strategies in MiniLM for performing better than baselines. This can be a challenge for reproduction and further research. I am specifically pointing to Table 4 and comparing to baseline numbers in Table 1: Why is MiniLM without either length-normalization (DollyEval GPT-4 22.4) or teacher-student distribution mixing (36.1) is significantly worse than comparable SeqKD (41.2) or KD (40.3) or SFT w/o KD (38.6) in Table 1? Does that mean Reverse KLD is generally harder to train without these strategies?\\\\n* Wall-clock time analysis of the method compared with baselines should be discussed. What is the training efficiency? How slow is the training with the MiniLM loss compared with SFT w/o KD, KD, and SeqKD? If the method is slower per iteration, what if baselines are trained for more iterations to match the wall-clock time of the method? Would they match the performance gains?\\\\n\\\\n**Questions:**\\\\n\\\\n* Page 2, introduction, line 11: How can one force q, the teacher, to do something? The teacher is not learnable. I’m assuming this is a typo and p/q\\\\\\\\_theta should be exchanged.\\\\n* Why is this work “white-box” KD? How is the method using the parameters of the teacher and not just the predictions of the teacher, p(y|x)?\\\\n* All experiments seem to be on instruction-following generation tasks. How would this distillation method perform for pretraining only? Can it help speed-up the pre-training of small models?\\\\n* Table 1: Can you provide examples of cases where the student is better than the teacher and provide a qualitative analysis of why? 8% improvement should show consistent improved behavior.\\\\n* Figure 5: Does MiniLM benefit more from scaling the teacher compared with SeqKD? Can you report the relative improvements of SeqKD and MiniLM as the teacher is scaled compared with a base teacher? If yes, it is useful for future scaling endeavors.\\\\n* Figure 8: y-axis says “Forward KLD” but the caption says “reverse KLD”, which value is plotted?\\\\n* Does the method have any hyperparameters specific to MiniLLM? For example, is there any thresholding of the ratio of q/q or p/q in Eq. 7 or epsilon in the denominator? If so, can you provide ablations?\\\\n\\\\nSuggestions\\\\n\\\\n* MiniLLM is a self-contradictory name as it expands to Mini Large Language Model. Please consider changing it, for example, to MiniLM.\\\\n* Figure 1: Please consider adding more description of sequence-level KD in the caption or the intro close to the reference to Figure 1. A reader not familiar with the literature does not learn about SeqKD until page 5.\\\\n* Eq 1 and A.1: For consistency it would help to use the KL with negative sign throughout (Eq. 1 is without negative sign but Eq. 8 is with negative sign). It would also help to highlight the difference in Eq 13 and 14 by color. It’s hard to notice the difference.\\\\n* Eq 7: It might help to use single/long gradients to simplify this equation and other predefined terms. This equation is not easily digestible as a summary equation.\\\\n\\\\nTypos:\\\\n\\\\n* Page 2: “... approximately minimizes the forward KLD” -> “minimize”\\\\n* Page 3: “... the quality of the each …” -> “the quality of each”\\\\n\\\\n**Flag For Ethics Review:** No ethics review needed.\\\\n\\\\n**Rating:** 8: accept, good paper\\\\n\\\\n**Confidence:** 5: You are absolutely certain about your assessment. You are very familiar with the related work and checked the math/other details carefully.\\\\n\\\\n**Code Of Conduct:** Yes\\\\n\\\\nAdd:\\\\n\\\\n#### **Response to Reviewer BHa2 (part 1)**\\\\n\\\\nOfficial Comment\\\\nby Authors\\\\n17 Nov 2023, 23:39 (modified: 17 Nov 2023, 23:54)\\\\nEveryone\\\\n\\\\n[Revisions](/revisions?id=cOiIhmbD5r)\\\\n\\\\n**Comment:**\\\\n\\\\nWe thank the reviewer for the detailed and encouraging comments. We will follow the suggestions about the paper writing and consider a better name for our method.\\\\n\\\\n**Regarding the Weakness:**\\\\n\\\\n**1. Strategies to train MiniLLM**\\\\n\\\\nSince longer sentences tend to have larger reverse KLD, length normalization prevents the model from outputting short and simple responses. And teacher-mixed sampling migrates the reward-hacking in policy optimization[1]. We provide all our codes in the supplementary material and will open-source all the codes, data, and model checkpoints for reproduction and further research.\\\\n\\\\n**2. Training efficiency**\\\\n\\\\nThe training time with MiniLLM is generally less than 2 times of SFT and KD. Note that since we consider KD approaches on the downstream datasets (e.g., instruction-following) where the number of training instances is small, the total training time will not increase much with MiniLLM.\\\\n\\\\nWe also evaluate the results if we train the student model with vanilla KD for the same amount of time as MiniLLM based on the GPT-2-base model (training for 40 epochs). The results show that the original training time (20 epochs) is enough for the model to converge, and training for more steps hurts the performance.\\\\n\\\\n| Method | Valid Rouge-L | Test Rouge-L |\\\\n| --- | --- | --- |\\\\n| KD (20 epochs) | 25.3 | 22.8 |\\\\n| KD (40 epochs) | 24.3 | 21.0 |\\\\n| MiniLLM | 27.4 | 24.6 |\\\\n\\\\n**Regarding the Questions:**\\\\n\\\\n1. Yes, this is a typo. We have fixed it in the revision.\\\\n2. We follow the definition in [2]. Black-box KD refers to the scenario where only the teacher model\\'s API (only the generated sentences, not including the probabilities) is available[3,4], and other cases are white-box KD. In our case, we need the model parameters to obtain p(y|x) to compute the reverse KLD. We have clarified the description of \\\\\"white-box KD\\\\\" in the introduction of the revised paper.\\\\n3. We did not conduct experiments during the pre-training phase and will leave this to future work.\\\\n\\\\n(continue in part 2)\\\\n\\\\nAdd:\\\\n\\\\n##### Replying to Response to Reviewer BHa2 (part 1)\\\\n\\\\n#### **Response to Reviewer BHa2 (part 2)**\\\\n\\\\nOfficial Comment\\\\nby Authors\\\\n17 Nov 2023, 23:55\\\\nEveryone\\\\n\\\\n**Comment:**\\\\n\\\\n4. Two examples from the Unnatural-Instructions test set on which the 760M MiniLLM outperforms the 1.5B teacher model are as follows:\\\\n\\\\n   **Example 1**\\\\n\\\\n   ```\\\\n   ## Instruction:\\\\n   You are given a sequence of steps which describe how to perform some task. Each step might reference information from a previous step. Your job is to re-order the steps so that they can be performed in order and make sense.\\\\n   ## Input:\\\\n   [\\' Mix together flour, sugar, eggs and butter\\', \\' Preheat oven to 375 degrees\\', \\' Roll out dough on floured surface\\'].\\\\n   ## Ground Truth:\\\\n   [\\' Preheat oven to 375 degrees\\', \\' Mix together flour, sugar, eggs and butter\\', \\' Roll out dough on floured surface\\']\\\\n   ## Teacher Model:\\\\n   First, preheat oven to 374 degrees. Then, mix together flour, sugar, eggs, butter, and strawberry jam. Once the oven reaches the desired temperature of 374 degrees, you can begin preparing the delicious strawberry jam bars. Have a try!\\\\n   ## MiniLLM:\\\\n   1. Preheat oven to 375 degrees\\\\n   2. Mix together flour, sugar, eggs and butter\\\\n   3. Roll out dough on floured surface\\\\n\\\\n   ```\\\\n\\\\n   **Example 2:**\\\\n\\\\n   ```\\\\n   ## Instruction:\\\\n   You will be given a paragraph of text, followed by a list of questions. For each question, you must determine the answer based on information in the paragraph.\\\\n   ## Input:\\\\n   Passage: The process of photosynthesis is used by plants to convert light energy into chemical energy that can be later used to fuel the plants\\' activities. This process involves two main steps: light absorption and carbon fixation. During light absorption,plant pigment molecules absorb photons and transfer their energy to chlorophyll molecules in the thylakoid membrane. In carbon fixation,the plant uses this excited state energy to convert CO2 gas into glucose sugar.\\\\n   Question 1: What are the two main steps of photosynthesis?\\\\n   Question 2: Where does light absorption take place?\\\\n   Question 3: What happens during carbon fixation?\\\\n   ## Ground Truth:\\\\n   1.The two main steps of photosynthesis are light absorption and carbon fixation.\\\\n   2. Light absorption takes place in the thylakoid membrane.\\\\n   3. During carbon fixation, the plant uses excited state energy to convert CO2 gas into glucose sugar.\\\\n   ## Teacher Model:\\\\n   Light absorption and carbon fixation. Light absorption takes place when chlorophyll molecules in plant cells capture photons from sunlight during the process of photosynthesis. This absorption of light energy is a crucial step in the conversion of solar energy into chemical energy…\\\\n   ## MiniLLM:\\\\n   Answer 1: Light absorption and carbon fixation. \\\\n   Answer 2: Light absorption takes place in the chlorophyll molecule of the plant.\\\\n   Answer 3: In carbon fixation, the plant uses this excited state of energy to convert CO2 into glucose.\\\\n\\\\n   ```\\\\n\\\\n   From the examples, we observe that MiniLLM follows the instructions better when generating long responses. The teacher model follows the instructions at first but then generates contents unrelated to the instructions. We attribute this phenomenon to exposure bias in the teacher model[5]. During training, the teacher model predicts the next word conditioning on the prefix from real data distribution, but during inference, the prefix is from the teacher model’s distribution, introducing a discrepancy. And this discrepancy accumulates during generation, causing the responses to finally deviate from the correct answer (exposure bias).\\\\n\\\\n   In contrast, MiniLLM sees self-generated responses during training (see Algorithm 1 in Appendix B), migrating the discrepancy. This effect is also observed in [6]. To summarize, MiniLLM with less exposure bias is possible to outperform the teacher model with more exposure bias.\\\\n5. We report the relative improvement when scaling up the teacher model compared to using the 340M teacher model. We find that MiniLLM benefits slightly better than SeqKD from scaling up the teacher model.\\\\n\\\\n   | Teacher Model Size | 340M | 760M | 1.5B |\\\\n   | --- | --- | --- | --- |\\\\n   | SeqKD | 0.0% | 0.3% | 1.0% |\\\\n   | MiniLLM | 0.0% | 1.4% | 3.4% |\\\\n6. The value is Reverse KLD. We have fixed this typo in the revision.\\\\n7. The only specific hyper-parameter of MiniLLM is the  in Eq. 4, and we provide an ablation study in Appendix D.4. We find that  is generally suitable for models across sizes and larger models are more robust to the choice of .\\\\n\\\\n[1] Defining and Characterizing Reward Hacking. 2022. In NeurIPS.\\\\n\\\\n[2] A Survey on Model Compression for Large Language Models.\\\\n\\\\n[3] Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%\\\\\\\\* ChatGPT Quality.\\\\n\\\\n[4] Instruction Tuning with GPT-4.\\\\n\\\\n[5] Why Exposure Bias Matters: An Imitation Learning Perspective of Error Accumulation in Language Generation. In ACL findings.\\\\n\\\\n[6] Text generation by learning from demonstrations. 2021. In ICLR.\\\\n\\\\nAdd:\\\\n\\\\n##### Replying to Response to Reviewer BHa2 (part 2)\\\\n\\\\n#### **I thank the the authors, my concerns are resolved**\\\\n\\\\nOfficial Comment\\\\nby Reviewer BHa2\\\\n21 Nov 2023, 19:31\\\\nEveryone\\\\n\\\\n**Comment:**\\\\n\\\\nI thank the authors for their response and overall I see my concerns resolved and recommend this paper for acceptance.\\\\n\\\\n**W.1** Reverse KLD might be harder to tune… This might be a challenge for reproduction and further research.\\\\n\\\\nMy concern is resolved by the fact that the method has only one hyperparameter and the ablations on that hyperparameter in Figure 16 shows relative consistently of the selected value 0.2. Moreover, the 3 proposed strategies are shown to be useful across all experiments.\\\\n\\\\n**W.2.1** Wall-clock time … should be discussed.\\\\n\\\\nThe rebuttal provides the rough ratio of the wall-clock time for MiniLLM vs KD. I encourage the authors to add a table with the breakdown of the exact wall-clock time ratios for each parts of the MiniLLM rather than the overall rough estimate of “less than 2x”.\\\\n\\\\n**W.2.2** What if baselines are trained for more iterations to match the wall-clock time.\\\\n\\\\nThe rebuttal partially resolves my concern by providing KD results of 2x epochs. I encourage authors to provide similar results for SeqKD.\\\\n\\\\n**Questions**\\\\n\\\\nI thank the authors for answering my questions including providing examples of MiniLLM outputs compared with the teacher. I agree with the authors’ analysis of the outputs.\\\\n\\\\nAdd:\\\\n\\\\n#### Official Review of Submission2166 by Reviewer oknc\\\\n\\\\nOfficial Review\\\\nby Reviewer oknc\\\\n21 Oct 2023, 00:45 (modified: 19 Nov 2023, 02:18)\\\\nEveryone\\\\n\\\\n[Revisions](/revisions?id=QbaMsCbvCV)\\\\n\\\\n**Summary:**\\\\n\\\\nFor lowering computation cost required by large deep learning models, knowledge distillation (KD) is a popular approach. This study presents a knowledge distillation method applied to open-sourced large language models (LLMs). While the standard KD method uses a linear combination of cross entropy loss and Kullback-Leibler (KL) divergence referred to as forward KL divergence in this study, this study also examines a reverse KL divergence, which swaps teacher and student distributions and is used in computer vision and reinforcement learning literature. With the modified loss function, LMs trained on instruction-following datasets with teachers by their proposed approach (called MiniLLM) achieved higher average GPT-4 feedback scores than those trained with the same teacher model by a sequence-level KD (SeqKD) baseline.\\\\n\\\\n**Soundness:** 2 fair\\\\n\\\\n**Presentation:** 3 good\\\\n\\\\n**Contribution:** 2 fair\\\\n\\\\n**Strengths:**\\\\n\\\\n* The reviewer wants to value originality of this study as this study is focused on open-sourced LLMs as targets for knowledge distillation, and black-box APIs can change their internal behavior without notice or proper versioning.\\\\n* This paper seems to well describe the proposed method and cites prior studies that inspired the authors to introduce key concepts in their method such as reverse KL divergence.\\\\n* It is empirically shown that MiniLLMs achieved better performance than KD baselines considered in this paper with multiple evaluation settings and instruction-following datasets. It is also notable that the overall trend in Table 1 seem consistent over different student models in a variety of model sizes.\\\\n* The ablation study attempts to test multiple hypotheses made when designing the proposed loss function.\\\\n\\\\n**Weaknesses:**\\\\n\\\\n## Presentation\\\\n\\\\nThis paper needs to improve the presentation and writing.\\\\ne.g.,\\\\n\\\\n* MiniLLM model must be tautology (Mini large language model model) and should be referred to as just MiniLLM instead\\\\n* \\\\\"distill [object Object] from [object Object]\\\\\" sounds weird to the reviewer, and the reviewer suggests \\\\\"distill (knowledge of) [object Object] into [object Object]\\\\\"\\\\n* Itemized lists in this paper look very packed. Did the authors change the format and reduce space between items?\\\\n* \\\\\"generative LLMs\\\\\" and \\\\\"generative language models\\\\\" also sound strange as language models themselves are generative models. The reviewer suggests just skipping \\\\\"generative\\\\\".\\\\n* \\\\\"the vocab size\\\\\" should be \\\\\"the vocabulary size\\\\\"\\\\n* \\\\\"similar to Learning from Human Feedback (RLFH; Ouyang et al., 2022).\\\\\" misses \\\\\"Reinforcement\\\\\"\\\\n* Use [] for the second equation in Eq. (5) as well\\\\n\\\\n## GPT-4-based evaluation\\\\n\\\\nOverall experimental designs in this study look good, but the reviewer has a big concern about evaluations involving GPT-4. Specifically, it is very questionable how scientifically meaningful the evaluations are when leaving all the evaluations to GPT-4, and the reviewer did not find any reasonable justifications of using GPT-4 as part of the evaluation process. Rouge-L should be sufficient for Tables 1 and 4, and the reviewer strongly recommends use of Rouge-L instead of GPT-4 feedback (score) for Figures 1 and 5. The reviewer will improve rating if GPT-4-based evaluations are removed and replaced with Rouge-L.\\\\n\\\\n**Questions:**\\\\n\\\\n1. What is the definition of \\\\\"white-box\\\\\" KD/model in this paper? White-box in this paper sounds misleading.\\\\n2. Why is the specific  between Eqs. (5) and (6) expected to reduce the variance of the estimator in Eq. (5)?\\\\n3. What is the definition of \\\\\"Exposure Bias\\\\\" ?(conceptual definition, not mathematical definition)\\\\n4. What is \\\\\"the responses\\' distinct 4-gram proportion\\\\\"?\\\\n\\\\n**Flag For Ethics Review:** No ethics review needed.\\\\n\\\\n**Rating:** 6: marginally above the acceptance threshold\\\\n\\\\n**Confidence:** 4: You are confident in your assessment, but not absolutely certain. It is unlikely, but not impossible, that you did not understand some parts of the submission or that you are unfamiliar with some pieces of related work.\\\\n\\\\n**Code Of Conduct:** Yes\\\\n\\\\nAdd:\\\\n\\\\n#### **Response to Reviewer oknc**\\\\n\\\\nOfficial Comment\\\\nby Authors\\\\n17 Nov 2023, 23:59\\\\nEveryone\\\\n\\\\n**Comment:**\\\\n\\\\nWe thank the reviewer for the thoughtful comments and suggestions.\\\\n\\\\n**Regarding the Presentation:**\\\\n\\\\nWe will follow the reviewer’s suggestions on presentation to revise our paper. For the itemized list in the paper, we did not use the `\\\\\\\\itemize` command but instead used `\\\\\\\\bullet`. We have changed it to `\\\\\\\\itemize` for a better presentation.\\\\n\\\\n**Regarding GPT-4 Evaluation:**\\\\n\\\\nWe have replaced the GPT-4 score in Figure 1 and 5 with Rouge-L.\\\\nWe use GPT-4 for evaluation because it is studied by previous literature[1,2], where GPT-4 shows good alignment with human evaluation. This metric is also widely used in previous works to evaluate instruction-following[3,4,5].\\\\n\\\\n**Regarding the Questions:**\\\\n\\\\n1. We follow the definition in [6]. Black-box KD refers to the scenario where only the teacher model\\'s API (only the generated sentences, not including the probabilities) is available, and other cases are white-box KD. “White-box” means we need the model parameters to obtain the output probabilities to compute reverse KLD. We have clarified the description of “white-box KD” in the introduction of the revised paper.\\\\n2. does not reduce the estimator\\'s variance in Eq. 5. It is the important sampling weight to ensure that the gradient estimation by sampling from the teacher-mixed distribution  equals the original estimator.\\\\n3. Exposure bias is a mismatch between MLE training and inference[7,8]. During training, the model predicts the next token conditioning on the prefix from the real data distribution. However, the prefix is generated from the model itself during inference. Therefore, the distribution of the prefixes seen during inference might differ greatly from those encountered during training, leading to a mismatch.\\\\n4. “Distinct 4-gram”[9] is a fraction: , where  is the number of the distinct 4-grams in the generated responses and  is the total number of 4-grams. It is a widely used metric to measure the generation diversity of a language model.\\\\n\\\\n[1] G-EVAL: NLG Evaluation using GPT-4 with Better Human Alignment\\\\n\\\\n[2] Judging LLM-as-a-Judge with MT-Bench and Chatbot Arena. 2023. In NeurIPS.\\\\n\\\\n[3] Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%\\\\\\\\* ChatGPT Quality.\\\\n\\\\n[4] Instruction Tuning with GPT-4.\\\\n\\\\n[5] LIMA: Less Is More for Alignment. 2023. In NeurIPS.\\\\n\\\\n[6] A Survey on Model Compression for Large Language Models.\\\\n\\\\n[7] Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks. 2015. In NeurIPS.\\\\n\\\\n[8] Sequence Level Training with Recurrent Neural Networks. 2016. In ICLR.\\\\n\\\\n[9] A diversity-promoting objective function for neural conversation models. 2016. In NAACL.\\\\n\\\\nAdd:\\\\n\\\\n##### Replying to Response to Reviewer oknc\\\\n\\\\n#### Official Comment by Reviewer oknc\\\\n\\\\nOfficial Comment\\\\nby Reviewer oknc\\\\n18 Nov 2023, 13:10\\\\nEveryone\\\\n\\\\n**Comment:**\\\\n\\\\nThe reviewer checked responses from the authors. The reviewer wants to thank them for their clarifications and updates.\\\\n\\\\n> We have replaced the GPT-4 score in Figure 1 and 5 with Rouge-L. We use GPT-4 for evaluation because it is studied by previous literature[1,2], where GPT-4 shows good alignment with human evaluation. This metric is also widely used in previous works to evaluate instruction-following[3,4,5].\\\\n\\\\nIt may be ok if the authors use the GPT-4 score (feedback) as a supplemental evaluation metric (i.e., moving them to appendix), but it is still not either convincing enough or clear how scientifically meaningful the evaluations are, for the following reasons.\\\\n\\\\n* Being used in a few previous studies does not explain why the metric is scientifically meaningful for this study. [3] is a blog post, [4] failed to justify why GPT-4 feedback is meaningful, [5] analyzes \\\\\"Inter-Annotator Agreement\\\\\", but the protocol is unclear. Moreover, their assessment is based on labeling which response was better, or whether neither response was significantly better than the other, which is different from the scheme used in this study (score 1 - 10)\\\\n* GPT-4 is a black-box service, and its behaviors may change over time. Also, the service is updated in an untrackable manner, thus it is very challenging to reproduce experimental results based on such services (including [1] and [2]).\\\\n\\\\n> does not reduce the estimator\\'s variance in Eq. 5. It is the important sampling weight to ensure that the gradient estimation by sampling from the teacher-mixed distribution equals the original estimator.\\\\n\\\\nThe reviewer needs more clarifications for this point.\\\\nIt looks like the revised manuscript still claims setting  ... to reduce the variance of the estimator in Eq. 5 as follows\\\\n\\\\n> > Therefore, we approximately set  ... to reduce the variance of the estimator in Eq. 5\\\\n\\\\nfrom the manuscript.\\\\n\\\\nAdd:\\\\n\\\\n##### Replying to Official Comment by Reviewer oknc\\\\n\\\\n#### **Further Response to Reviewer oknc**\\\\n\\\\nOfficial Comment\\\\nby Authors\\\\n18 Nov 2023, 23:26\\\\nEveryone\\\\n\\\\n**Comment:**\\\\n\\\\nWe thank the reviewer for their comments. Further responses and clarifications are as follows:\\\\n\\\\n**Regarding GPT-4 scores**\\\\n\\\\nWe understand the reviewer\\'s concerns about the GPT-4 feedback evaluation. We have moved all GPT-4 scores in our paper to the Appendix.\\\\n\\\\n**Regarding :**\\\\n\\\\nOur choice of  reduces variance because the original importance weight  requires multiplying per-token importance weight over multiple time steps, and thus the variance of each step will accumulate to the estimator. Therefore, we truncate the products to only consider the current time step . This approximation is also used in prior works[1,2,3], where its effectiveness is empirically verified.\\\\n\\\\n[1] Text Generation by Learning from Demonstrations. 2021. In ICLR.\\\\n\\\\n[2] Offline Reinforcement Learning: Tutorial, Review, and Perspectives on Open Problems.\\\\n\\\\n[3] A deep reinforcement learning chatbot.\\\\n\\\\nAdd:\\\\n\\\\n##### Replying to Further Response to Reviewer oknc\\\\n\\\\n#### Official Comment by Reviewer oknc\\\\n\\\\nOfficial Comment\\\\nby Reviewer oknc\\\\n19 Nov 2023, 02:17\\\\nEveryone\\\\n\\\\n**Comment:**\\\\n\\\\nThe reviewer thanks the authors for the quick updates. The rating was improved, conditioned on the updates.\\\\n\\\\nThe reviewer also wants to see the clarification of  in the manuscript (footnote is fine if the space is limited)\\\\n\\\\nAdd:\"\\n      },\\n      {\\n        \"url\": \"https://github.com/Tebmer/Awesome-Knowledge-Distillation-of-LLMs\",\\n        \"title\": \"Awesome Knowledge Distillation of LLM Papers - GitHub\",\\n        \"content\": \"This survey delves into knowledge distillation (KD) techniques in Large Language Models (LLMs), highlighting KD\\'s crucial role in transferring advanced\",\\n        \"score\": 0.87166095,\\n        \"raw_content\": \"{{ message }}\\\\n\\\\n[Tebmer](/Tebmer) \\\\n/\\\\n**[Awesome-Knowledge-Distillation-of-LLMs](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs)**\\\\nPublic\\\\n\\\\n* [Notifications](/login?return_to=%2FTebmer%2FAwesome-Knowledge-Distillation-of-LLMs) You must be signed in to change notification settings\\\\n* [Fork\\\\n  68](/login?return_to=%2FTebmer%2FAwesome-Knowledge-Distillation-of-LLMs)\\\\n* [Star\\\\n   1.1k](/login?return_to=%2FTebmer%2FAwesome-Knowledge-Distillation-of-LLMs)\\\\n\\\\nThis repository collects papers for \\\\\"A Survey on Knowledge Distillation of Large Language Models\\\\\". We break down KD into Knowledge Elicitation and Distillation Algorithms, and explore the Skill & Vertical Distillation of LLMs.\\\\n\\\\n[1.1k\\\\nstars](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/stargazers) [68\\\\nforks](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/forks) [Branches](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/branches) [Tags](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/tags) [Activity](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/activity)\\\\n\\\\n[Star](/login?return_to=%2FTebmer%2FAwesome-Knowledge-Distillation-of-LLMs)\\\\n\\\\n[Notifications](/login?return_to=%2FTebmer%2FAwesome-Knowledge-Distillation-of-LLMs) You must be signed in to change notification settings\\\\n\\\\n# Tebmer/Awesome-Knowledge-Distillation-of-LLMs\\\\n\\\\n[**1** Branch](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/branches)[**0** Tags](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/tags)\\\\n\\\\nOpen more actions menu\\\\n\\\\n## Folders and files\\\\n\\\\n| Name | | Name | Last commit message | Last commit date |\\\\n| --- | --- | --- | --- | --- |\\\\n| Latest commit [Tebmer](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/commits?author=Tebmer)  [Update README.md](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/commit/c96c71a979712f44eb8629072c6ad0cc8d2a56b8) Mar 9, 2025  [c96c71a](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/commit/c96c71a979712f44eb8629072c6ad0cc8d2a56b8)\\xa0·\\xa0Mar 9, 2025  History[56 Commits](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/commits/main/) Open commit details | | |\\\\n| [imgs](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/tree/main/imgs \\\\\"imgs\\\\\") | | [imgs](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/tree/main/imgs \\\\\"imgs\\\\\") | [Update Image](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/commit/17c81b93a29736347a269ce7f3707ff0263a9cd3 \\\\\"Update Image\\\\\") | Oct 21, 2024 |\\\\n| [README.md](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/blob/main/README.md \\\\\"README.md\\\\\") | | [README.md](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/blob/main/README.md \\\\\"README.md\\\\\") | [Update README.md](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/commit/c96c71a979712f44eb8629072c6ad0cc8d2a56b8 \\\\\"Update README.md\\\\\") | Mar 9, 2025 |\\\\n|  | | |\\\\n\\\\n## Repository files navigation\\\\n\\\\n# Awesome Knowledge Distillation of LLM Papers\\\\n\\\\n## A Survey on Knowledge Distillation of Large Language Models\\\\n\\\\nXiaohan Xu1\\xa0\\xa0\\\\nMing Li2\\xa0\\xa0\\\\nChongyang Tao3\\xa0\\xa0\\\\nTao Shen4\\xa0\\xa0\\\\nReynold Cheng1\\xa0\\xa0\\\\nJinyang Li1\\xa0\\xa0\\\\nCan Xu5\\xa0\\xa0\\\\nDacheng Tao6\\xa0\\xa0\\\\nTianyi Zhou2\\\\n\\\\n1 The University of Hong Kong \\xa0\\xa0\\\\n2 University of Maryland \\xa0\\xa0\\\\n3 Microsoft \\xa0\\xa0\\\\n4 University of Technology Sydney \\xa0\\xa0\\\\n5 Peking University \\xa0\\xa0\\\\n6 The University of Sydney\\\\n\\\\n  \\\\n\\\\n*A collection of papers related to knowledge distillation of large language models (LLMs).\\\\nIf you want to use LLMs for benefitting your own smaller models training, or use self-generated knowledge to achieve the self-improvement, just take a look at this collection.*\\\\n\\\\n***We will update this collection every week. Welcome to star ⭐️ this repo to keep track of the updates.***\\\\n\\\\n> ❗️Legal Consideration: It\\'s crucial to note the legal implications of utilizing LLM outputs, such as those from ChatGPT ([Restrictions](https://openai.com/policies/business-terms)), Llama ([License](https://llama.meta.com/llama-downloads/)), etc. We strongly advise users to adhere to the terms of use specified by the model providers, such as the restrictions on developing competitive products, and so on.\\\\n\\\\n## 💡 News\\\\n\\\\n* **2024-2-20**: 📃 We released a survey paper \\\\\"**[A Survey on Knowledge Distillation of Large Language Models](https://arxiv.org/abs/2402.13116)**\\\\\". Welcome to read and cite it. We are looking forward to your feedback and suggestions.\\\\n* Update Log\\\\n\\\\n  + **2024-3-19**: Add 14 papers.\\\\n\\\\n## Contributing to This Collection\\\\n\\\\nFeel free to **open an issue/PR** or e-mail [shawnxxh@gmail.com](mailto:shawnxxh@gmail.com), [minglii@umd.edu](mailto:minglii@umd.edu), [hishentao@gmail.com](mailto:hishentao@gmail.com) and [chongyangtao@gmail.com](mailto:chongyangtao@gmail.com) if you find any missing taxonomies or papers. We will keep updating this collection and survey.\\\\n\\\\n## 📝 Introduction\\\\n\\\\n**KD of LLMs**: This survey delves into knowledge distillation (KD) techniques in Large Language Models (LLMs), highlighting KD\\'s crucial role in transferring advanced capabilities from proprietary LLMs like GPT-4 to open-source counterparts such as LLaMA and Mistral. We also explore how KD enables the compression and self-improvement of open-source LLMs by using them as teachers.\\\\n\\\\n**KD and Data Augmentation**: Crucially, the survey navigates the intricate interplay between data augmentation (DA) and KD, illustrating how DA emerges as a powerful paradigm within the KD framework to bolster LLMs\\' performance. By leveraging DA to generate context-rich, skill-specific training data, KD transcends traditional boundaries, enabling open-source models to approximate the contextual adeptness, ethical alignment, and deep semantic insights characteristic of their proprietary counterparts.\\\\n\\\\n**Taxonomy**: Our analysis is meticulously structured around three foundational pillars: **[algorithm](#kd-algorithms)**, **[skill](#skill-distillation)**, and **[verticalization](#verticalization-distillation)** -- providing a comprehensive examination of KD mechanisms, the enhancement of specific cognitive abilities, and their practical implications across diverse fields.\\\\n\\\\n**[KD Algorithms](#kd-algorithms)**: For KD algorithms, we categorize it into two principal steps: \\\\\"Knowledge Elicitation\\\\\" focusing on eliciting knowledge from teacher LLMs, and \\\\\"Distillation Algorithms\\\\\" centered on injecting this knowledge into student models.\\\\n\\\\n*Figure: An illustration of different knowledge elicitation methods from teacher LLMs.*\\\\n\\\\n  \\\\n\\\\n**[Skill Distillation](#skill-distillation)**: We delve into the enhancement of specific cognitive abilities, such as context following, alignment, agent, NLP task specialization, and multi-modality.\\\\n\\\\n**[Verticalization Distillation](#verticalization-distillation)**: We explore the practical implications of KD across diverse fields, including law, medical & healthcare, finance, science, and miscellaneous domains.\\\\n\\\\n> Note that both [Skill Distillation](/Tebmer/Awesome-Knowledge-Distillation-of-LLMs/blob/main/(#skill-distillation)) and [Verticalization Distillation](#verticalization-distillation) employ Knowledge Elicitation and Distillation Algorithms in [KD Algorithms](#kd-algorithms) to achieve their KD. Thus, there are overlaps between them. However, this could also provide different perspectives for the papers.\\\\n\\\\n## Why KD of LLMs?\\\\n\\\\nIn the era of LLMs, KD of LLMs plays the following crucial roles:\\\\n\\\\n  \\\\n\\\\n\\\\n| Role | Description | Trend |\\\\n| --- | --- | --- |\\\\n| **① Advancing SLMs** | Transferring advanced capabilities from proprietary LLMs to smaller SLMs, such as open source LLMs or other smaller models. | Most common |\\\\n| **② Compression** | Compressing LLMs to make them more efficient and practical. | More popular with the prosperity of open-source LLMs |\\\\n| **③ Self-Improvement** | Refining open-source LLMs\\' performance by leveraging their own knowledge, i.e. self-knowledge. | New trend to make open-source LLMs more competitive |\\\\n\\\\n## 📒 Table of Contents\\\\n\\\\n* [KD Algorithms](#kd-algorithms)\\\\n\\\\n  + [Knowledge Elicitation](#knowledge-elicitation)\\\\n    - [Labeling](#labeling)\\\\n    - [Expansion](#expansion)\\\\n    - [Curation](#curation)\\\\n    - [Feature](#feature)\\\\n    - [Feedback](#feedback)\\\\n    - [Self-Knowledge](#self-knowledge)\\\\n  + [Distillation Algorithms](#distillation-algorithms)\\\\n    - [Supervised Fine-Tuning](#supervised-fine-tuning)\\\\n    - [Divergence and Similarity](#divergence-and-similarity)\\\\n    - [Reinforcement Learning](#reinforcement-learning)\\\\n    - [Rank Optimization](#rank-optimization)\\\\n* [Skill Distillation](#skill-distillation)\\\\n\\\\n  + [Context Following](#context-following)\\\\n    - [Instruction Following](#instruction-following)\\\\n    - [Multi-turn Dialogue](#multi-turn-dialogue)\\\\n    - [RAG Capability](#rag-capability)\\\\n  + [Alignment](#alignment)\\\\n    - [Thinking Pattern](#thinking-pattern)\\\\n    - [Preference](#preference)\\\\n    - [Value](#value)\\\\n  + [Agent](#agent)\\\\n    - [Tool Using](#tool-using)\\\\n    - [Planning](#planning)\\\\n  + [NLP Task Specialization](#nlp-task-specialization)\\\\n    - [NLU](#nlu)\\\\n    - [NLG](#nlg)\\\\n    - [Information Retrieval](#information-retrieval)\\\\n    - [Recommendation](#recommendation)\\\\n    - [Text Generation Evaluation](#text-generation-evaluation)\\\\n    - [Code](#code)\\\\n  + [Multi-Modality](#multi-modality)\\\\n  + [Summary Table](#summary-table)\\\\n* [Verticalization Distillation](#verticalization-distillation)\\\\n\\\\n  + [Law](#law)\\\\n  + [Medical & Healthcare](#medical--healthcare)\\\\n  + [Finance](#finance)\\\\n  + [Science](#science)\\\\n  + [Misc.](#misc)\\\\n* [Encoder-based KD](#encoder-based-kd)\\\\n* [Citation](#citation)\\\\n\\\\n## KD Algorithms\\\\n\\\\n### Knowledge Elicitation\\\\n\\\\n#### Labeling\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering**](https://arxiv.org/pdf/2403.02966.pdf) | arXiv | 2024-03 |  |  |\\\\n| [**Aligning Large and Small Language Models via Chain-of-Thought Reasoning**](https://aclanthology.org/2024.eacl-long.109.pdf) | EACL | 2024-03 | [Github](https://github.com/lranaldii/Aligning_LLMs) |  |\\\\n| [**Divide-or-Conquer? Which Part Should You Distill Your LLM?**](https://arxiv.org/pdf/2402.15000.pdf) | arXiv | 2024-02 |  |  |\\\\n| [**Miko: Multimodal Intention Knowledge Distillation from Large Language Models for Social-Media Commonsense Discovery**](https://arxiv.org/pdf/2402.18169.pdf) | arXiv | 2024-02 |  |  |\\\\n| [**KnowTuning: Knowledge-aware Fine-tuning for Large Language Models**](https://arxiv.org/pdf/2402.11176.pdf) | arXiv | 2024-02 | [Github](https://github.com/youganglyu/KnowTuning) |  |\\\\n| [**TinyLLM: Learning a Small Student from Multiple Large Language Models**](https://arxiv.org/pdf/2402.04616.pdf) | arXiv | 2024-02 |  |  |\\\\n| [**Mixed Distillation Helps Smaller Language Model Better Reasoning**](https://arxiv.org/pdf/2312.10730.pdf) | arXiv | 2023-12 |  |  |\\\\n| [**Tailoring Self-Rationalizers with Multi-Reward Distillation**](https://arxiv.org/pdf/2311.02805.pdf) | arXiv | 2023-11 | [Github](https://inklab.usc.edu/MaRio/) | [Data](https://inklab.usc.edu/MaRio/) |\\\\n| [**Orca 2: Teaching Small Language Models How to Reason**](https://arxiv.org/pdf/2311.11045.pdf) | arXiv | 2023-11 |  |  |\\\\n| [**Mammoth: Building Math Generalist Models through Hybrid Instruction Tuning**](https://arxiv.org/abs/2309.05653) | arXiv | 2023-09 | [Github](https://tiger-ai-lab.github.io/MAmmoTH/) | [Data](https://huggingface.co/datasets/TIGER-Lab/MathInstruct) |\\\\n| [**PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization**](https://arxiv.org/abs/2306.05087) | arXiv | 2023-06 | [Github](https://github.com/WeOpenML/PandaLM) | [Data](https://github.com/WeOpenML/PandaLM) |\\\\n| [**Symbolic Chain-of-Thought Distillation: Small Models Can Also \\\\\"Think\\\\\" Step-by-Step**](https://arxiv.org/abs/2306.14050) | ACL | 2023-06 |  |  |\\\\n| [**Orca: Progressive Learning from Complex Explanation Traces of GPT-4**](https://arxiv.org/abs/2306.02707) | arXiv | 2023-06 |  |  |\\\\n| [**Distilling Step-by-Step! Outperforming Larger Language Models with Less Training Data and Smaller Model Sizes**](https://arxiv.org/abs/2305.02301) | ACL | 2023-05 | [Github](https://github.com/google-research/distilling-step-by-step) | [Data](https://github.com/google-research/distilling-step-by-step) |\\\\n| [**Impossible Distillation: from Low-Quality Model to High-Quality Dataset & Model for Summarization and Paraphrasing**](https://arxiv.org/abs/2305.16635) | arXiv | 2023-05 | [Github](https://github.com/jaehunjung1/impossible-distillation) |  |\\\\n| [**Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data**](https://arxiv.org/abs/2304.01196) | EMNLP | 2023-04 | [Github](https://github.com/project-baize/baize-chatbot) | [Data](https://github.com/project-baize/baize-chatbot/tree/main/data) |\\\\n| [**ChatGPT outperforms crowd workers for text-annotation tasks**](https://arxiv.org/pdf/2303.15056.pdf) | arXiv | 2023-03 |  |  |\\\\n| [**Annollm: Making large language models to be better crowdsourced annotators**](https://arxiv.org/abs/2303.16854) | arXiv | 2023-03 |  |  |\\\\n| [**GPT-4All: Training an Assistant-Style Chatbot with Large Scale Data Distillation from GPT-3.5-Turbo**](https://s3.amazonaws.com/static.nomic.ai/gpt4all/2023_GPT4All_Technical_Report.pdf) | - | 2023-03 | [Github](https://github.com/nomic-ai/gpt4all) |  |\\\\n| [**Specializing Smaller Language Models towards Multi-Step Reasoning**](https://arxiv.org/abs/2301.12726) | arXiv | 2023-01 |  |  |\\\\n| [**Is GPT-3 a Good Data Annotator?**](https://arxiv.org/pdf/2212.10450.pdf) | ACL | 2022-12 | [Github](https://github.com/DAMO-NLP-SG/LLM-Data-Annotator) |  |\\\\n| [**Large Language Models Are Reasoning Teachers**](https://arxiv.org/abs/2212.10071) | ACL | 2022-12 | [Github](https://github.com/itsnamgyu/reasoning-teacher) | [Data](https://github.com/itsnamgyu/reasoning-teacher) |\\\\n| [**Teaching Small Language Models to Reason**](https://arxiv.org/abs/2212.08410) | ACL | 2022-12 |  |  |\\\\n| [**Explanations from Large Language Models Make Small Reasoners Better**](https://arxiv.org/abs/2210.06726) | arXiv | 2022-10 |  |  |\\\\n| [**Want To Reduce Labeling Cost? GPT-3 Can Help**](https://aclanthology.org/2021.findings-emnlp.354) | Findings of EMNLP | 2021-08 |  |  |\\\\n\\\\n#### Expansion\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Instruction Fusion: Advancing Prompt Evolution through Hybridization**](https://arxiv.org/pdf/2312.15692.pdf) | arXiv | 2023-12 |  |  |\\\\n| [**An Empirical Study of Instruction-tuning Large Language Models in Chinese**](https://arxiv.org/pdf/2310.07328.pdf) | EMNLP | 2023-10 | [Github](https://github.com/PhoebusSi/Alpaca-CoT) | [Data](https://huggingface.co/datasets/QingyiSi/Alpaca-CoT) |\\\\n| [**PromptMix: A Class Boundary Augmentation Method for Large Language Model Distillation**](https://arxiv.org/pdf/2310.14192.pdf) | EMNLP | 2023-10 | [Github](https://github.com/ServiceNow/PromptMix-EMNLP-2023) |  |\\\\n| [**Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct**](https://arxiv.org/abs/2308.09583) | arXiv | 2023-08 | [Github](https://github.com/nlpxucan/WizardLM) |  |\\\\n| [**Code Llama: Open Foundation Models for Code**](https://arxiv.org/pdf/2308.12950.pdf) | arXiv | 2023-08 | [Github](https://github.com/facebookresearch/codellama) |  |\\\\n| [**WizardCoder: Empowering Code Large Language Models with Evol-Instruct**](https://arxiv.org/abs/2306.08568) | ICLR | 2023-06 | [Github](https://github.com/nlpxucan/WizardLM) |  |\\\\n| [**Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision**](https://proceedings.neurips.cc/paper/2023/hash/0764db1151b936aca59249e2c1386101-Abstract-Conference.html) | NeurIPS | 2023-05 | [Github](https://github.com/IBM/Dromedary) | [Data](https://huggingface.co/datasets/zhiqings/dromedary-65b-verbose-clone-v0) |\\\\n| [**Targeted Data Generation: Finding and Fixing Model Weaknesses**](https://arxiv.org/pdf/2305.17804.pdf) | ACL | 2023-05 | [Github](https://github.com/ZexueHe/TDG) |  |\\\\n| [**Wizardlm: Empowering large language models to follow complex instructions**](https://arxiv.org/abs/2304.12244) | ICLR | 2023-04 | [Github](https://github.com/nlpxucan/WizardLM) | [Data](https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_70k)   [Data](https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k) |\\\\n| [**LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions**](https://arxiv.org/abs/2304.14402) | arXiv | 2023-04 | [Github](https://github.com/mbzuai-nlp/LaMini-LM?tab=readme-ov-file) | [Data](https://huggingface.co/datasets/MBZUAI/LaMini-instruction) |\\\\n| [**Alpaca: Aligning Language Model with Human Preferences**](https://crfm.stanford.edu/2023/03/13/alpaca.html) | - | 2023-03 | [Github](https://github.com/tatsu-lab/stanford_alpaca) | [Data](https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json) |\\\\n| Code Alpaca: An Instruction-following LLaMA model for code generation | - | 2023-03 | [Github](https://github.com/sahil280114/codealpaca) | [Data](https://github.com/sahil280114/codealpaca?tab=readme-ov-file#data-release) |\\\\n| [**Exploring the Impact of Instruction Data Scaling on Large Language Models: An Empirical Study on Real-World Use Cases**](https://arxiv.org/abs/2303.14742) | arXiv | 2023-03 | [Github](https://github.com/LianjiaTech/BELLE) | [Data](https://huggingface.co/BelleGroup) |\\\\n| [**AugGPT: Leveraging ChatGPT for Text Data Augmentation**](https://arxiv.org/pdf/2302.13007.pdf) | arXiv | 2023-02 | [Github](https://github.com/yhydhx/AugGPT) |  |\\\\n| [**Self-instruct: Aligning language model with self generated instructions**](https://arxiv.org/abs/2212.10560) | ACL | 2022-12 | [Github](https://github.com/yizhongw/self-instruct) | [Data](https://github.com/yizhongw/self-instruct) |\\\\n| [**Symbolic Knowledge Distillation: from General Language Models to Commonsense Models**](https://arxiv.org/pdf/2110.07178.pdf) | NAACL | 2021-10 | [Github](https://github.com/peterwestai2/symbolic-knowledge-distillation) | [Data](https://github.com/peterwestai2/symbolic-knowledge-distillation) |\\\\n\\\\n#### Curation\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models**](https://arxiv.org/abs/2402.13064) | arXiv | 2024-02 |  |  |\\\\n| [**Phi-2: The surprising power of small language models**](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/) | - | 2023-12 |  |  |\\\\n| [**WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with Refined Data Generation**](https://arxiv.org/abs/2312.14187) | arXiv | 2023-12 |  |  |\\\\n| [**Magicoder: Source Code Is All You Need**](https://arxiv.org/pdf/2312.02120.pdf) | arXiv | 2023-12 | [Github](https://github.com/ise-uiuc/magicoder) | [Data](https://huggingface.co/datasets/ise-uiuc/Magicoder-OSS-Instruct-75K)   [Data](https://huggingface.co/datasets/ise-uiuc/Magicoder-Evol-Instruct-110K) |\\\\n| [**MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning**](https://arxiv.org/pdf/2311.02303.pdf) | arXiv | 2023-11 | [Github](https://github.com/codefuse-ai/MFTCOder) | [Data](https://huggingface.co/datasets/codefuse-ai/Evol-instruction-66k)   [Data](https://huggingface.co/datasets/codefuse-ai/CodeExercise-Python-27k) |\\\\n| [**Textbooks Are All You Need II: Phi-1.5 Technical Report**](https://arxiv.org/pdf/2309.05463.pdf) | arXiv | 2023-09 |  |  |\\\\n| [**Neural Machine Translation Data Generation and Augmentation using ChatGPT**](https://arxiv.org/pdf/2307.05779.pdf) | arXiv | 2023-07 |  |  |\\\\n| [**Textbooks Are All You Need: A Large-Scale Instructional Text Data Set for Language Models**](https://arxiv.org/pdf/2306.11644.pdf) | arXiv | 2023-06 |  |  |\\\\n| [**Enhancing Chat Language Models by Scaling High-quality Instructional Conversations**](https://arxiv.org/abs/2305.14233) | arXiv | 2023-05 | [Github](https://github.com/thunlp/UltraChat) | [Data](https://huggingface.co/datasets/stingning/ultrachat) |\\\\n| [**AugTriever: Unsupervised Dense Retrieval by Scalable Data Augmentation**](https://arxiv.org/pdf/2212.08841.pdf) | arXiv | 2022-12 | [Github](https://github.com/salesforce/AugTriever) |  |\\\\n| [**SunGen: Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning**](https://arxiv.org/pdf/2205.12679.pdf) | ICLR | 2022-05 | [Github](https://github.com/SumilerGAO/SunGen) |  |\\\\n| [**ZeroGen: Efficient Zero-shot Learning via Dataset Generation**](https://arxiv.org/pdf/2202.07922.pdf) | EMNLP | 2022-02 | [Github](https://github.com/jiacheng-ye/ZeroGen) |  |\\\\n| [**InPars: Data Augmentation for Information Retrieval using Large Language Models**](https://arxiv.org/pdf/2202.05144.pdf) | arXiv | 2022-02 | [Github](https://github.com/zetaalphavector/inpars) | [Data](https://github.com/zetaalphavector/inpars) |\\\\n| [**Towards Zero-Label Language Learning**](https://arxiv.org/pdf/2109.09193.pdf) | arXiv | 2021-09 |  |  |\\\\n\\\\n#### Feature\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning**](https://arxiv.org/abs/2402.12842) | EMNLP Findings | 2024-02 | [Github](https://github.com/gmkim-ai/PromptKD) | [Data](https://github.com/gmkim-ai/PromptKD/tree/main/data_utils) |\\\\n| [**Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models**](https://arxiv.org/pdf/2404.02657.pdf) | arXiv | 2024-04 |  |  |\\\\n| [**Direct Alignment of Draft Model for Speculative Decoding with Chat-Fine-Tuned LLMs**](https://arxiv.org/pdf/2403.00858.pdf) | arXiv | 2024-03 |  |  |\\\\n| [**DB-LLM: Accurate Dual-Binarization for Efficient LLMs**](https://arxiv.org/pdf/2402.11960.pdf) | arXiv | 2024-02 |  |  |\\\\n| [**BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillation**](https://arxiv.org/pdf/2402.10631.pdf) | arXiv | 2024-02 | [Github](https://github.com/DD-DuDa/BitDistiller) |  |\\\\n| [**DISTILLM: Towards Streamlined Distillation for Large Language Models**](https://arxiv.org/pdf/2402.03898.pdf) | arXiv | 2024-02 | [Github](https://github.com/jongwooko/distillm) |  |\\\\n| [**Towards Cross-Tokenizer Distillation: the Universal Logit Distillation Loss for LLMs**](https://arxiv.org/pdf/2402.12030.pdf) | arXiv | 2024-02 | [Github](https://github.com/Nicolas-BZRD/llm-recipes) | [Data](https://huggingface.co/Nicolas-BZRD) |\\\\n| [**Revisiting Knowledge Distillation for Autoregressive Language Models**](https://arxiv.org/pdf/2402.11890.pdf) | arXiv | 2024-02 |  |  |\\\\n| [**Knowledge Fusion of Large Language Models**](https://arxiv.org/abs/2401.10491) | ICLR | 2024-01 | [Github](https://github.com/fanqiwan/FuseLLM) |  |\\\\n| [**Improving In-context Learning via Bidirectional Alignment**](https://arxiv.org/pdf/2312.17055.pdf) | arXiv | 2023-12 |  |  |\\\\n| [**Towards the Fundamental Limits of Knowledge Transfer over Finite Domains**](https://arxiv.org/abs/2310.07838) | NeurIPS | 2023-10 |  |  |\\\\n| [**Baby Llama: Knowledge Distillation from an Ensemble of Teachers Trained on a Small Dataset with No Performance Penalty**](https://arxiv.org/pdf/2308.02019.pdf) | CoNLL | 2023-08 | [Github](https://github.com/timinar/BabyLlama) | [Data](https://github.com/timinar/BabyLlama) |\\\\n| [**f-Divergence Minimization for Sequence-Level Knowledge Distillation**](https://arxiv.org/pdf/2307.15190.pdf) | ACL | 2023-07 | [Github](https://github.com/MANGA-UOFA/fdistill) | [Data](https://drive.google.com/file/d/1V7bPndyoTQxcJ6m1BoXAw7-ub-jv8Wh1/view?usp=sharing) |\\\\n| [**MiniLLM: Knowledge Distillation of Large Language Models**](https://arxiv.org/pdf/2306.08543.pdf) | ICLR | 2023-06 | [Github](https://github.com/microsoft/LMOps/tree/main/minillm) | [Data](https://github.com/microsoft/LMOps/tree/main/minillm) |\\\\n| [**On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes**](https://arxiv.org/pdf/2306.13649.pdf) | ICLR | 2023-06 |  |  |\\\\n| [**LLM-QAT: Data-Free Quantization Aware Training for Large Language Models**](https://arxiv.org/pdf/2305.17888.pdf) | arXiv | 2023-05 | [Github](https://github.com/facebookresearch/LLM-QAT) | [Data](https://github.com/facebookresearch/LLM-QAT) |\\\\n| [**Less is more: Task-aware layer-wise distillation for language model compression**](https://arxiv.org/pdf/2210.01351.pdf) | PMLR | 2022-10 | [Github](https://github.com/cliang1453/task-aware-distillation) |  |\\\\n\\\\n#### Feedback\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning**](https://arxiv.org/abs/2402.12842) | EMNLP Findings | 2024-02 | [Github](https://github.com/gmkim-ai/PromptKD) | [Data](https://github.com/gmkim-ai/PromptKD/tree/main/data_utils) |\\\\n| [**Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering**](https://arxiv.org/pdf/2403.02966.pdf) | arXiv | 2024-03 |  |  |\\\\n| [**Evolving Knowledge Distillation with Large Language Models and Active Learning**](https://arxiv.org/pdf/2403.06414v1.pdf) | arXiv | 2024-03 |  |  |\\\\n| [**Direct Language Model Alignment from Online AI Feedback**](https://arxiv.org/pdf/2402.04792.pdf) | arXiv | 2024-02 |  |  |\\\\n| [**DISTILLM: Towards Streamlined Distillation for Large Language Models**](https://arxiv.org/pdf/2402.03898.pdf) | arXiv | 2024-02 | [Github](https://github.com/jongwooko/distillm) |  |\\\\n| [**Improving Large Language Models via Fine-grained Reinforcement Learning with Minimum Editing Constraint**](https://arxiv.org/pdf/2401.06081.pdf) | arXiv | 2024-01 | [Github](https://github.com/RUCAIBox/RLMEC) |  |\\\\n| [**Beyond Imitation: Leveraging Fine-grained Quality Signals for Alignment**](https://arxiv.org/pdf/2311.04072.pdf) | arXiv | 2023-11 |  |  |\\\\n| [**Can Language Models Teach Weaker Agents? Teacher Explanations Improve Students via Personalization**](https://arxiv.org/abs/2310.02421) | ICLR | 2023-10 | [Github](https://github.com/swarnaHub/ExplanationIntervention) |  |\\\\n| [**Motif: Intrinsic Motivation from Artificial Intelligence Feedback**](https://arxiv.org/abs/2310.00166) | ICLR | 2023-10 | [Github](https://github.com/facebookresearch/motif) |  |\\\\n| [**Ultrafeedback: Boosting language models with high-quality feedback**](https://arxiv.org/pdf/2310.01377.pdf) | arXiv | 2023-10 | [Github](https://github.com/thunlp/UltraFeedback) | [Data](https://huggingface.co/datasets/openbmb/UltraFeedback) |\\\\n| [**Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation**](https://arxiv.org/pdf/2310.18628.pdf) | EMNLP | 2023-10 | [Github](https://github.com/SalesforceAIResearch/PersDistill) |  |\\\\n| [**CycleAlign: Iterative Distillation from Black-box LLM to White-box Models for Better Human Alignment**](https://arxiv.org/abs/2310.16271) | arXiv | 2023-10 |  |  |\\\\n| [**Rlaif: Scaling Reinforcement Learning from Human Feedback with AI Feedback**](https://arxiv.org/pdf/2309.00267.pdf) | arXiv | 2023-09 |  |  |\\\\n| [**Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct**](https://arxiv.org/abs/2308.09583) | arXiv | 2023-08 | [Github](https://github.com/nlpxucan/WizardLM) |  |\\\\n| [**On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes**](https://arxiv.org/pdf/2306.13649.pdf) | ICLR | 2023-06 |  |  |\\\\n| [**MiniLLM: Knowledge Distillation of Large Language Models**](https://arxiv.org/pdf/2306.08543.pdf) | ICLR | 2023-06 | [Github](https://github.com/microsoft/LMOps/tree/main/minillm) | [Data](https://github.com/microsoft/LMOps/tree/main/minillm) |\\\\n| [**Language to Rewards for Robotic Skill Synthesis**](https://arxiv.org/pdf/2306.08647.pdf) | arXiv | 2023-06 | [Github](https://github.com/google-deepmind/language_to_reward_2023) |  |\\\\n| [**Lion: Adversarial Distillation of Closed-Source Large Language Model**](https://arxiv.org/pdf/2305.12870.pdf) | EMNLP | 2023-05 | [Github](https://github.com/YJiangcm/Lion) |  |\\\\n| [**SelFee: Iterative Self-Revising LLM Empowered by Self-Feedback Generation**](https://kaistai.github.io/SelFee/) | arXiv | 2023-05 |  |  |\\\\n| [**LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions**](https://arxiv.org/abs/2304.14402) | arXiv | 2023-04 | [Github](https://github.com/mbzuai-nlp/LaMini-LM?tab=readme-ov-file) | [Data](https://huggingface.co/datasets/MBZUAI/LaMini-instruction) |\\\\n| [**Reward Design with Language Models**](https://arxiv.org/pdf/2303.00001.pdf) | ICLR | 2023-03 | [Github](https://github.com/minaek/reward_design_with_llms) |  |\\\\n| [**Consitutional AI: Harmlessness from AI Feedback**](https://arxiv.org/pdf/2212.08073.pdf) | arXiv | 2022-12 |  |  |\\\\n\\\\n#### Self-Knowledge\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**V-STaR: Training Verifiers for Self-Taught Reasoners**](https://arxiv.org/pdf/2402.06457.pdf) | arXiv | 2024-02 |  |  |\\\\n| [**Self-Rewarding Language Models**](https://arxiv.org/pdf/2401.10020.pdf) | arXiv | 2024-01 | [Github](https://github.com/lucidrains/self-rewarding-lm-pytorch?tab=readme-ov-file) |  |\\\\n| [**Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models**](https://arxiv.org/pdf/2401.01335.pdf) | arXiv | 2024-01 | [Github](https://github.com/uclaml/SPIN) | [Data](https://huggingface.co/datasets/UCLA-AGI/SPIN_iter0) |\\\\n| [**Kun: Answer Polishment for Chinese Self-Alignment with Instruction Back-Translation**](https://arxiv.org/pdf/2401.06477.pdf) | arXiv | 2024-01 | [Github](https://github.com/Zheng0428/COIG-Kun) | [Data](https://huggingface.co/datasets/m-a-p/COIG-Kun) |\\\\n| [**APT: Adaptive Pruning and Tuning Pretrained Language Models for Efficient Training and Inference**](https://arxiv.org/pdf/2401.12200.pdf) | arXiv | 2024-01 |  |  |\\\\n| [**GRATH: Gradual Self-Truthifying for Large Language Models**](https://arxiv.org/abs/2401.12292) | arXiv | 2024-01 |  |  |\\\\n| [**Beyond human data: Scaling self-training for problem-solving with language models**](https://arxiv.org/pdf/2312.06585.pdf) | arXiv | 2023-12 |  |  |\\\\n| [**Self-Knowledge Guided Retrieval Augmentation for Large Language Models**](https://arxiv.org/abs/2310.05002) | EMNLP Findings | 2023-10 | [Github](https://github.com/THUNLP-MT/SKR) |  |\\\\n| [**RAIN: Your Language Models Can Align Themselves without Finetuning**](https://arxiv.org/pdf/2309.07124.pdf) | arXiv | 2023-09 | [Github](https://github.com/SafeAILab/RAIN) |  |\\\\n| [**Reinforced Self-Training (ReST) for Language Modeling**](https://arxiv.org/pdf/2308.08998.pdf) | arXiv | 2023-08 |  |  |\\\\n| [**Humback: Self-Alignment with Instruction Backtranslation**](https://arxiv.org/pdf/2308.06259.pdf) | ICLR | 2023-08 | [Github](https://github.com/Spico197/Humback) |  |\\\\n| [**Self-Alignment of Large Language Models via Reinforcement Learning from Contrast Distillation**](https://arxiv.org/pdf/2307.12950.pdf) | ICLR | 2023-07 | [Github](https://github.com/facebookresearch/rlcd) |  |\\\\n| [**Self-Improvement of Large Language Models via Reinforcement Learning from Human Feedback**](https://arxiv.org/pdf/2306.14050.pdf) | EMNLP | 2023-06 |  |  |\\\\n| [**Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision**](https://proceedings.neurips.cc/paper/2023/hash/0764db1151b936aca59249e2c1386101-Abstract-Conference.html) | NeurIPS | 2023-05 | [Github](https://github.com/IBM/Dromedary) | [Data](https://huggingface.co/datasets/zhiqings/dromedary-65b-verbose-clone-v0) |\\\\n| [**Impossible Distillation: from Low-Quality Model to High-Quality Dataset & Model for Summarization and Paraphrasing**](https://arxiv.org/abs/2305.16635) | arXiv | 2023-05 | [Github](https://github.com/jaehunjung1/impossible-distillation) |  |\\\\n| [**Language Model Self-improvement by Reinforcement Learning Contemplation**](https://arxiv.org/pdf/2305.14483.pdf) | arXiv | 2023-05 |  |  |\\\\n| [**Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data**](https://arxiv.org/abs/2304.01196) | EMNLP | 2023-04 | [Github](https://github.com/project-baize/baize-chatbot) | [Data](https://github.com/project-baize/baize-chatbot/tree/main/data) |\\\\n| [**Self-instruct: Aligning language model with self generated instructions**](https://arxiv.org/abs/2212.10560) | ACL | 2022-12 | [Github](https://github.com/yizhongw/self-instruct) | [Data](https://github.com/yizhongw/self-instruct) |\\\\n| [**Large Language Models Can Self-Improve**](https://arxiv.org/pdf/2210.11610.pdf) | EMNLP | 2022-10 |  |  |\\\\n| [**STaR: Bootstrapping Reasoning With Reasoning**](https://arxiv.org/pdf/2203.14465.pdf) | NeurIPS | 2022-03 | [Github](https://github.com/ezelikman/STaR) |  |\\\\n\\\\n### Distillation Algorithms\\\\n\\\\n#### Supervised Fine-Tuning\\\\n\\\\n> Due to the large number of works applying supervised fine-tuning, we only list the most representative ones here.\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering**](https://arxiv.org/pdf/2403.02966.pdf) | arXiv | 2024-03 |  |  |\\\\n| [**Aligning Large and Small Language Models via Chain-of-Thought Reasoning**](https://aclanthology.org/2024.eacl-long.109.pdf) | EACL | 2024-03 | [Github](https://github.com/lranaldii/Aligning_LLMs) |  |\\\\n| [**Divide-or-Conquer? Which Part Should You Distill Your LLM?**](https://arxiv.org/pdf/2402.15000.pdf) | arXiv | 2024-02 |  |  |\\\\n| [**Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models**](https://arxiv.org/abs/2402.13064) | arXiv | 2024-02 |  |  |\\\\n| [**Orca 2: Teaching Small Language Models How to Reason**](https://arxiv.org/pdf/2311.11045.pdf) | arXiv | 2023-11 |  |  |\\\\n| [**TinyLLM: Learning a Small Student from Multiple Large Language Models**](https://arxiv.org/pdf/2402.04616.pdf) | arXiv | 2024-02 |  |  |\\\\n| [**Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct**](https://arxiv.org/abs/2308.09583) | arXiv | 2023-08 | [Github](https://github.com/nlpxucan/WizardLM) |  |\\\\n| [**Orca: Progressive Learning from Complex Explanation Traces of GPT-4**](https://arxiv.org/abs/2306.02707) | arXiv | 2023-06 |  |  |\\\\n| [**LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions**](https://arxiv.org/abs/2304.14402) | arXiv | 2023-04 | [Github](https://github.com/mbzuai-nlp/LaMini-LM?tab=readme-ov-file) | [Data](https://huggingface.co/datasets/MBZUAI/LaMini-instruction) |\\\\n| [**Wizardlm: Empowering large language models to follow complex instructions**](https://arxiv.org/abs/2304.12244) | ICLR | 2023-04 | [Github](https://github.com/nlpxucan/WizardLM) | [Data](https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_70k)   [Data](https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k) |\\\\n| [**Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data**](https://arxiv.org/abs/2304.01196) | EMNLP | 2023-04 | [Github](https://github.com/project-baize/baize-chatbot) | [Data](https://github.com/project-baize/baize-chatbot/tree/main/data) |\\\\n| [**Alpaca: Aligning Language Model with Human Preferences**](https://crfm.stanford.edu/2023/03/13/alpaca.html) | - | 2023-03 | [Github](https://github.com/tatsu-lab/stanford_alpaca) | [Data](https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json) |\\\\n| [**Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality*\\\\\\\\*](https://lmsys.org/blog/2023-03-30-vicuna/) | - | 2023-03 | [Github](https://github.com/lm-sys/FastChat) | [Data](https://huggingface.co/datasets/anon8231489123/ShareGPT_Vicuna_unfiltered) |\\\\n| [**Self-instruct: Aligning language model with self generated instructions**](https://arxiv.org/abs/2212.10560) | ACL | 2022-12 | [Github](https://github.com/yizhongw/self-instruct) | [Data](https://github.com/yizhongw/self-instruct) |\\\\n| [**Large Language Models Can Self-Improve**](https://arxiv.org/pdf/2210.11610.pdf) | EMNLP | 2022-10 |  |  |\\\\n| [**STaR: Bootstrapping Reasoning With Reasoning**](https://arxiv.org/pdf/2203.14465.pdf) | NeurIPS | 2022-03 | [Github](https://github.com/ezelikman/STaR) |  |\\\\n\\\\n#### Divergence and Similarity\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**PromptKD: Distilling Student-Friendly Knowledge for Generative Language Models via Prompt Tuning**](https://arxiv.org/abs/2402.12842) | EMNLP Findings | 2024-02 | [Github](https://github.com/gmkim-ai/PromptKD) | [Data](https://github.com/gmkim-ai/PromptKD/tree/main/data_utils) |\\\\n| [**Rethinking Kullback-Leibler Divergence in Knowledge Distillation for Large Language Models**](https://arxiv.org/pdf/2404.02657.pdf) | arXiv | 2024-04 |  |  |\\\\n| [**Weight-Inherited Distillation for Task-Agnostic BERT Compression**](https://arxiv.org/pdf/2305.09098.pdf) | NAACL | 2024-03 | [Github](https://github.com/wutaiqiang/WID-NAACL2024) |  |\\\\n| [**BitDistiller: Unleashing the Potential of Sub-4-Bit LLMs via Self-Distillation**](https://arxiv.org/pdf/2402.10631.pdf) | arXiv | 2024-02 | [Github](https://github.com/DD-DuDa/BitDistiller) |  |\\\\n| [**DISTILLM: Towards Streamlined Distillation for Large Language Models**](https://arxiv.org/pdf/2402.03898.pdf) | arXiv | 2024-02 | [Github](https://github.com/jongwooko/distillm) |  |\\\\n| [**Towards Cross-Tokenizer Distillation: the Universal Logit Distillation Loss for LLMs**](https://arxiv.org/pdf/2402.12030.pdf) | arXiv | 2024-02 | [Github](https://github.com/Nicolas-BZRD/llm-recipes) | [Data](https://huggingface.co/Nicolas-BZRD) |\\\\n| [**Revisiting Knowledge Distillation for Autoregressive Language Models**](https://arxiv.org/pdf/2402.11890.pdf) | arXiv | 2024-02 |  |  |\\\\n| [**Knowledge Distillation for Closed-Source Language Models**](https://arxiv.org/pdf/2401.07013.pdf) | arXiv | 2024-01 |  |  |\\\\n| [**Knowledge Fusion of Large Language Models**](https://arxiv.org/abs/2401.10491) | ICLR | 2024-01 | [Github](https://github.com/fanqiwan/FuseLLM) |  |\\\\n| [**Improving In-context Learning via Bidirectional Alignment**](https://arxiv.org/pdf/2312.17055.pdf) | arXiv | 2023-12 |  |  |\\\\n| [**Towards the Fundamental Limits of Knowledge Transfer over Finite Domains**](https://arxiv.org/abs/2310.07838) | NeurIPS | 2023-10 |  |  |\\\\n| [**Baby Llama: Knowledge Distillation from an Ensemble of Teachers Trained on a Small Dataset with No Performance Penalty**](https://arxiv.org/pdf/2308.02019.pdf) | CoNLL | 2023-08 | [Github](https://github.com/timinar/BabyLlama) | [Data](https://github.com/timinar/BabyLlama) |\\\\n| [**f-Divergence Minimization for Sequence-Level Knowledge Distillation**](https://arxiv.org/pdf/2307.15190.pdf) | ACL | 2023-07 | [Github](https://github.com/MANGA-UOFA/fdistill) | [Data](https://drive.google.com/file/d/1V7bPndyoTQxcJ6m1BoXAw7-ub-jv8Wh1/view?usp=sharing) |\\\\n| [**f-Divergence Minimization for Sequence-Level Knowledge Distillation**](https://arxiv.org/pdf/2307.15190.pdf) | ACL | 2023-07 | [Github](https://github.com/MANGA-UOFA/fdistill) | [Data](https://drive.google.com/file/d/1V7bPndyoTQxcJ6m1BoXAw7-ub-jv8Wh1/view?usp=sharing) |\\\\n| [**MiniLLM: Knowledge Distillation of Large Language Models**](https://arxiv.org/pdf/2306.08543.pdf) | ICLR | 2023-06 | [Github](https://github.com/microsoft/LMOps/tree/main/minillm) | [Data](https://github.com/microsoft/LMOps/tree/main/minillm) |\\\\n| [**On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes**](https://arxiv.org/pdf/2306.13649.pdf) | ICLR | 2023-06 |  |  |\\\\n| [**LLM-QAT: Data-Free Quantization Aware Training for Large Language Models**](https://arxiv.org/pdf/2305.17888.pdf) | arXiv | 2023-05 | [Github](https://github.com/facebookresearch/LLM-QAT) | [Data](https://github.com/facebookresearch/LLM-QAT) |\\\\n| [**Less is more: Task-aware layer-wise distillation for language model compression**](https://arxiv.org/pdf/2210.01351.pdf) | PMLR | 2022-10 | [Github](https://github.com/cliang1453/task-aware-distillation) |  |\\\\n| [**DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter**](https://arxiv.org/pdf/1910.01108.pdf) | NeurIPS | 2019-10 |  |  |\\\\n\\\\n#### Reinforcement Learning\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Direct Language Model Alignment from Online AI Feedback**](https://arxiv.org/pdf/2402.04792.pdf) | arXiv | 2024-02 |  |  |\\\\n| [**Improving Large Language Models via Fine-grained Reinforcement Learning with Minimum Editing Constraint**](https://arxiv.org/pdf/2401.06081.pdf) | arXiv | 2024-01 | [Github](https://github.com/RUCAIBox/RLMEC) |  |\\\\n| [**Accelerating Reinforcement Learning of Robotic Manipulations via Feedback from Large Language Models**](https://arxiv.org/abs/2311.02379) | CoRL | 2023-11 |  |  |\\\\n| [**Motif: Intrinsic Motivation from Artificial Intelligence Feedback**](https://arxiv.org/abs/2310.00166) | ICLR | 2023-10 | [Github](https://github.com/facebookresearch/motif) |  |\\\\n| [**Ultrafeedback: Boosting language models with high-quality feedback**](https://arxiv.org/pdf/2310.01377.pdf) | arXiv | 2023-10 | [Github](https://github.com/thunlp/UltraFeedback) | [Data](https://huggingface.co/datasets/openbmb/UltraFeedback) |\\\\n| [**Eureka: Human-Level Reward Design via Coding Large Language Models**](https://arxiv.org/pdf/2310.12931.pdf) | arXiv | 2023-10 | [Github](https://github.com/eureka-research/Eureka) |  |\\\\n| [**Rlaif: Scaling Reinforcement Learning from Human Feedback with AI Feedback**](https://arxiv.org/pdf/2309.00267.pdf) | arXiv | 2023-09 |  |  |\\\\n| [**Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct**](https://arxiv.org/abs/2308.09583) | arXiv | 2023-08 | [Github](https://github.com/nlpxucan/WizardLM) |  |\\\\n| [**On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes**](https://arxiv.org/pdf/2306.13649.pdf) | ICLR | 2023-06 |  |  |\\\\n| [**Aligning Large Language Models through Synthetic Feedback**](https://arxiv.org/pdf/2305.13735.pdf) | EMNLP | 2023-05 | [Github](https://github.com/naver-ai/almost) | [Data](https://github.com/naver-ai/almost) |\\\\n| [**Language Model Self-improvement by Reinforcement Learning Contemplation**](https://arxiv.org/pdf/2305.14483.pdf) | arXiv | 2023-05 |  |  |\\\\n| [**Consitutional AI: Harmlessness from AI Feedback**](https://arxiv.org/pdf/2212.08073.pdf) | arXiv | 2022-12 |  |  |\\\\n\\\\n#### Rank Optimization\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Evidence-Focused Fact Summarization for Knowledge-Augmented Zero-Shot Question Answering**](https://arxiv.org/pdf/2403.02966.pdf) | arXiv | 2024-03 |  |  |\\\\n| [**KnowTuning: Knowledge-aware Fine-tuning for Large Language Models**](https://arxiv.org/pdf/2402.11176.pdf) | arXiv | 2024-02 | [Github](https://github.com/youganglyu/KnowTuning) |  |\\\\n| [**Self-Rewarding Language Models**](https://arxiv.org/pdf/2401.10020.pdf) | arXiv | 2024-01 | [Github](https://github.com/lucidrains/self-rewarding-lm-pytorch?tab=readme-ov-file) |  |\\\\n| [**Self-Play Fine-Tuning Converts Weak Language Models to Strong Language Models**](https://arxiv.org/pdf/2401.01335.pdf) | arXiv | 2024-01 | [Github](https://github.com/uclaml/SPIN) | [Data](https://huggingface.co/datasets/UCLA-AGI/SPIN_iter0) |\\\\n| [**Zephyr: Direct Distillation of Language Model Alignment**](https://arxiv.org/pdf/2310.16944.pdf) | arXiv | 2023-10 | [Github](https://github.com/huggingface/alignment-handbook) | [Data](https://huggingface.co/datasets/HuggingFaceH4/ultrachat_200k) |\\\\n| [**CycleAlign: Iterative Distillation from Black-box LLM to White-box Models for Better Human Alignment**](https://arxiv.org/abs/2310.16271) | arXiv | 2023-10 |  |  |\\\\n\\\\n## Skill Distillation\\\\n\\\\n### Context Following\\\\n\\\\n#### Instruction Following\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Synthetic Data (Almost) from Scratch: Generalized Instruction Tuning for Language Models**](https://arxiv.org/abs/2402.13064) | arXiv | 2024-02 |  |  |\\\\n| [**Revisiting Knowledge Distillation for Autoregressive Language Models**](https://arxiv.org/pdf/2402.11890.pdf) | arXiv | 2024-02 |  |  |\\\\n| [**Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning**](https://arxiv.org/abs/2402.10110) | arXiv | 2024-02 | [Github](https://github.com/tianyi-lab/Reflection_Tuning) | [Data](https://github.com/tianyi-lab/Reflection_Tuning) |\\\\n| [**Phi-2: The surprising power of small language models**](https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/) | - | 2023-12 |  |  |\\\\n| [**What Makes Good Data for Alignment? A Comprehensive Study of Automatic Data Selection in Instruction Tuning**](https://arxiv.org/abs/2312.15685) | ICLR | 2023-12 | [Github](https://github.com/hkust-nlp/deita) | [Data](https://github.com/hkust-nlp/deita) |\\\\n| [**MUFFIN: Curating Multi-Faceted Instructions for Improving Instruction-Following**](https://arxiv.org/abs/2312.02436) | arXiv | 2023-12 | [Github](https://github.com/RenzeLou/Muffin) | [Data](https://huggingface.co/datasets/Reza8848/MUFFIN_68k) |\\\\n| [**Instruction Fusion: Advancing Prompt Evolution through Hybridization**](https://arxiv.org/pdf/2312.15692.pdf) | arXiv | 2023-12 |  |  |\\\\n| [**Orca 2: Teaching Small Language Models How to Reason**](https://arxiv.org/pdf/2311.11045.pdf) | arXiv | 2023-11 |  |  |\\\\n| [**Reflection-Tuning: Data Recycling Improves LLM Instruction-Tuning**](https://arxiv.org/abs/2310.11716) | NIPS Workshop | 2023-10 | [Github](https://github.com/tianyi-lab/Reflection_Tuning) | [Data](https://github.com/tianyi-lab/Reflection_Tuning) |\\\\n| [**Textbooks Are All You Need II: Phi-1.5 Technical Report**](https://arxiv.org/pdf/2309.05463.pdf) | arXiv | 2023-09 |  |  |\\\\n| [**Orca: Progressive Learning from Complex Explanation Traces of GPT-4**](https://arxiv.org/abs/2306.02707) | arXiv | 2023-06 |  |  |\\\\n| [**Textbooks Are All You Need: A Large-Scale Instructional Text Data Set for Language Models**](https://arxiv.org/pdf/2306.11644.pdf) | arXiv | 2023-06 |  |  |\\\\n| [**SelFee: Iterative Self-Revising LLM Empowered by Self-Feedback Generation**](https://kaistai.github.io/SelFee/) | arXiv | 2023-05 |  |  |\\\\n| [**ExpertPrompting: Instructing Large Language Models to be Distinguished Experts**](https://arxiv.org/abs/2305.14688) | arXiv | 2023-05 | [Github](https://github.com/OFA-Sys/ExpertLLaMA) | [Data](https://github.com/OFA-Sys/ExpertLLaMA) |\\\\n| [**LaMini-LM: A Diverse Herd of Distilled Models from Large-Scale Instructions**](https://arxiv.org/abs/2304.14402) | arXiv | 2023-04 | [Github](https://github.com/mbzuai-nlp/LaMini-LM?tab=readme-ov-file) | [Data](https://huggingface.co/datasets/MBZUAI/LaMini-instruction) |\\\\n| [**Wizardlm: Empowering large language models to follow complex instructions**](https://arxiv.org/abs/2304.12244) | ICLR | 2023-04 | [Github](https://github.com/nlpxucan/WizardLM) | [Data](https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_70k)   [Data](https://huggingface.co/datasets/WizardLM/WizardLM_evol_instruct_V2_196k) |\\\\n| [**Koala: A Dialogue Model for Academic Research**](https://bair.berkeley.edu/blog/2023/04/03/koala/) | - | 2023-04 | [Github](https://github.com/lm-sys/FastChat) | [Data](https://huggingface.co/datasets/lmsys/chatbot_arena_conversations) |\\\\n| [**Alpaca: Aligning Language Model with Human Preferences**](https://crfm.stanford.edu/2023/03/13/alpaca.html) | - | 2023-03 | [Github](https://github.com/tatsu-lab/stanford_alpaca) | [Data](https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json) |\\\\n| [**Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality*\\\\\\\\*](https://lmsys.org/blog/2023-03-30-vicuna/) | - | 2023-03 | [Github](https://github.com/lm-sys/FastChat) | [Data](https://huggingface.co/datasets/lmsys/chatbot_arena_conversations) |\\\\n| [**Self-instruct: Aligning language model with self generated instructions**](https://arxiv.org/abs/2212.10560) | ACL | 2022-12 | [Github](https://github.com/yizhongw/self-instruct) | [Data](https://github.com/yizhongw/self-instruct) |\\\\n\\\\n#### Multi-turn Dialogue\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Zephyr: Direct Distillation of LM Alignment**](https://arxiv.org/abs/2310.16944) | arXiv | 2023-10 | [Github](https://github.com/huggingface/alignment-handbook) | [Data](https://github.com/huggingface/alignment-handbook) |\\\\n| [**OPENCHAT: ADVANCING OPEN-SOURCE LANGUAGE MODELS WITH MIXED-QUALITY DATA**](https://arxiv.org/pdf/2309.11235.pdf) | ICLR | 2023-09 | [Github](https://github.com/imoneoi/openchat) | [Data](https://github.com/imoneoi/openchat) |\\\\n| [**Enhancing Chat Language Models by Scaling High-quality Instructional Conversations**](https://arxiv.org/abs/2305.14233) | arXiv | 2023-05 | [Github](https://github.com/thunlp/UltraChat) | [Data](https://huggingface.co/datasets/stingning/ultrachat) |\\\\n| [**Baize: An Open-Source Chat Model with Parameter-Efficient Tuning on Self-Chat Data**](https://arxiv.org/abs/2304.01196) | EMNLP | 2023-04 | [Github](https://github.com/project-baize/baize-chatbot) | [Data](https://github.com/project-baize/baize-chatbot/tree/main/data) |\\\\n| [**Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90%* ChatGPT Quality*\\\\\\\\*](https://lmsys.org/blog/2023-03-30-vicuna/) | - | 2023-03 | [Github](https://github.com/lm-sys/FastChat) | [Data](https://huggingface.co/datasets/lmsys/chatbot_arena_conversations) |\\\\n\\\\n#### RAG Capability\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection**](https://arxiv.org/abs/2310.11511) | NIPS | 2023-10 | [Github](https://selfrag.github.io/) | [Data](https://selfrag.github.io/) |\\\\n| [**SAIL: Search-Augmented Instruction Learning**](https://arxiv.org/abs/2305.15225) | arXiv | 2023-05 | [Github](https://openlsr.org/sail-7b) | [Data](https://github.com/luohongyin/SAIL#reproducing-sail-models) |\\\\n| [**Knowledge-Augmented Reasoning Distillation for Small Language Models in Knowledge-Intensive Tasks**](https://arxiv.org/abs/2305.18395) | NIPS | 2023-05 | [Github](https://github.com/Nardien/KARD) | [Data](https://github.com/Nardien/KARD) |\\\\n\\\\n### Alignment\\\\n\\\\n#### Thinking Pattern\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Aligning Large and Small Language Models via Chain-of-Thought Reasoning**](https://aclanthology.org/2024.eacl-long.109.pdf) | EACL | 2024-03 | [Github](https://github.com/lranaldii/Aligning_LLMs) |  |\\\\n| [**Divide-or-Conquer? Which Part Should You Distill Your LLM?**](https://arxiv.org/pdf/2402.15000.pdf) | arXiv | 2024-02 |  |  |\\\\n| [**Selective Reflection-Tuning: Student-Selected Data Recycling for LLM Instruction-Tuning**](https://arxiv.org/abs/2402.10110) | arXiv | 2024-02 | [Github](https://github.com/tianyi-lab/Reflection_Tuning) | [Data](https://github.com/tianyi-lab/Reflection_Tuning) |\\\\n| [**Can LLMs Speak For Diverse People? Tuning LLMs via Debate to Generate Controllable Controversial Statements**](https://arxiv.org/abs/2402.10614) | arXiv | 2024-02 | [Github](https://github.com/tianyi-lab/DEBATunE) | [Data](https://github.com/tianyi-lab/DEBATunE) |\\\\n| [**Knowledgeable Preference Alignment for LLMs in Domain-specific Question Answering**](https://arxiv.org/abs/2311.06503) | arXiv | 2023-11 | [Github](https://github.com/zjukg/KnowPAT) |  |\\\\n| [**Orca 2: Teaching Small Language Models How to Reason**](https://arxiv.org/pdf/2311.11045.pdf) | arXiv | 2023-11 |  |  |\\\\n| [**Reflection-Tuning: Data Recycling Improves LLM Instruction-Tuning**](https://arxiv.org/abs/2310.11716) | NIPS Workshop | 2023-10 | [Github](https://github.com/tianyi-lab/Reflection_Tuning) | [Data](https://github.com/tianyi-lab/Reflection_Tuning) |\\\\n| [**Orca: Progressive Learning from Complex Explanation Traces of GPT-4**](https://arxiv.org/abs/2306.02707) | arXiv | 2023-06 |  |  |\\\\n| [**SelFee: Iterative Self-Revising LLM Empowered by Self-Feedback Generation**](https://kaistai.github.io/SelFee/) | arXiv | 2023-05 |  |  |\\\\n\\\\n#### Preference\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Ultrafeedback: Boosting language models with high-quality feedback**](https://arxiv.org/pdf/2310.01377.pdf) | arXiv | 2023-10 | [Github](https://github.com/thunlp/UltraFeedback) | [Data](https://huggingface.co/datasets/openbmb/UltraFeedback) |\\\\n| [**Zephyr: Direct Distillation of LM Alignment**](https://arxiv.org/abs/2310.16944) | arXiv | 2023-10 | [Github](https://github.com/huggingface/alignment-handbook) | [Data](https://github.com/huggingface/alignment-handbook) |\\\\n| [**Rlaif: Scaling Reinforcement Learning from Human Feedback with AI Feedback**](https://arxiv.org/pdf/2309.00267.pdf) | arXiv | 2023-09 |  |  |\\\\n| [**OPENCHAT: ADVANCING OPEN-SOURCE LANGUAGE MODELS WITH MIXED-QUALITY DATA**](https://arxiv.org/pdf/2309.11235.pdf) | ICLR | 2023-09 | [Github](https://github.com/imoneoi/openchat) | [Data](https://github.com/imoneoi/openchat) |\\\\n| [**RLCD: Reinforcement Learning from Contrast Distillation for Language Model Alignment**](https://arxiv.org/abs/2307.12950) | arXiv | 2023-07 | [Github](https://github.com/facebookresearch/rlcd) |  |\\\\n| [**Aligning Large Language Models through Synthetic Feedbacks**](https://arxiv.org/abs/2305.13735) | EMNLP | 2023-05 | [Github](https://github.com/naver-ai/almost) | [Data](https://github.com/naver-ai/almost) |\\\\n| [**Reward Design with Language Models**](https://arxiv.org/pdf/2303.00001.pdf) | ICLR | 2023-03 | [Github](https://github.com/minaek/reward_design_with_llms) |  |\\\\n| [**Training Language Models with Language Feedback at Scale**](https://arxiv.org/abs/2303.16755) | arXiv | 2023-03 |  |  |\\\\n| [**Constitutional AI: Harmlessness from AI Feedback**](https://arxiv.org/abs/2212.08073) | arXiv | 2022-12 |  |  |\\\\n\\\\n#### Value\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Ultrafeedback: Boosting language models with high-quality feedback**](https://arxiv.org/pdf/2310.01377.pdf) | arXiv | 2023-10 | [Github](https://github.com/thunlp/UltraFeedback) | [Data](https://huggingface.co/datasets/openbmb/UltraFeedback) |\\\\n| [**RLCD: Reinforcement Learning from Contrast Distillation for Language Model Alignment**](https://arxiv.org/abs/2307.12950) | arXiv | 2023-07 | [Github](https://github.com/facebookresearch/rlcd) |  |\\\\n| [**Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision**](https://proceedings.neurips.cc/paper/2023/hash/0764db1151b936aca59249e2c1386101-Abstract-Conference.html) | NeurIPS | 2023-05 | [Github](https://github.com/IBM/Dromedary) | [Data](https://huggingface.co/datasets/zhiqings/dromedary-65b-verbose-clone-v0) |\\\\n| [**Training Socially Aligned Language Models on Simulated Social Interactions**](https://arxiv.org/abs/2305.16960) | arXiv | 2023-05 |  |  |\\\\n| [**Constitutional AI: Harmlessness from AI Feedback**](https://arxiv.org/abs/2212.08073) | arXiv | 2022-12 |  |  |\\\\n\\\\n### Agent\\\\n\\\\n#### Tool Using\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Toolformer: Language Models Can Teach Themselves to Use Tools**](https://arxiv.org/abs/2302.04761) | arXiv | 2023-02 |  |  |\\\\n| [**Graph-ToolFormer: To Empower LLMs with Graph Reasoning Ability via Prompt Augmented by ChatGPT**](https://arxiv.org/abs/2304.11116) | arXiv | 2023-04 | [Github](https://github.com/jwzhanggy/Graph_Toolformer) | [Data](https://github.com/jwzhanggy/Graph_Toolformer) |\\\\n| [**Gorilla: Large Language Model Connected with Massive APIs**](https://arxiv.org/abs/2305.15334) | arXiv | 2023-05 | [Github](https://gorilla.cs.berkeley.edu/) | [Data](https://gorilla.cs.berkeley.edu/) |\\\\n| [**GPT4Tools: Teaching Large Language Model to Use Tools via Self-instruction**](https://arxiv.org/abs/2305.18752) | arXiv | 2023-05 | [Github](https://github.com/AILab-CVC/GPT4Tools) | [Data](https://github.com/AILab-CVC/GPT4Tools) |\\\\n| [**ToolAlpaca: Generalized Tool Learning for Language Models with 3000 Simulated Cases**](https://arxiv.org/abs/2306.05301) | arXiv | 2023-06 | [Github](https://github.com/tangqiaoyu/ToolAlpaca) | [Data](https://github.com/tangqiaoyu/ToolAlpaca) |\\\\n| [**ToolLLM: Facilitating Large Language Models to Master 16000+ Real-world APIs**](https://arxiv.org/abs/2307.16789) | arXiv | 2023-07 | [Github](https://github.com/OpenBMB/ToolBench) | [Data](https://github.com/OpenBMB/ToolBench) |\\\\n| [**Confucius: Iterative Tool Learning from Introspection Feedback by Easy-to-Difficult Curriculum**](https://arxiv.org/abs/2308.14034) | arXiv | 2023-08 | [Github](https://github.com/shizhl/Confucius) |  |\\\\n| [**CRAFT: Customizing LLMs by Creating and Retrieving from Specialized Toolsets**](https://arxiv.org/abs/2309.17428) | arXiv | 2023-09 | [Github](https://github.com/lifan-yuan/CRAFT) |  |\\\\n| [**MLLM-Tool: A Multimodal Large Language Model For Tool Agent Learning**](https://arxiv.org/abs/2401.10727) | arXiv | 2024-01 | [Github](https://github.com/MLLM-Tool/MLLM-Tool) | [Data](https://github.com/MLLM-Tool/MLLM-Tool) |\\\\n| [**Small LLMs Are Weak Tool Learners: A Multi-LLM Agent**](https://arxiv.org/abs/2401.07324) | arXiv | 2024-01 | [Github](https://github.com/X-PLUG/Multi-LLM-Agent) |  |\\\\n| [**EASYTOOL: Enhancing LLM-based Agents with Concise Tool Instruction**](https://arxiv.org/abs/2401.06201) | arXiv | 2024-01 | [Github](https://github.com/microsoft/JARVIS/) |  |\\\\n\\\\n#### Planning\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**AUTOACT: Automatic Agent Learning from Scratch via Self-Planning**](https://arxiv.org/abs/2401.05268) | arXiv | 2024-01 | [Github](https://github.com/zjunlp/AutoAct) |  |\\\\n| [**Lumos: Learning Agents with Unified Data, Modular Design, and Open-Source LLMs**](https://arxiv.org/abs/2311.05657) | arXiv | 2023-11 | [Github](https://allenai.github.io/lumos/) | [Data](https://allenai.github.io/lumos/) |\\\\n| [**TPTU-v2: Boosting Task Planning and Tool Usage of Large Language Model-based Agents in Real-world Systems**](https://arxiv.org/abs/2311.11315) | arXiv | 2023-11 |  |  |\\\\n| [**Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld**](https://arxiv.org/abs/2311.16714) | arXiv | 2023-11 |  |  |\\\\n| [**Accelerating Reinforcement Learning of Robotic Manipulations via Feedback from Large Language Models**](https://arxiv.org/abs/2311.02379) | CoRL | 2023-11 |  |  |\\\\n| [**Motif: Intrinsic Motivation from Artificial Intelligence Feedback**](https://arxiv.org/abs/2310.00166) | ICLR | 2023-10 | [Github](https://github.com/facebookresearch/motif) |  |\\\\n| [**FireAct: Toward Language Agent Fine-tuning**](https://arxiv.org/abs/2310.05915) | arXiv | 2023-10 | [Github](https://fireact-agent.github.io/) | [Data](https://fireact-agent.github.io/) |\\\\n| [**AgentTuning: Enabling Generalized Agent Abilities for LLMs**](https://arxiv.org/abs/2310.12823) | arXiv | 2023-10 | [Github](https://github.com/THUDM/AgentTuning) |  |\\\\n| [**Eureka: Human-Level Reward Design via Coding Large Language Models**](https://arxiv.org/pdf/2310.12931.pdf) | arXiv | 2023-10 | [Github](https://github.com/eureka-research/Eureka) |  |\\\\n| [**Language Instructed Reinforcement Learning for Human-AI Coordination**](https://arxiv.org/pdf/2304.07297.pdf) | PMLR | 2023-04 |  |  |\\\\n| [**Guiding Pretraining in Reinforcement Learning with Large Language Models**](https://arxiv.org/pdf/2302.06692.pdf) | PMLR | 2023-02 |  |  |\\\\n| [**Distilling Internet-Scale Vision-Language Models into Embodied Agents**](https://arxiv.org/abs/2301.12507) | ICML | 2023-01 |  |  |\\\\n\\\\n### NLP Task Specialization\\\\n\\\\n#### NLU\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**LLM vs Small Model? Large Language Model Based Text Augmentation Enhanced Personality Detection Model**](https://arxiv.org/pdf/2403.07581v1.pdf) | arXiv | 2024-03 |  |  |\\\\n| [**Evolving Knowledge Distillation with Large Language Models and Active Learning**](https://arxiv.org/pdf/2403.06414v1.pdf) | arXiv | 2024-03 |  |  |\\\\n| [**Mixed Distillation Helps Smaller Language Model Better Reasoning**](https://arxiv.org/pdf/2312.10730.pdf) | arXiv | 2023-12 |  |  |\\\\n| [**PromptMix: A Class Boundary Augmentation Method for Large Language Model Distillation**](https://arxiv.org/pdf/2310.14192.pdf) | EMNLP | 2023-10 | [Github](https://github.com/ServiceNow/PromptMix-EMNLP-2023) |  |\\\\n| [**TinyLLM: Learning a Small Student from Multiple Large Language Models**](https://arxiv.org/pdf/2402.04616.pdf) | arXiv | 2024-02 |  |  |\\\\n| [**Targeted Data Generation: Finding and Fixing Model Weaknesses**](https://arxiv.org/pdf/2305.17804.pdf) | ACL | 2023-05 | [Github](https://github.com/ZexueHe/TDG) |  |\\\\n| [**Distilling ChatGPT for Explainable Automated Student Answer Assessment**](https://arxiv.org/pdf/2305.12962.pdf) | arXiv | 2023-05 | [Github](https://github.com/lijiazheng99/aera) |  |\\\\n| [**ChatGPT outperforms crowd workers for text-annotation tasks**](https://arxiv.org/pdf/2303.15056.pdf) | arXiv | 2023-03 |  |  |\\\\n| [**Annollm: Making large language models to be better crowdsourced annotators**](https://arxiv.org/abs/2303.16854) | arXiv | 2023-03 |  |  |\\\\n| [**AugGPT: Leveraging ChatGPT for Text Data Augmentation**](https://arxiv.org/pdf/2302.13007.pdf) | arXiv | 2023-02 | [Github](https://github.com/yhydhx/AugGPT) |  |\\\\n| [**Is GPT-3 a Good Data Annotator?**](https://arxiv.org/pdf/2212.10450.pdf) | ACL | 2022-12 | [Github](https://github.com/DAMO-NLP-SG/LLM-Data-Annotator) |  |\\\\n| [**SunGen: Self-Guided Noise-Free Data Generation for Efficient Zero-Shot Learning**](https://arxiv.org/pdf/2205.12679.pdf) | ICLR | 2022-05 | [Github](https://github.com/SumilerGAO/SunGen) |  |\\\\n| [**ZeroGen: Efficient Zero-shot Learning via Dataset Generation**](https://arxiv.org/pdf/2202.07922.pdf) | EMNLP | 2022-02 | [Github](https://github.com/jiacheng-ye/ZeroGen) |  |\\\\n| [**Generating Training Data with Language Models: Towards Zero-Shot Language Understanding**](https://arxiv.org/pdf/2202.04538.pdf) | NeurIPS | 2022-02 | [Github](https://github.com/yumeng5/SuperGen) |  |\\\\n| [**Towards Zero-Label Language Learning**](https://arxiv.org/pdf/2109.09193.pdf) | arXiv | 2021-09 |  |  |\\\\n| [**Generate, Annotate, and Learn: NLP with Synthetic Text**](https://arxiv.org/pdf/2106.06168.pdf) | TACL | 2021-06 |  |  |\\\\n\\\\n#### NLG\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Tailoring Self-Rationalizers with Multi-Reward Distillation**](https://arxiv.org/pdf/2311.02805.pdf) | arXiv | 2023-11 | [Github](https://inklab.usc.edu/MaRio/) | [Data](https://inklab.usc.edu/MaRio/) |\\\\n| [**RECOMP: Improving Retrieval-Augmented LMs with Compression and Selective Augmentation**](https://arxiv.org/pdf/2310.04408.pdf) | arXiv | 2023-10 | [Github](https://github.com/carriex/recomp) |  |\\\\n| [**Neural Machine Translation Data Generation and Augmentation using ChatGPT**](https://arxiv.org/pdf/2307.05779.pdf) | arXiv | 2023-07 |  |  |\\\\n| [**On-Policy Distillation of Language Models: Learning from Self-Generated Mistakes**](https://arxiv.org/pdf/2306.13649.pdf) | ICLR | 2023-06 |  |  |\\\\n| [**Can LLMs generate high-quality synthetic note-oriented doctor-patient conversations?**](https://arxiv.org/pdf/2306.16931.pdf) | arXiv | 2023-06 | [Github](https://github.com/believewhat/Dr.NoteAid) | [Data](https://huggingface.co/datasets/akemiH/NoteChat) |\\\\n| [**InheritSumm: A General, Versatile and Compact Summarizer by Distilling from GPT**](https://arxiv.org/pdf/2305.13083.pdf) | EMNLP | 2023-05 |  |  |\\\\n| [**Impossible Distillation: from Low-Quality Model to High-Quality Dataset & Model for Summarization and Paraphrasing**](https://arxiv.org/abs/2305.16635) | arXiv | 2023-05 | [Github](https://github.com/jaehunjung1/impossible-distillation) |  |\\\\n| [**Data Augmentation for Radiology Report Simplification**](https://aclanthology.org/2023.findings-eacl.144.pdf) | Findings of EACL | 2023-04 | [Github](https://github.com/Ziyu-Yang/Radiology-Text-Simplification-Liver) |  |\\\\n| [**Want To Reduce Labeling Cost? GPT-3 Can Help**](https://aclanthology.org/2021.findings-emnlp.354) | Findings of EMNLP | 2021-08 |  |  |\\\\n\\\\n#### Information Retrieval\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**InstructDistill: Instruction Distillation Makes Large Language Models Efficient Zero-shot Rankers**](https://arxiv.org/pdf/2311.01555.pdf) | arXiv | 2023-11 | [Github](https://github.com/sunnweiwei/RankGPT/tree/main/InstructDistill) | [Data](https://github.com/sunnweiwei/RankGPT?tab=readme-ov-file#download-data-and-model) |\\\\n| [**Soft prompt tuning for augmenting dense retrieval with large language models**](https://arxiv.org/pdf/2307.08303.pdf) | arXiv | 2023-07 | [Github](https://github.com/zhiyuanpeng/SPTAR.git) |  |\\\\n| [**Query Rewriting in Retrieval-Augmented Large Language Models**](https://arxiv.org/pdf/2305.14283.pdf) | EMNLP | 2023-05 |  |  |\\\\n| [**Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents**](https://arxiv.org/pdf/2304.09542.pdf) | EMNLP | 2023-04 | [Github](https://github.com/sunnweiwei/RankGPT) | [Data](https://github.com/sunnweiwei/RankGPT?tab=readme-ov-file#download-data-and-models) |\\\\n| [**AugTriever: Unsupervised Dense Retrieval by Scalable Data Augmentation**](https://arxiv.org/pdf/2212.08841.pdf) | arXiv | 2022-12 | [Github](https://github.com/salesforce/AugTriever) |  |\\\\n| [**QUILL: Query Intent with Large Language Models using Retrieval Augmentation and Multi-stage Distillation**](https://arxiv.org/pdf/2210.15718.pdf) | EMNLP | 2022-10 |  |  |\\\\n| [**Promptagator: Few-shot Dense Retrieval From 8 Examples**](https://arxiv.org/pdf/2209.11755.pdf) | ICLR | 2022-09 |  |  |\\\\n| [**Questions Are All You Need to Train a Dense Passage Retrieval**](https://arxiv.org/pdf/2206.10658.pdf) | TACL | 2022-06 | [Github](https://github.com/DevSinghSachan/art) |  |\\\\n| [**Improving Passage Retrieval with Zero-Shot Question Generation**](https://arxiv.org/pdf/2204.07496.pdf) | EMNLP | 2022-04 | [Github](https://github.com/DevSinghSachan/unsupervised-passage-reranking) | [Data](https://github.com/DevSinghSachan/unsupervised-passage-reranking) |\\\\n| [**InPars: Data Augmentation for Information Retrieval using Large Language Models**](https://arxiv.org/pdf/2202.05144.pdf) | arXiv | 2022-02 | [Github](https://github.com/zetaalphavector/inpars) | [Data](https://github.com/zetaalphavector/inpars) |\\\\n| [**Generating Datasets with Pretrained Language Models**](https://arxiv.org/abs/2104.07540) | EMNLP | 2021-04 | [Github](https://github.com/timoschick/dino) |  |\\\\n\\\\n#### Recommendation\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Can Small Language Models be Good Reasoners for Sequential Recommendation?**](https://arxiv.org/pdf/2403.04260.pdf) | arXiv | 2024-03 |  |  |\\\\n| [**Large Language Model Augmented Narrative Driven Recommendations**](https://arxiv.org/pdf/2306.02250.pdf) | arXiv | 2023-06 |  |  |\\\\n| [**Recommendation as Instruction Following: A Large Language Model Empowered Recommendation Approach**](https://arxiv.org/pdf/2305.07001.pdf) | arXiv | 2023-05 |  |  |\\\\n| [**ONCE: Boosting Content-based Recommendation with Both Open- and Closed-source Large Language Models**](https://arxiv.org/pdf/2305.06566.pdf) | WSDM | 2023-05 | [Github](https://github.com/Jyonn/ONCE) | [Data](https://github.com/Jyonn/ONCE/releases/tag/Dataset) |\\\\n\\\\n#### Text Generation Evaluation\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Prometheus: Inducing Fine-grained Evaluation Capability in Language Models**](https://arxiv.org/pdf/2310.08491.pdf) | ICLR | 2023-10 | [Github](https://github.com/kaistAI/Prometheus) | [Data](https://huggingface.co/datasets/kaist-ai/Feedback-Collection) |\\\\n| [**TIGERScore: Towards Building Explainable Metric for All Text Generation Tasks**](https://arxiv.org/pdf/2310.00752.pdf) | arXiv | 2023-10 | [Github](https://tiger-ai-lab.github.io/TIGERScore/) | [Data](https://huggingface.co/datasets/TIGER-Lab/MetricInstruct) |\\\\n| [**Generative Judge for Evaluating Alignment**](https://arxiv.org/pdf/2310.05470.pdf) | ICLR | 2023-10 | [Github](https://github.com/GAIR-NLP/auto-j) | [Data](https://github.com/GAIR-NLP/auto-j) |\\\\n| [**PandaLM: An Automatic Evaluation Benchmark for LLM Instruction Tuning Optimization**](https://arxiv.org/abs/2306.05087) | arXiv | 2023-06 | [Github](https://github.com/WeOpenML/PandaLM) | [Data](https://github.com/WeOpenML/PandaLM) |\\\\n| [**INSTRUCTSCORE: Explainable Text Generation Evaluation with Fine-grained Feedback**](https://arxiv.org/pdf/2305.14282.pdf) | EMNLP | 2023-05 | [Github](https://github.com/xu1998hz/InstructScore_SEScore3) | [Data](https://github.com/xu1998hz/InstructScore_SEScore3) |\\\\n\\\\n\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Magicoder: Source Code Is All You Need**](https://arxiv.org/pdf/2312.02120.pdf) | arXiv | 2023-12 | [Github](https://github.com/ise-uiuc/magicoder) | [Data](https://huggingface.co/datasets/ise-uiuc/Magicoder-OSS-Instruct-75K)   [Data](https://huggingface.co/datasets/ise-uiuc/Magicoder-Evol-Instruct-110K) |\\\\n| [**WaveCoder: Widespread And Versatile Enhanced Instruction Tuning with Refined Data Generation**](https://arxiv.org/abs/2312.14187) | arXiv | 2023-12 |  |  |\\\\n| [**Instruction Fusion: Advancing Prompt Evolution through Hybridization**](https://arxiv.org/pdf/2312.15692.pdf) | arXiv | 2023-12 |  |  |\\\\n| [**MFTCoder: Boosting Code LLMs with Multitask Fine-Tuning**](https://arxiv.org/pdf/2311.02303.pdf) | arXiv | 2023-11 | [Github](https://github.com/codefuse-ai/MFTCOder) | [Data](https://huggingface.co/datasets/codefuse-ai/Evol-instruction-66k)   [Data](https://huggingface.co/datasets/codefuse-ai/CodeExercise-Python-27k) |\\\\n| [**LLM-Assisted Code Cleaning For Training Accurate Code Generators**](https://arxiv.org/pdf/2311.14904.pdf) | arXiv | 2023-11 |  |  |\\\\n| [**Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation**](https://arxiv.org/pdf/2310.18628.pdf) | EMNLP | 2023-10 | [Github](https://github.com/SalesforceAIResearch/PersDistill) |  |\\\\n| [**Code Llama: Open Foundation Models for Code**](https://arxiv.org/pdf/2308.12950.pdf) | arXiv | 2023-08 | [Github](https://github.com/facebookresearch/codellama) |  |\\\\n| [**Distilled GPT for Source Code Summarization**](https://arxiv.org/pdf/2308.14731.pdf) | arXiv | 2023-08 | [Github](https://github.com/apcl-research/jam-cgpt) | [Data](https://huggingface.co/datasets/apcl/Jam-CGPT/tree/main) |\\\\n| [**Textbooks Are All You Need: A Large-Scale Instructional Text Data Set for Language Models**](https://arxiv.org/pdf/2306.11644.pdf) | arXiv | 2023-06 |  |  |\\\\n| Code Alpaca: An Instruction-following LLaMA model for code generation | - | 2023-03 | [Github](https://github.com/sahil280114/codealpaca) | [Data](https://github.com/sahil280114/codealpaca?tab=readme-ov-file#data-release) |\\\\n\\\\n\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Miko: Multimodal Intention Knowledge Distillation from Large Language Models for Social-Media Commonsense Discovery**](https://arxiv.org/pdf/2402.18169.pdf) | arXiv | 2024-02 |  |  |\\\\n| [**Localizing Visual Commonsense Knowledge in Large Language Models**](https://arxiv.org/abs/2312.04837) | NeurIPS | 2023-12 | [Github](https://github.com/jamespark3922/localized-skd) | [Data](https://github.com/jamespark3922/localized-skd?tab=readme-ov-file) |\\\\n| [**To See is to Believe: Prompting GPT-4V for Better Visual Instruction Tuning**](https://arxiv.org/pdf/2311.07574.pdf) | arXiv | 2023-11 | [Github](https://github.com/X2FD/LVIS-INSTRUCT4V) | [Data](https://github.com/X2FD/LVIS-INSTRUCT4V) |\\\\n| [**ILuvUI: Instruction-tuned LangUage-Vision modeling of UIs from Machine Conversations**](https://arxiv.org/pdf/2310.04869.pdf) | arXiv | 2023-10 |  |  |\\\\n| [**NExT-GPT: Any-to-Any Multimodal LLM**](https://arxiv.org/pdf/2309.05519.pdf) | arXiv | 2023-09 | [Github](https://github.com/NExT-GPT/NExT-GPT) | [Data](https://github.com/NExT-GPT/NExT-GPT) |\\\\n| [**StableLLaVA: Enhanced Visual Instruction Tuning with Synthesized Image-Dialogue Data**](https://arxiv.org/pdf/2308.10253.pdf) | arXiv | 2023-08 | [Github](https://github.com/icoz69/StableLLAVA?tab=readme-ov-file) | [Data](https://github.com/icoz69/StableLLAVA?tab=readme-ov-file) |\\\\n| [**PointLLM: Empowering Large Language Models to Understand Point Clouds**](https://arxiv.org/pdf/2308.16911.pdf) | arXiv | 2023-08 | [Github](https://github.com/OpenRobotLab/PointLLM) | [Data](https://huggingface.co/datasets/RunsenXu/PointLLM/tree/main) |\\\\n| [**SVIT: Scaling up Visual Instruction Tuning**](https://arxiv.org/pdf/2307.04087.pdf) | arXiv | 2023-07 | [Github](https://github.com/BAAI-DCAI/Visual-Instruction-Tuning) | [Data](https://huggingface.co/datasets/BAAI/SVIT) |\\\\n| [**ChatSpot: Bootstrapping Multimodal LLMs via Precise Referring Instruction Tuning**](https://arxiv.org/pdf/2307.09474.pdf) | arXiv | 2023-07 |  |  |\\\\n| [**Shikra: Unleashing Multimodal LLM\\'s Referential Dialogue Magic**](https://arxiv.org/pdf/2306.15195.pdf) | arXiv | 2023-06 | [Github](https://github.com/shikras/shikra) | [Data](https://github.com/shikras/shikra/blob/main/docs/data.md) |\\\\n| [**Mitigating Hallucination in Large Multi-Modal Models via Robust Instruction Tuning**](https://arxiv.org/pdf/2306.14565.pdf) | ICLR | 2023-06 | [Github](https://github.com/FuxiaoLiu/LRV-Instruction) | [Data](https://github.com/FuxiaoLiu/LRV-Instruction?tab=readme-ov-file) |\\\\n| [**Valley: Video Assistant with Large Language model Enhanced abilitY**](https://arxiv.org/pdf/2306.07207.pdf) | arXiv | 2023-06 | [Github](https://github.com/RupertLuo/Valley) | [Data](https://huggingface.co/datasets/luoruipu1/Valley-Instruct-73k) |\\\\n| [**DetGPT: Detect What You Need via Reasoning**](https://arxiv.org/pdf/2305.14167.pdf) | EMNLP | 2023-05 | [Github](https://detgpt.github.io) |  |\\\\n| [**Visual Instruction Tuning: A Comprehensive Study of Visual Instruction Tuning for Large Language Models**](https://arxiv.org/abs/2304.08485) | NeurIPS | 2023-04 | [Github](https://github.com/haotian-liu/LLaVA) | [Data](https://github.com/haotian-liu/LLaVA/blob/main/docs/Data.md) |\\\\n\\\\n### Summary Table\\\\n\\\\n*Figure: A summary of representative works about skill distillation.*\\\\n\\\\n  \\\\n\\\\n## Verticalization Distillation\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Fuzi**](https://github.com/irlab-sdu/fuzi.mingcha) | - | 2023-08 | [Github](https://github.com/irlab-sdu/fuzi.mingcha) |  |\\\\n| [**ChatLaw: Open-Source Legal Large Language Model with Integrated External Knowledge Bases**](https://arxiv.org/pdf/2306.16092.pdf) | arXiv | 2023-06 | [Github](https://github.com/PKU-YuanGroup/ChatLaw) |  |\\\\n| [**Lawyer LLaMA Technical Report**](https://arxiv.org/pdf/2305.15062.pdf) | arXiv | 2023-05 | [Github](https://github.com/AndrewZhe/lawyer-llama) | [Data](https://github.com/AndrewZhe/lawyer-llama) |\\\\n\\\\n### Medical & Healthcare\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**HuatuoGPT-II, One-stage Training for Medical Adaption of LLMs**](https://arxiv.org/pdf/2311.09774.pdf) | arXiv | 2023-11 | [Github](https://github.com/FreedomIntelligence/HuatuoGPT-II) | [Data](https://huggingface.co/datasets/FreedomIntelligence/HuatuoGPT2_sft_instruct_GPT4_50K) |\\\\n| [**AlpaCare: Instruction-tuned large language models for medical application**](https://arxiv.org/pdf/2310.14558.pdf) | arXiv | 2023-10 | [Github](https://github.com/xzhang97666/alpacare) | [Data](https://github.com/XZhang97666/AlpaCare/blob/master/data/MedInstruct-52k.json) |\\\\n| [**DISC-MedLLM: Bridging General Large Language Models and Real-World Medical Consultation**](https://arxiv.org/pdf/2308.14346.pdf) | arXiv | 2023-08 | [Github](https://github.com/FudanDISC/DISC-MedLLM/tree/main) | [Data](https://huggingface.co/datasets/Flmc/DISC-Med-SFT) |\\\\n| [**HuatuoGPT: Taming Language Model to Be a Doctor**](https://arxiv.org/pdf/2305.15075.pdf) | EMNLP | 2023-05 | [Github](https://github.com/FreedomIntelligence/HuatuoGPT) | [Data](https://huggingface.co/datasets/FreedomIntelligence/HuatuoGPT-sft-data-v1) |\\\\n| [**DoctorGLM: Fine-tuning your Chinese doctor is not a herculean task**](https://arxiv.org/pdf/2304.01097.pdf) | arXiv | 2023-04 | [Github](https://github.com/xionghonglin/DoctorGLM) | [Data](https://github.com/Toyhom/Chinese-medical-dialogue-data) |\\\\n| [**Huatuo: Tuning LLM with Chinese Medical Knowledge**](https://arxiv.org/pdf/2304.06975.pdf) | arXiv | 2023-04 | [Github](https://github.com/SCIR-HI/Huatuo-Llama-Med-Chinese) |  |\\\\n| [**MedAlpaca: An Open-Source Collection of Medical Conversational AI Models and Training Data**](https://arxiv.org/pdf/2304.08247.pdf) | arXiv | 2023-04 | [Github](https://github.com/kbressem/medAlpaca) | [Data](https://github.com/kbressem/medAlpaca) |\\\\n| [**PMC-LLaMA: Further Finetuning LLaMA on Medical Papers**](https://arxiv.org/pdf/2304.14454.pdf) | arXiv | 2023-04 | [Github](https://github.com/chaoyi-wu/PMC-LLaMA) | [Data](https://huggingface.co/datasets/axiong/pmc_llama_instructions) |\\\\n| [**ChatDoctor: A Medical Chat Model Fine-Tuned on a Large Language Model Meta-AI (LLaMA) Using Medical Domain Knowledge**](https://arxiv.org/pdf/2303.14070.pdf) | arXiv | 2023-03 | [Github](https://github.com/Kent0n-Li/ChatDoctor) |  |\\\\n\\\\n\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**XuanYuan 2.0: A Large Chinese Financial Chat Model with Hundreds of Billions Parameters**](https://arxiv.org/pdf/2305.12002.pdf) | CIKM | 2023-05 |  |  |\\\\n\\\\n\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**MuseGraph: Graph-oriented Instruction Tuning of Large Language Models for Generic Graph Mining**](https://arxiv.org/pdf/2403.04780.pdf) | arXiv | 2024-03 |  |  |\\\\n| [**SciGLM: Training Scientific Language Models with Self-Reflective Instruction Annotation and Tuning**](https://arxiv.org/pdf/2401.07950.pdf) | arXiv | 2024-01 | [Github](https://github.com/THUDM/SciGLM) |  |\\\\n| [**AstroLLaMA-Chat: Scaling AstroLLaMA with Conversational and Diverse Datasets**](https://arxiv.org/pdf/2401.01916.pdf) | arXiv | 2024-01 |  |  |\\\\n| [**GeoGalactica: A Scientific Large Language Model in Geoscience**](https://arxiv.org/pdf/2401.00434.pdf) | arXiv | 2024-01 | [Github](https://github.com/geobrain-ai/geogalactica) | [Data](https://huggingface.co/datasets/daven3/geobench) |\\\\n| [**InstructMol: Multi-Modal Integration for Building a Versatile and Reliable Molecular Assistant in Drug Discovery**](https://arxiv.org/pdf/2311.16208.pdf) | arXiv | 2023-11 | [Github](https://github.com/IDEA-XL/InstructMol) |  |\\\\n| [**LLM-Prop: Predicting Physical And Electronic Properties Of Crystalline Solids From Their Text Descriptions**](https://arxiv.org/pdf/2310.14029.pdf) | arXiv | 2023-10 | [Github](https://github.com/vertaix/LLM-Prop) |  |\\\\n| [**OceanGPT: A Large Language Model for Ocean Science Tasks**](https://arxiv.org/pdf/2310.02031.pdf) | arXiv | 2023-10 | [Github](https://github.com/zjunlp/KnowLM) | [Data](https://huggingface.co/datasets/zjunlp/OceanBench) |\\\\n| [**MarineGPT: Unlocking Secrets of Ocean to the Public**](https://arxiv.org/pdf/2310.13596.pdf) | arXiv | 2023-10 | [Github](https://github.com/hkust-vgd/MarineGPT) |  |\\\\n| [**Mammoth: Building Math Generalist Models through Hybrid Instruction Tuning**](https://arxiv.org/abs/2309.05653) | arXiv | 2023-09 | [Github](https://tiger-ai-lab.github.io/MAmmoTH/) | [Data](https://huggingface.co/datasets/TIGER-Lab/MathInstruct) |\\\\n| [**ToRA: A Tool-Integrated Reasoning Agent for Mathematical Problem Solving**](https://arxiv.org/pdf/2309.17452.pdf) | ICLR | 2023-09 | [Github](https://github.com/microsoft/ToRA) |  |\\\\n| [**DARWIN Series: Domain Specific Large Language Models for Natural Science**](https://arxiv.org/pdf/2308.13565.pdf) | arXiv | 2023-08 | [Github](https://github.com/MasterAI-EAM/Darwin) |  |\\\\n| [**Wizardmath: Empowering mathematical reasoning for large language models via reinforced evol-instruct**](https://arxiv.org/abs/2308.09583) | arXiv | 2023-08 | [Github](https://github.com/nlpxucan/WizardLM) |  |\\\\n| [**Biomedgpt: Open Multimodal Generative Pre-trained Transformer for Biomedicine**](https://arxiv.org/pdf/2308.09442.pdf) | arXiv | 2023-08 | [Github](https://github.com/PharMolix/OpenBioMed) | [Data](https://github.com/PharMolix/OpenBioMed) |\\\\n| [**Prot2Text: Multimodal Protein’s Function Generation with GNNs and Transformers**](https://arxiv.org/pdf/2307.14367.pdf) | NeurIPS | 2023-07 |  |  |\\\\n| [**xTrimoPGLM: Unified 100B-Scale Pre-trained Transformer for Deciphering the Language of Protein**](https://www.biorxiv.org/content/10.1101/2023.07.05.547496v1.full.pdf) | bioRxiv | 2023-07 |  |  |\\\\n| [**GIMLET: A Unified Graph-Text Model for Instruction-Based Molecule Zero-Shot Learning**](https://arxiv.org/pdf/2306.13089.pdf) | NeurIPS | 2023-06 | [Github](https://github.com/zhao-ht/GIMLET) | [Data](https://huggingface.co/datasets/haitengzhao/molecule_property_instruction) |\\\\n| [**K2: A Foundation Language Model for Geoscience Knowledge Understanding and Utilization**](https://arxiv.org/pdf/2306.05064.pdf) | arXiv | 2023-06 | [Github](https://github.com/davendw49/k2) |  |\\\\n| [**Visual Instruction Tuning: A Comprehensive Study of Visual Instruction Tuning for Large Language Models**](https://arxiv.org/abs/2304.08485) | NeurIPS | 2023-04 | [Github](https://github.com/haotian-liu/LLaVA) | [Data](https://github.com/haotian-liu/LLaVA/blob/main/docs/Data.md) |\\\\n\\\\n\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**OWL: A Large Language Model for IT Operations**](https://arxiv.org/pdf/2309.09298.pdf) | arXiv | 2023-09 | [Github](https://github.com/HC-Guo/Owl) | [Data](https://github.com/HC-Guo/Owl/tree/main/OWL-Instruct/data) |\\\\n| [**EduChat: A Large-Scale Language Model-based Chatbot System for Intelligent Education**](https://arxiv.org/pdf/2308.02773.pdf) | arXiv | 2023-08 | [Github](https://github.com/ECNU-ICALK/EduChat) | [Data](https://huggingface.co/datasets/ecnu-icalk/educhat-sft-002-data-osm) |\\\\n\\\\n## Encoder-based KD\\\\n\\\\n> **Note**: Our survey mainly focuses on generative LLMs, and thus the encoder-based KD is not included in the survey. However, we are also interested in this topic and continue to update the latest works in this area.\\\\n\\\\n| Title | Venue | Date | Code | Data |\\\\n| --- | --- | --- | --- | --- |\\\\n| [**Masked Latent Semantic Modeling: an Efficient Pre-training Alternative to Masked Language Modeling**](https://aclanthology.org/2023.findings-acl.876.pdf) | Findings of ACL | 2023-08 |  |  |\\\\n| [**Better Together: Jointly Using Masked Latent Semantic Modeling and Masked Language Modeling for Sample Efficient Pre-training**](https://aclanthology.org/2023.conll-babylm.26.pdf) | CoNLL | 2023-08 |  |  |\\\\n\\\\n## TODO List\\\\n\\\\n* Add works about O1-like distillation. Stay tuned!\\\\n\\\\n## Citation\\\\n\\\\nIf you find this repository helpful, please consider citing the following paper:\\\\n\\\\n```\\\\n@misc{xu2024survey,\\\\n      title={A Survey on Knowledge Distillation of Large Language Models}, \\\\n      author={Xiaohan Xu and Ming Li and Chongyang Tao and Tao Shen and Reynold Cheng and Jinyang Li and Can Xu and Dacheng Tao and Tianyi Zhou},\\\\n      year={2024},\\\\n      eprint={2402.13116},\\\\n      archivePrefix={arXiv},\\\\n      primaryClass={cs.CL}\\\\n}\\\\n\\\\n```\\\\n\\\\n## Star History\\\\n\\\\nYou can’t perform that action at this time.\"\\n      }\\n    ],\\n    \"response_time\": 1.57,\\n    \"request_id\": \"51bc50f0-be4f-40a1-a9dc-321bb2f7d037\"\\n  }\\n}' name='web_search' id='c75cba2d-a4ba-4bc8-8c7b-67f31f4aa318' tool_call_id='y1xbsjyej'\n"
     ]
    },
    {
     "ename": "APIStatusError",
     "evalue": "Error code: 413 - {'error': {'message': 'Request too large for model `qwen/qwen3-32b` in organization `org_01hrm502bcfvcas4j2ppdwhsxf` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 43538, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAPIStatusError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m thinking = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      2\u001b[39m answer = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m msg, metadata \u001b[38;5;129;01min\u001b[39;00m graph.astream({\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mknowledge distillation regarding large language models?\u001b[39m\u001b[33m\"\u001b[39m}, stream_mode=\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2768\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2766\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m loop.amatch_cached_writes():\n\u001b[32m   2767\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2768\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   2769\u001b[39m     [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop.tasks.values() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t.writes],\n\u001b[32m   2770\u001b[39m     timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   2771\u001b[39m     get_waiter=get_waiter,\n\u001b[32m   2772\u001b[39m     schedule_task=loop.aaccept_push,\n\u001b[32m   2773\u001b[39m ):\n\u001b[32m   2774\u001b[39m     \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   2775\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m _output(\n\u001b[32m   2776\u001b[39m         stream_mode,\n\u001b[32m   2777\u001b[39m         print_mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2780\u001b[39m         asyncio.QueueEmpty,\n\u001b[32m   2781\u001b[39m     ):\n\u001b[32m   2782\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m o\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:401\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdone\u001b[49m\u001b[43m.\u001b[49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout_exc_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTimeoutError\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpanic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    407\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tb := exc.__traceback__:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:511\u001b[39m, in \u001b[36m_panic_or_proceed\u001b[39m\u001b[34m(futs, timeout_exc_cls, panic)\u001b[39m\n\u001b[32m    509\u001b[39m                 interrupts.append(exc)\n\u001b[32m    510\u001b[39m             \u001b[38;5;28;01melif\u001b[39;00m fut \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SKIP_RERAISE_SET:\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    512\u001b[39m \u001b[38;5;66;03m# raise combined interrupts\u001b[39;00m\n\u001b[32m    513\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m interrupts:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:137\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policy, stream, match_cached_writes, configurable)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    139\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:672\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    670\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    671\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m672\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(\n\u001b[32m    673\u001b[39m             step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs), context=context\n\u001b[32m    674\u001b[39m         )\n\u001b[32m    675\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    676\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\futures.py:291\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    290\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:316\u001b[39m, in \u001b[36mTask.__step_run_and_handle_result\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    314\u001b[39m         result = coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    315\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m         result = \u001b[43mcoro\u001b[49m\u001b[43m.\u001b[49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    318\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._must_cancel:\n\u001b[32m    319\u001b[39m         \u001b[38;5;66;03m# Task is cancelled right before coro stops.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:440\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    438\u001b[39m         \u001b[38;5;28;01mawait\u001b[39;00m run_manager.on_chain_end(ret)\n\u001b[32m    439\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.afunc(*args, **kwargs)\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    442\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m ret.ainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:617\u001b[39m, in \u001b[36mrun_in_executor\u001b[39m\u001b[34m(executor_or_config, func, *args, **kwargs)\u001b[39m\n\u001b[32m    613\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m executor_or_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(executor_or_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;66;03m# Use default executor with context copied from current context\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.get_running_loop().run_in_executor(\n\u001b[32m    618\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    619\u001b[39m         cast(\u001b[33m\"\u001b[39m\u001b[33mCallable[..., T]\u001b[39m\u001b[33m\"\u001b[39m, partial(copy_context().run, wrapper)),\n\u001b[32m    620\u001b[39m     )\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.get_running_loop().run_in_executor(executor_or_config, wrapper)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\futures.py:291\u001b[39m, in \u001b[36mFuture.__await__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    290\u001b[39m     \u001b[38;5;28mself\u001b[39m._asyncio_future_blocking = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m  \u001b[38;5;66;03m# This tells Task to wait for completion.\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.done():\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mawait wasn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt used with future\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\tasks.py:385\u001b[39m, in \u001b[36mTask.__wakeup\u001b[39m\u001b[34m(self, future)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__wakeup\u001b[39m(\u001b[38;5;28mself\u001b[39m, future):\n\u001b[32m    384\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m385\u001b[39m         \u001b[43mfuture\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    387\u001b[39m         \u001b[38;5;66;03m# This may also be a cancellation.\u001b[39;00m\n\u001b[32m    388\u001b[39m         \u001b[38;5;28mself\u001b[39m.__step(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\asyncio\\futures.py:203\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    201\u001b[39m \u001b[38;5;28mself\u001b[39m.__log_traceback = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception.with_traceback(\u001b[38;5;28mself\u001b[39m._exception_tb)\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:608\u001b[39m, in \u001b[36mrun_in_executor.<locals>.wrapper\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m() -> T:\n\u001b[32m    607\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m608\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    609\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    610\u001b[39m         \u001b[38;5;66;03m# StopIteration can't be set on an asyncio.Future\u001b[39;00m\n\u001b[32m    611\u001b[39m         \u001b[38;5;66;03m# it raises a TypeError and leaves the Future pending forever\u001b[39;00m\n\u001b[32m    612\u001b[39m         \u001b[38;5;66;03m# so we need to convert it to a RuntimeError\u001b[39;00m\n\u001b[32m    613\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 25\u001b[39m, in \u001b[36mcall_model\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_model\u001b[39m(state: MessagesState):\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m     response = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbind_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: response}\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\langchain_core\\runnables\\base.py:5434\u001b[39m, in \u001b[36mRunnableBindingBase.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   5427\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   5428\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m   5429\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   5432\u001b[39m     **kwargs: Optional[Any],\n\u001b[32m   5433\u001b[39m ) -> Output:\n\u001b[32m-> \u001b[39m\u001b[32m5434\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbound\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5435\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   5436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5437\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5438\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:980\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    971\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    972\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    973\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    977\u001b[39m     **kwargs: Any,\n\u001b[32m    978\u001b[39m ) -> LLMResult:\n\u001b[32m    979\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m980\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:799\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    796\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    797\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    798\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m799\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    805\u001b[39m         )\n\u001b[32m    806\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    807\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1034\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1028\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._should_stream(\n\u001b[32m   1029\u001b[39m     async_api=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1030\u001b[39m     run_manager=run_manager,\n\u001b[32m   1031\u001b[39m     **kwargs,\n\u001b[32m   1032\u001b[39m ):\n\u001b[32m   1033\u001b[39m     chunks: \u001b[38;5;28mlist\u001b[39m[ChatGenerationChunk] = []\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresponse_metadata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_gen_info_and_msg_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1036\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\langchain_groq\\chat_models.py:593\u001b[39m, in \u001b[36mChatGroq._stream\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m    590\u001b[39m params = {**params, **kwargs, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m}\n\u001b[32m    592\u001b[39m default_chunk_class: \u001b[38;5;28mtype\u001b[39m[BaseMessageChunk] = AIMessageChunk\n\u001b[32m--> \u001b[39m\u001b[32m593\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    594\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunk, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    595\u001b[39m         chunk = chunk.model_dump()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\groq\\resources\\chat\\completions.py:368\u001b[39m, in \u001b[36mCompletions.create\u001b[39m\u001b[34m(self, messages, model, exclude_domains, frequency_penalty, function_call, functions, include_domains, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, n, parallel_tool_calls, presence_penalty, reasoning_effort, reasoning_format, response_format, search_settings, seed, service_tier, stop, store, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[39m\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcreate\u001b[39m(\n\u001b[32m    182\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    183\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    229\u001b[39m     timeout: \u001b[38;5;28mfloat\u001b[39m | httpx.Timeout | \u001b[38;5;28;01mNone\u001b[39;00m | NotGiven = NOT_GIVEN,\n\u001b[32m    230\u001b[39m ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[32m    231\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    232\u001b[39m \u001b[33;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[32m    233\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    366\u001b[39m \u001b[33;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[32m    367\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/openai/v1/chat/completions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mexclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunction_call\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfunctions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minclude_domains\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_domains\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogit_bias\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlogprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_completion_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmax_tokens\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallel_tool_calls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    386\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    387\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_effort\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    388\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mreasoning_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    389\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse_format\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    390\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msearch_settings\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msearch_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    391\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mseed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    392\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mservice_tier\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstop\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    394\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    395\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstream\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtool_choice\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtools\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_logprobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1232\u001b[39m, in \u001b[36mSyncAPIClient.post\u001b[39m\u001b[34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[39m\n\u001b[32m   1218\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(\n\u001b[32m   1219\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1220\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1227\u001b[39m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1228\u001b[39m ) -> ResponseT | _StreamT:\n\u001b[32m   1229\u001b[39m     opts = FinalRequestOptions.construct(\n\u001b[32m   1230\u001b[39m         method=\u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m, url=path, json_data=body, files=to_httpx_files(files), **options\n\u001b[32m   1231\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1232\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Agents\\.venv\\Lib\\site-packages\\groq\\_base_client.py:1034\u001b[39m, in \u001b[36mSyncAPIClient.request\u001b[39m\u001b[34m(self, cast_to, options, stream, stream_cls)\u001b[39m\n\u001b[32m   1031\u001b[39m             err.response.read()\n\u001b[32m   1033\u001b[39m         log.debug(\u001b[33m\"\u001b[39m\u001b[33mRe-raising status error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1034\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_status_error_from_response(err.response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1036\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m   1038\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mcould not resolve response (should never happen)\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mAPIStatusError\u001b[39m: Error code: 413 - {'error': {'message': 'Request too large for model `qwen/qwen3-32b` in organization `org_01hrm502bcfvcas4j2ppdwhsxf` service tier `on_demand` on tokens per minute (TPM): Limit 6000, Requested 43538, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
      "During task with name 'call_model' and id '49e8441f-0ba9-b898-a349-3f4d60f8fdb4'"
     ]
    }
   ],
   "source": [
    "thinking = \"\"\n",
    "answer = \"\"\n",
    "async for msg, metadata in graph.astream({\"messages\": \"knowledge distillation regarding large language models?\"}, stream_mode=\"messages\"):\n",
    "    print(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb8f5a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='', additional_kwargs={}, response_metadata={'finish_reason': 'length', 'model_name': 'qwen/qwen3-32b', 'system_fingerprint': 'fp_5cf921caa2', 'service_tier': 'on_demand'}, id='run--db23fa6b-3e56-49d3-9a67-14cf5c5b2b94', usage_metadata={'input_tokens': 1227, 'output_tokens': 1000, 'total_tokens': 2227})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c81b32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
